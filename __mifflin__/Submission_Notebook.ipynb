{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Instantiate the R environment in this notebook:**"
      ],
      "metadata": {
        "id": "R9ZjdI2qmQH8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hLfPFpgfl56M"
      },
      "outputs": [],
      "source": [
        "!pip install rpy2==3.5.1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import rpy2"
      ],
      "metadata": {
        "id": "LhtV5UI-mX7i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext rpy2.ipython"
      ],
      "metadata": {
        "id": "myYrMeHumaBi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **First, use R and stringr to clean prompts from text_exercise_final, as well as impute means, and create a column of concatenated responses:**"
      ],
      "metadata": {
        "id": "ub8x6LXzorG9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prompts below were found using by inspecting the first few responses to text_exercise_final and using the str_detect function from the stringr library on certain phrases that appeared to be repeated, to see how frequently they were repeated across the entire dataset. Frequently repeated prompts were saved to be cleaned / removed from all responses."
      ],
      "metadata": {
        "id": "SQyIKmus9XTo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "\n",
        "library(stringr)\n",
        "\n",
        "# Clean prompts from responses: \n",
        "newest_first_detect = \"1. Did you handle each challenge in the order you received it, or did you handle them another way? Please describe your approach.\"\n",
        "first_detect = \"Original Message----- From: Assessment Administrator Sent:\"\n",
        "third_detect = \"Subject : RESPONSE REQUIRED: About your day This e-mail contains some final questions for you. Your answers to these questions will help in the evaluation of your performance by providing a better understanding of your approach and rationale. It is important that you provide complete and thorough answers to the questions below.  For your reference, a list of messages you received today is shown after question 4.\"\n",
        "fourth_detect = \" This e-mail and the one that follows contain some final questions for you. Your answers to these questions will help us evaluate your performance by giving us a better understanding of your approach to the challenges you faced. It is therefore very important that you provide complete and thorough answers to the questions below and on the e-mail that follows.  To reply to the questions in these messages, simply click the Reply button above and enter your responses in the form of a reply e-mail.\"\n",
        "newest_second_detect = \"Cc: Subject : About your day (1 of 2)  This e-mail and the one that follows contain some final questions for you. Your answers to these questions will help us evaluate your performance by giving us a better understanding of your approach to the challenges you faced. It is therefore very important that you provide complete and thorough answers to the questions below and on the e-mail that follows.  To reply to the questions in these messages, simply click the Reply button above and enter your responses in the form of a reply e-mail.\"\n",
        "newest_third_detect = \"Subject : About your day (2 of 2)  Following are some of the e-mails that you received today, along with some questions about how you approached them. Your answers to these questions will help us evaluate your performance by giving us a better understanding of your approach to the challenges you faced. To respond, simply click the Reply button above and enter your answers in the form of a reply e-mail.\"\n",
        "newest_fourth_detect = \"2. Please list the major categories of issues or problems facing Final Assembly in the Bridgeport facility of Soundproof Solutions.\"\n",
        "newest_fifth_detect = \"3. Describe why each entry in Question 2 is an issue or problem.\"\n",
        "newest_sixth_detect = \"1. What were the three most important and the three least important e-mails to handle?\"\n",
        "newest_seventh_detect = \"2. Why did you feel that the e-mails you rated as most important were critical?\"\n",
        "newest_eighth_detect = \"3.Todays assessment provided you with background information about Soundproof Solutions and also presented thechallenging messages listed above. Were there situations where information from one source/challenge helped you to better understand and address anotherchallenge? If so, please list specific examples of theseinstances (Example: Message X related to Message Z, Company Policies related to Message Y, etc.).\"\n",
        "newest_ninth_detect = \"4. Describe what additional information you would have liked to have in order to have a better or clearer understanding of the messages and challenges presented to you today.\"\n",
        "newest_tenth_detect = \"1. Please list the major categories of issues or problems facing Customer Service Team 5 of Soundproof Solutions. Why is each an issue or a problem?\"\n",
        "newest_eleventh_detect = \"Cc:\"\n",
        "newest_twelvth_detect = \"3. List specific examples (if any) of instances where you detected a relationship between two of the messages you received in your inbox. For example, when you decided how respond to one message, did you consider information provided not only in that message, but in other message(s)?\"\n",
        "newest_thirteenth_detect = \"2. What were the three most important messages you considered the highest priorities to handle? Why?\"\n",
        "newest_fourteenth_detect = \"The messages you received today included:\"#  Weedler Contracting: A customer is suspected of abusing the companys replacement policies  Eluto Caplanu: Someone has placed an insulting message on Elutos lunch  Effective mentoring pays dividends: Taylor mentored Jerry Winters and presents the results  Customer satisfaction insights: Tracy Hurdle reports research on customer satisfaction  Promotion: There is new room in the budget to promote a part-time employee to full-time  Professional conduct: A salesperson complains that representatives behave unprofessionally  Theft of company-confidential information: A security guard suspects an associate of improper activity  Bench strength: Representatives must be signed up for training per company policy  quietPAPER ONE: A new product is faulty and will start to produce complaints in two weeks  Paperless office: A plan is presented to replace paper files  Installation in Sales: Sales requests scheduling soundproofing for their area, and a meeting with a customer  Feedback process: Kim proposes a way to efficiently deal with customer feedback  Fletcher Systems: An unhappy customer demands reinstallation and a meeting\"\n",
        "newest_fifteenth_detect = \"Weedler Contracting: A customer is suspected of abusing the companys replacement policies\"#  Eluto Caplanu: Someone has placed an insulting message on Elutos lunch  Effective mentoring pays dividends: Taylor mentored Jerry Winters and presents the results  Customer satisfaction insights: Tracy Hurdle reports research on customer satisfaction  Promotion: There is new room in the budget to promote a part-time employee to full-time  Professional conduct: A salesperson complains that representatives behave unprofessionally  Theft of company-confidential information: A security guard suspects an associate of improper activity  Bench strength: Representatives must be signed up for training per company policy  quietPAPER ONE: A new product is faulty and will start to produce complaints in two weeks  Paperless office: A plan is presented to replace paper files  Installation in Sales: Sales requests scheduling soundproofing for their area, and a meeting with a customer  Feedback process: Kim proposes a way to efficiently deal with customer feedback  Fletcher Systems: An unhappy customer demands reinstallation and a meeting\"\n",
        "newest_sixteenth_detect = \"Eluto Caplanu: Someone has placed an insulting message on Elutos lunch\"#  Effective mentoring pays dividends: Taylor mentored Jerry Winters and presents the results  Customer satisfaction insights: Tracy Hurdle reports research on customer satisfaction  Promotion: There is new room in the budget to promote a part-time employee to full-time  Professional conduct: A salesperson complains that representatives behave unprofessionally  Theft of company-confidential information: A security guard suspects an associate of improper activity  Bench strength: Representatives must be signed up for training per company policy  quietPAPER ONE: A new product is faulty and will start to produce complaints in two weeks  Paperless office: A plan is presented to replace paper files  Installation in Sales: Sales requests scheduling soundproofing for their area, and a meeting with a customer  Feedback process: Kim proposes a way to efficiently deal with customer feedback  Fletcher Systems: An unhappy customer demands reinstallation and a meeting\"\n",
        "newest_seventeenth_detect = \"Effective mentoring pays dividends: Taylor mentored Jerry Winters and presents the results\"#  Customer satisfaction insights: Tracy Hurdle reports research on customer satisfaction  Promotion: There is new room in the budget to promote a part-time employee to full-time  Professional conduct: A salesperson complains that representatives behave unprofessionally  Theft of company-confidential information: A security guard suspects an associate of improper activity  Bench strength: Representatives must be signed up for training per company policy  quietPAPER ONE: A new product is faulty and will start to produce complaints in two weeks  Paperless office: A plan is presented to replace paper files  Installation in Sales: Sales requests scheduling soundproofing for their area, and a meeting with a customer  Feedback process: Kim proposes a way to efficiently deal with customer feedback  Fletcher Systems: An unhappy customer demands reinstallation and a meeting\"\n",
        "newest_eigthteenth_detect = \"Customer satisfaction insights: Tracy Hurdle reports research on customer satisfaction\"#  Promotion: There is new room in the budget to promote a part-time employee to full-time  Professional conduct: A salesperson complains that representatives behave unprofessionally  Theft of company-confidential information: A security guard suspects an associate of improper activity  Bench strength: Representatives must be signed up for training per company policy  quietPAPER ONE: A new product is faulty and will start to produce complaints in two weeks  Paperless office: A plan is presented to replace paper files  Installation in Sales: Sales requests scheduling soundproofing for their area, and a meeting with a customer  Feedback process: Kim proposes a way to efficiently deal with customer feedback  Fletcher Systems: An unhappy customer demands reinstallation and a meeting\"\n",
        "newest_nineteenth_detect = \"Promotion: There is new room in the budget to promote a part-time employee to full-time\"#  Professional conduct: A salesperson complains that representatives behave unprofessionally  Theft of company-confidential information: A security guard suspects an associate of improper activity  Bench strength: Representatives must be signed up for training per company policy  quietPAPER ONE: A new product is faulty and will start to produce complaints in two weeks  Paperless office: A plan is presented to replace paper files  Installation in Sales: Sales requests scheduling soundproofing for their area, and a meeting with a customer  Feedback process: Kim proposes a way to efficiently deal with customer feedback  Fletcher Systems: An unhappy customer demands reinstallation and a meeting\"\n",
        "newest_twentieth_detect = \"Professional conduct: A salesperson complains that representatives behave unprofessionally\"#  Theft of company-confidential information: A security guard suspects an associate of improper activity  Bench strength: Representatives must be signed up for training per company policy  quietPAPER ONE: A new product is faulty and will start to produce complaints in two weeks  Paperless office: A plan is presented to replace paper files  Installation in Sales: Sales requests scheduling soundproofing for their area, and a meeting with a customer  Feedback process: Kim proposes a way to efficiently deal with customer feedback  Fletcher Systems: An unhappy customer demands reinstallation and a meeting\"\n",
        "newest_twentyfirst_detect = \"Theft of company-confidential information: A security guard suspects an associate of improper activity\"#  Bench strength: Representatives must be signed up for training per company policy  quietPAPER ONE: A new product is faulty and will start to produce complaints in two weeks  Paperless office: A plan is presented to replace paper files  Installation in Sales: Sales requests scheduling soundproofing for their area, and a meeting with a customer  Feedback process: Kim proposes a way to efficiently deal with customer feedback  Fletcher Systems: An unhappy customer demands reinstallation and a meeting\"\n",
        "newest_twentysecond_detect = \"Bench strength: Representatives must be signed up for training per company policy\"#  quietPAPER ONE: A new product is faulty and will start to produce complaints in two weeks  Paperless office: A plan is presented to replace paper files  Installation in Sales: Sales requests scheduling soundproofing for their area, and a meeting with a customer  Feedback process: Kim proposes a way to efficiently deal with customer feedback  Fletcher Systems: An unhappy customer demands reinstallation and a meeting\"\n",
        "newest_twentythird_detect = \"quietPAPER ONE: A new product is faulty and will start to produce complaints in two weeks\"#  Paperless office: A plan is presented to replace paper files  Installation in Sales: Sales requests scheduling soundproofing for their area, and a meeting with a customer  Feedback process: Kim proposes a way to efficiently deal with customer feedback  Fletcher Systems: An unhappy customer demands reinstallation and a meeting\"\n",
        "newest_twentyfourth_detect = \"Paperless office: A plan is presented to replace paper files\"#  Installation in Sales: Sales requests scheduling soundproofing for their area, and a meeting with a customer  Feedback process: Kim proposes a way to efficiently deal with customer feedback  Fletcher Systems: An unhappy customer demands reinstallation and a meeting\"\n",
        "newest_twentyfifth_detect = \"Installation in Sales: Sales requests scheduling soundproofing for their area, and a meeting with a customer\"#  Feedback process: Kim proposes a way to efficiently deal with customer feedback  Fletcher Systems: An unhappy customer demands reinstallation and a meeting\"\n",
        "newest_twentysixth_detect = \"Feedback process: Kim proposes a way to efficiently deal with customer feedback\"#  Fletcher Systems: An unhappy customer demands reinstallation and a meeting\"\n",
        "newest_twentyseventh_detect = \"Fletcher Systems: An unhappy customer demands reinstallation and a meeting\"\n",
        "\n",
        "# Script to remove all of these strings from responses: \n",
        "strs_to_remove_list = c(newest_first_detect, newest_second_detect, first_detect, fourth_detect,newest_third_detect,newest_fourth_detect,newest_fifth_detect,newest_sixth_detect,newest_seventh_detect,newest_eighth_detect,third_detect, newest_ninth_detect, newest_tenth_detect, newest_eleventh_detect, newest_twelvth_detect, newest_thirteenth_detect, newest_fourteenth_detect, newest_fifteenth_detect, newest_sixteenth_detect, newest_seventeenth_detect, newest_eigthteenth_detect, newest_nineteenth_detect, newest_twentieth_detect, newest_twentyfirst_detect, newest_twentysecond_detect, newest_twentythird_detect, newest_twentyfourth_detect, newest_twentyfifth_detect, newest_twentysixth_detect, newest_twentyseventh_detect) \n",
        "\n",
        "# Read in data: \n",
        "train_pub_df = read.csv(\"/content/train_pub.csv\")\n",
        "dev_pub_df = read.csv(\"/content/test_pub.csv\")\n",
        "\n",
        "i = 1\n",
        "while (i <= nrow(train_pub_df))\n",
        "{\n",
        "  j = 1\n",
        "  while (j <= length(strs_to_remove_list))\n",
        "  {\n",
        "    train_pub_df[i, 25] = str_remove_all(train_pub_df[i, 25], coll(strs_to_remove_list[j]))\n",
        "    j = j + 1\n",
        "  }\n",
        "  i = i + 1\n",
        "}\n",
        "\n",
        "i = 1\n",
        "while (i <= nrow(dev_pub_df))\n",
        "{\n",
        "  j = 1\n",
        "  while (j <= length(strs_to_remove_list))\n",
        "  {\n",
        "    dev_pub_df[i, 25] = str_remove_all(dev_pub_df[i, 25], coll(strs_to_remove_list[j]))\n",
        "    j = j + 1\n",
        "  }\n",
        "  i = i + 1\n",
        "}\n",
        "\n",
        "\n",
        "# Impute means for missing values in ratings for train_pub \n",
        "train_pub_df$rating_chooses_appropriate_action = ifelse(is.na(train_pub_df$rating_chooses_appropriate_action), 2.762491, train_pub_df$rating_chooses_appropriate_action) \n",
        "\n",
        "train_pub_df$rating_identifies_issues_opportunities = ifelse(is.na(train_pub_df$rating_identifies_issues_opportunities), 2.668356, train_pub_df$rating_identifies_issues_opportunities) \n",
        "\n",
        "train_pub_df$rating_involves_others = ifelse(is.na(train_pub_df$rating_involves_others), 2.80449, train_pub_df$rating_involves_others)\n",
        "\n",
        "print(colSums(is.na(train_pub_df)))\n",
        "\n",
        "\n",
        "# Create super columns of concatenated responses - first, for train_pub: \n",
        "train_pub_df$super = rep(0, nrow(train_pub_df))\n",
        "\n",
        "i = 1\n",
        "while (i <= nrow(train_pub_df))\n",
        "{\n",
        "  j = 9\n",
        "  x = ''\n",
        "  while (j <= 26)\n",
        "  {\n",
        "    if (is.na(train_pub_df[i,j]))\n",
        "    {\n",
        "      j = j + 1\n",
        "    }\n",
        "    else if (j != 26)\n",
        "    {\n",
        "      x = str_c(x, train_pub_df[i,j], sep = \" \")\n",
        "      j = j + 1\n",
        "    }\n",
        "    else if (j == 26)\n",
        "    {\n",
        "      train_pub_df[i,j] = x\n",
        "      j = j + 1\n",
        "    }\n",
        "  }\n",
        "  i = i + 1\n",
        "}\n",
        "\n",
        "\n",
        "# Next, for dev_pub:\n",
        "dev_pub_df$super = rep(0, nrow(dev_pub_df))\n",
        "\n",
        "i = 1\n",
        "while (i <= nrow(dev_pub_df))\n",
        "{\n",
        "  j = 9\n",
        "  x = ''\n",
        "  while (j <= 26)\n",
        "  {\n",
        "    if (is.na(dev_pub_df[i,j]))\n",
        "    {\n",
        "      j = j + 1\n",
        "    }\n",
        "    else if (j != 26)\n",
        "    {\n",
        "      x = str_c(x, dev_pub_df[i,j], sep = \" \")\n",
        "      j = j + 1\n",
        "    }\n",
        "    else if (j == 26)\n",
        "    {\n",
        "      dev_pub_df[i,j] = x\n",
        "      j = j + 1\n",
        "    }\n",
        "  }\n",
        "  i = i + 1\n",
        "}\n",
        "\n",
        "\n",
        "# Create label columns:\n",
        "train_pub_df$label = rep('train', nrow(train_pub_df))\n",
        "dev_pub_df$label = rep('dev', nrow(dev_pub_df))\n",
        "\n",
        "# Create super_df - all particpants in single dataframe: \n",
        "super_df = rbind(train_pub_df, dev_pub_df)\n",
        "\n",
        "# output to csv\n",
        "write.csv(super_df, file = \"cleaned_text_super_df_FINAL_TEST_SET.csv\")\n",
        "\n",
        "# Sent to python pyenchant + word_ninja script to fix spelling errors and split words that are missing required spaces: "
      ],
      "metadata": {
        "id": "mH1u1q_Tm-oW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Using Pyenchant and wordninja to fix misspelled words and phrases missing spaces:**"
      ],
      "metadata": {
        "id": "DNYDQi_No1Bj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!apt update\n",
        "!apt install enchant\n",
        "!pip install pyenchant"
      ],
      "metadata": {
        "id": "vr09bcxLpRxz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wordninja"
      ],
      "metadata": {
        "id": "P4GQAfr4qB8O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "so first split into tokens \n",
        "\n",
        "then, in that token list,\n",
        "\n",
        "for each token in list, check if it's in the vocabulary (or pronoun list)\n",
        "\n",
        "if it is, add it to a new list \n",
        "\n",
        "if not, word ninja it, then add each seperated one to the list \n",
        "\n",
        "then, join the new list with a space in between (# corpus = \" \".join(super_df)) \n",
        "\n",
        "\"\"\"\n",
        "import spacy\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.model_selection import train_test_split\n",
        "import sys\n",
        "from sklearn.linear_model import Ridge\n",
        "# from textblob import TextBlob#, Word\n",
        "import enchant\n",
        "import wordninja\n",
        "import sys \n",
        "\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "b = enchant.Broker()\n",
        "\n",
        "b.set_ordering(\"en_US\",\"aspell\")\n",
        "\n",
        "dictionary_enchant = b.request_dict(\"en_US\")\n",
        "\n",
        "# Set pandas options to allow more printing rows/columns\n",
        "pd.set_option(\"display.max_rows\", 2000)\n",
        "pd.set_option(\"display.max_columns\", 2000)\n",
        "\n",
        "# Read in data: \n",
        "super_pub_df = pd.read_csv('/content/cleaned_text_super_df_FINAL_TEST_SET.csv')\n",
        "\n",
        "cols = super_pub_df.axes[1]\n",
        "\n",
        "print(cols)\n",
        "print(len(cols))\n",
        "\n",
        "unwanted_pipes = [\"ner\", \"parser\"]\n",
        "\n",
        "def spacy_tokenizer(doc):\n",
        "  with nlp.disable_pipes(*unwanted_pipes):\n",
        "    return [t.lemma_ for t in nlp(doc) if \\\n",
        "            not t.is_punct and \\\n",
        "            not t.is_space and \\\n",
        "            t.is_alpha]\n",
        "\n",
        "first_version = super_pub_df.iloc[0,26]\n",
        "\n",
        "print(f\"{first_version=}\")\n",
        "\n",
        "for i in range(len(super_pub_df)):\n",
        "    og_text_cell = super_pub_df.iloc[i,26]\n",
        "    tokenized_og_text_cell = spacy_tokenizer(og_text_cell)\n",
        "\n",
        "    for index, item in enumerate(tokenized_og_text_cell):\n",
        "        if not dictionary_enchant.check(item):\n",
        "            try:\n",
        "                tokenized_og_text_cell[index] = dictionary_enchant.suggest(item)[0]\n",
        "            except IndexError:\n",
        "                # print(item)\n",
        "                # use wordninja to split \n",
        "                wordninja_list = wordninja.split(item)\n",
        "                # print(wordninja_list)\n",
        "                # if they're in list, join like below \n",
        "                joined_wordninja_list = \" \".join(wordninja_list)\n",
        "                # then make the index that \n",
        "                tokenized_og_text_cell[index] = joined_wordninja_list\n",
        "\n",
        "                 \n",
        "    super_pub_df.iloc[i,26] = \" \".join(tokenized_og_text_cell) \n",
        "\n",
        "# Export corrected version to csv: \n",
        "super_pub_df.to_csv('truly_corrected_super_df_correct_spelling_splits_cleaned_text_FINAL_TEST_SET.csv',index=False)\n",
        "\n",
        "corrected_version = super_pub_df.iloc[0,26]\n",
        "\n",
        "print(f\"{corrected_version=}\")"
      ],
      "metadata": {
        "id": "21IyA840o685"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Next, separate particpants into groups based on questions received:**"
      ],
      "metadata": {
        "id": "GWPAwdFktcya"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Groupings / clusters were found by inspecting patterns in NA values among participants - there was a pattern regarding which participants received which set of questions, which was the basis for the groupings into seperate \"clusters\". \n",
        "\n",
        "The main idea is that, if participants received different questions, their reponses should be evaluted separately. The cosine similarity of responses / textual features of participants who received the same or similar questions should be more meaningful than including all participants and comparing cosine similarity to the rest of the entire group of participants, so the participants were seperated based upon the set of questions they received.  "
      ],
      "metadata": {
        "id": "CYaL8ZPm_LuO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "\n",
        "truly_corrected_super_df_correct_spelling_splits_cleaned_text = read.csv(\"/content/truly_corrected_super_df_correct_spelling_splits_cleaned_text_FINAL_TEST_SET.csv\")\n",
        "\n",
        "# Removing the index column that Python added: \n",
        "colnames(truly_corrected_super_df_correct_spelling_splits_cleaned_text)[1] = 'unnamed'\n",
        "\n",
        "truly_corrected_super_df_correct_spelling_splits_cleaned_text = subset(truly_corrected_super_df_correct_spelling_splits_cleaned_text, select = -c(unnamed))\n",
        "\n",
        "\n",
        "# So first, let's separate super df into L cluster, S cluster, and T cluster (Large, Small, Tiny)\n",
        "verified_super = truly_corrected_super_df_correct_spelling_splits_cleaned_text\n",
        "\n",
        "verified_super[verified_super==\"\"]<-NA\n",
        "\n",
        "\n",
        "L_cluster_verified_super = subset(verified_super, subset = is.na(verified_super$text_exercise_18))\n",
        "\n",
        "T_cluster_verified_super = subset(L_cluster_verified_super, subset = !is.na(L_cluster_verified_super$text_exercise_4))\n",
        "print(nrow(T_cluster_verified_super))\n",
        "\n",
        "L_cluster_verified_super = subset(L_cluster_verified_super, subset = is.na(L_cluster_verified_super$text_exercise_4))\n",
        "print(nrow(L_cluster_verified_super))\n",
        "print(colSums(is.na(L_cluster_verified_super)))\n",
        "\n",
        "S_cluster_verified_super = subset(verified_super, subset = !is.na(verified_super$text_exercise_18))\n",
        "print(nrow(S_cluster_verified_super))\n",
        "\n",
        "print(colSums(is.na(T_cluster_verified_super)))\n",
        "\n",
        "print(colSums(is.na(S_cluster_verified_super)))\n",
        "\n",
        "print(sort(colSums(is.na(L_cluster_verified_super)), decreasing = TRUE))\n",
        "print(sort(colSums(is.na(S_cluster_verified_super)), decreasing = TRUE))\n",
        "print(sort(colSums(is.na(T_cluster_verified_super)), decreasing = TRUE))\n",
        "\n",
        "print(colnames(T_cluster_verified_super))\n",
        "\n",
        "row_with_text_exercise4_in_s_cluster = subset(S_cluster_verified_super, subset = !is.na(S_cluster_verified_super$text_exercise_4))\n",
        "print(nrow(row_with_text_exercise4_in_s_cluster))\n",
        "print(colSums(is.na(row_with_text_exercise4_in_s_cluster)))\n",
        "\n",
        "S_cluster_verified_super = subset(S_cluster_verified_super, subset = is.na(S_cluster_verified_super$text_exercise_4))\n",
        "\n",
        "print(nrow(S_cluster_verified_super))\n",
        "\n",
        "L_cluster_verified_super = rbind(L_cluster_verified_super, row_with_text_exercise4_in_s_cluster)\n",
        "\n",
        "print(nrow(L_cluster_verified_super))\n",
        "print(nrow(S_cluster_verified_super))\n",
        "print(nrow(T_cluster_verified_super))\n",
        "\n",
        "# view(row_with_text_exercise4_in_s_cluster)\n",
        "\n",
        "print(sort(colSums(is.na(L_cluster_verified_super)), decreasing = FALSE))\n",
        "print(sort(colSums(is.na(S_cluster_verified_super)), decreasing = FALSE))\n",
        "print(sort(colSums(is.na(T_cluster_verified_super)), decreasing = FALSE))\n",
        "\n",
        "\n",
        "# Then we need to start getting the values for cosine similarity for each cluster for each thing \n",
        "# So, first would be unigrams/bigrams for each of the three clusters \n",
        "\n",
        "write.csv(L_cluster_verified_super, \"L_cluster_truly_correct_spelling_splits_cleaned_text_FINAL_TEST_SET.csv\")\n",
        "\n",
        "write.csv(S_cluster_verified_super, \"S_cluster_truly_correct_spelling_splits_cleaned_text_FINAL_TEST_SET.csv\")\n",
        "\n",
        "write.csv(T_cluster_verified_super, \"T_cluster_truly_correct_spelling_splits_cleaned_text_FINAL_TEST_SET.csv\")\n"
      ],
      "metadata": {
        "id": "0SmV6g1EtMEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Getting the cosine similarity of the unigrams/bigrams vector of each participant's concatenated response vs each other participants' vector. Appends n columns of cosine similarity scores, where n is the number of particpants in that group.**"
      ],
      "metadata": {
        "id": "nH6lZm1m3IfQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import pandas as pd\n",
        "from scipy import spatial\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "pd.set_option(\"display.max_rows\", 4000)\n",
        "pd.set_option(\"display.max_columns\", 4000)\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "def spacy_tokenizer(doc):\n",
        "  return [t.text for t in nlp(doc) if not t.is_punct]\n",
        "\n",
        "vectorizer = CountVectorizer(tokenizer=spacy_tokenizer, lowercase=False, binary=True, ngram_range=(1,2))"
      ],
      "metadata": {
        "id": "LrlDEqtD1Bkx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "L_cluster_verified_super = pd.read_csv(\"/content/L_cluster_truly_correct_spelling_splits_cleaned_text_FINAL_TEST_SET.csv\")\n",
        "\n",
        "print(L_cluster_verified_super.iloc[0,0])"
      ],
      "metadata": {
        "id": "cnd0zt_R1I3J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cols = L_cluster_verified_super.axes[1]\n",
        "\n",
        "print(cols)\n",
        "print(len(cols))"
      ],
      "metadata": {
        "id": "3PB0-wyw1PAk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(L_cluster_verified_super.iloc[1,26])"
      ],
      "metadata": {
        "id": "arfMYWGs2CUt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "L_cluster_verified_super_w_bigrams_cos_sim = pd.concat([L_cluster_verified_super, pd.DataFrame(cosine_similarity(vectorizer.fit_transform(L_cluster_verified_super.iloc[:,26].tolist())))], axis=1)"
      ],
      "metadata": {
        "id": "5li7_WH_2IF6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "L_cluster_verified_super_w_bigrams_cos_sim.to_csv('L_cluster_verified_super_w_bigrams_cos_sim.csv',index=False)"
      ],
      "metadata": {
        "id": "25GxZh7a2Kps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "S_cluster_verified_super = pd.read_csv(\"/content/S_cluster_truly_correct_spelling_splits_cleaned_text_FINAL_TEST_SET.csv\")\n",
        "\n",
        "S_cluster_verified_super_w_bigrams_cos_sim = pd.concat([S_cluster_verified_super, pd.DataFrame(cosine_similarity(vectorizer.fit_transform(S_cluster_verified_super.iloc[:,26].tolist())))], axis=1)\n",
        "\n",
        "S_cluster_verified_super_w_bigrams_cos_sim.to_csv('S_cluster_verified_super_w_bigrams_cos_sim.csv',index=False)"
      ],
      "metadata": {
        "id": "1gsr8HHn2eZc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "T_cluster_verified_super = pd.read_csv(\"/content/T_cluster_truly_correct_spelling_splits_cleaned_text_FINAL_TEST_SET.csv\")\n",
        "\n",
        "T_cluster_verified_super_w_bigrams_cos_sim = pd.concat([T_cluster_verified_super, pd.DataFrame(cosine_similarity(vectorizer.fit_transform(T_cluster_verified_super.iloc[:,26].tolist())))], axis=1)\n",
        "\n",
        "T_cluster_verified_super_w_bigrams_cos_sim.to_csv('T_cluster_verified_super_w_bigrams_cos_sim.csv',index=False)"
      ],
      "metadata": {
        "id": "GNgDWkED2-GH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "\n",
        "# Next let's get the bigrams/unigrams from google colab script for L, S, and T: \n",
        "\n",
        "L_cluster_verified_super_w_bigrams_cos_sim = read.csv(\"/content/L_cluster_verified_super_w_bigrams_cos_sim.csv\")\n",
        "\n",
        "S_cluster_verified_super_w_bigrams_cos_sim = read.csv(\"/content/S_cluster_verified_super_w_bigrams_cos_sim.csv\")\n",
        "\n",
        "T_cluster_verified_super_w_bigrams_cos_sim = read.csv(\"/content/T_cluster_verified_super_w_bigrams_cos_sim.csv\")\n",
        "\n",
        "colnames(L_cluster_verified_super_w_bigrams_cos_sim)[1:40]\n",
        "colnames(L_cluster_verified_super_w_bigrams_cos_sim)[1] = \"unnamed\"\n",
        "colnames(S_cluster_verified_super_w_bigrams_cos_sim)[1] = \"unnamed\"\n",
        "colnames(T_cluster_verified_super_w_bigrams_cos_sim)[1] = \"unnamed\"\n",
        "\n",
        "L_cluster_verified_super_w_bigrams_cos_sim = subset(L_cluster_verified_super_w_bigrams_cos_sim, select = -c(unnamed))\n",
        "S_cluster_verified_super_w_bigrams_cos_sim = subset(S_cluster_verified_super_w_bigrams_cos_sim, select = -c(unnamed))\n",
        "T_cluster_verified_super_w_bigrams_cos_sim = subset(T_cluster_verified_super_w_bigrams_cos_sim, select = -c(unnamed))\n",
        "\n",
        "colnames(L_cluster_verified_super_w_bigrams_cos_sim)[1:40]\n",
        "colnames(S_cluster_verified_super_w_bigrams_cos_sim)[1:40]\n",
        "colnames(T_cluster_verified_super_w_bigrams_cos_sim)[1:40]\n",
        "\n",
        "# Changing colnames that start w X so we can add TFIDF / distilbert embeddings / cos_sim of distilbert embeddings without issue \n",
        "\n",
        "i = 28\n",
        "while(i <= ncol(L_cluster_verified_super_w_bigrams_cos_sim))\n",
        "{\n",
        "  prev = colnames(L_cluster_verified_super_w_bigrams_cos_sim)[i]\n",
        "  curr = str_c(\"uni_bigrams\", prev, sep = \"_\")\n",
        "  colnames(L_cluster_verified_super_w_bigrams_cos_sim)[i] = curr\n",
        "  i = i + 1\n",
        "}\n",
        "\n",
        "i = 28\n",
        "while(i <= ncol(S_cluster_verified_super_w_bigrams_cos_sim))\n",
        "{\n",
        "  prev = colnames(S_cluster_verified_super_w_bigrams_cos_sim)[i]\n",
        "  curr = str_c(\"uni_bigrams\", prev, sep = \"_\")\n",
        "  colnames(S_cluster_verified_super_w_bigrams_cos_sim)[i] = curr\n",
        "  i = i + 1\n",
        "}\n",
        "\n",
        "i = 28\n",
        "while(i <= ncol(T_cluster_verified_super_w_bigrams_cos_sim))\n",
        "{\n",
        "  prev = colnames(T_cluster_verified_super_w_bigrams_cos_sim)[i]\n",
        "  curr = str_c(\"uni_bigrams\", prev, sep = \"_\")\n",
        "  colnames(T_cluster_verified_super_w_bigrams_cos_sim)[i] = curr\n",
        "  i = i + 1\n",
        "}\n"
      ],
      "metadata": {
        "id": "cKdVfT2U6zVk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Next, get the distilbert embeddings vectors cosine similarity columns for each participant in each group:**"
      ],
      "metadata": {
        "id": "m4A1wffU8tO8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Note: Credit for the below code used to generate distilbert text embeddings goes to Dr. Louis Hickman. For reference, see the paper, \"Automatic scoring of speeded interpersonal assessment center exercises via machine learning: Initial psychometric evidence and practical guidelines\", (Hickman et. al., 2023).**"
      ],
      "metadata": {
        "id": "xXoiKZ8a9RiQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "4qQMxYoU-vCW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
        "!pip install transformers\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import transformers as ppb # pytorch transformers"
      ],
      "metadata": {
        "id": "3ZySxB9O_KHp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_class, tokenizer_class, pretrained_weights = (ppb.DistilBertModel, ppb.DistilBertTokenizer, 'distilbert-base-uncased')\n",
        "\n",
        "# Load pretrained model/tokenizer\n",
        "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
        "model = model_class.from_pretrained(pretrained_weights)"
      ],
      "metadata": {
        "id": "1YkEehUl_NlJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "L_cluster_verified_super = pd.read_csv(\"/content/L_cluster_truly_correct_spelling_splits_cleaned_text_FINAL_TEST_SET.csv\")"
      ],
      "metadata": {
        "id": "gQvmbmvp_Plo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized1 = L_cluster_verified_super['super'].apply((lambda x: tokenizer.encode(x, padding=True, truncation=True, add_special_tokens=True)))"
      ],
      "metadata": {
        "id": "zvnQMZS4_l4D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = 0\n",
        "for i in tokenized1.values:\n",
        "    if len(i) > max_len:\n",
        "        max_len = len(i)\n",
        "\n",
        "padded1 = np.array([i + [0]*(max_len-len(i)) for i in tokenized1.values])\n",
        "\n",
        "np.array(padded1).shape"
      ],
      "metadata": {
        "id": "OTaDhyhg_tqz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attention_mask1 = np.where(padded1 != 0, 1, 0)\n",
        "attention_mask1.shape"
      ],
      "metadata": {
        "id": "Q1ijlUvV_wPK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(L_cluster_verified_super))"
      ],
      "metadata": {
        "id": "w8_YA78A_0el"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids1 = torch.tensor(np.array(padded1[0:173]))\n",
        "\n",
        "with torch.no_grad():\n",
        "    last_hidden_states1 = model(input_ids1)"
      ],
      "metadata": {
        "id": "-V3xwv6LA0pE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features1 = last_hidden_states1[0][:,0,:].numpy()"
      ],
      "metadata": {
        "id": "n6NnYDaWA1l4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids2 = torch.tensor(np.array(padded1[173:346]))\n",
        "\n",
        "with torch.no_grad():\n",
        "    last_hidden_states2 = model(input_ids2)"
      ],
      "metadata": {
        "id": "5udH9nBEA3ZN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features2 = last_hidden_states2[0][:,0,:].numpy()"
      ],
      "metadata": {
        "id": "GzoMpos7A5nP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids3 = torch.tensor(np.array(padded1[346:519]))\n",
        "\n",
        "with torch.no_grad():\n",
        "    last_hidden_states3 = model(input_ids3)"
      ],
      "metadata": {
        "id": "nka5-H44A7rg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features3 = last_hidden_states3[0][:,0,:].numpy()"
      ],
      "metadata": {
        "id": "Yl1mu_ICA-Bu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids4 = torch.tensor(np.array(padded1[519:692]))\n",
        "\n",
        "with torch.no_grad():\n",
        "    last_hidden_states4 = model(input_ids4)"
      ],
      "metadata": {
        "id": "qMHGwaMMA_zb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features4 = last_hidden_states4[0][:,0,:].numpy()"
      ],
      "metadata": {
        "id": "xCpnRDuyBCN_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids5 = torch.tensor(np.array(padded1[692:865]))\n",
        "\n",
        "with torch.no_grad():\n",
        "    last_hidden_states5 = model(input_ids5)"
      ],
      "metadata": {
        "id": "-E4X-nOMBD_b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features5 = last_hidden_states5[0][:,0,:].numpy()"
      ],
      "metadata": {
        "id": "hn7g2ZCWBGWn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids6 = torch.tensor(np.array(padded1[865:1038]))\n",
        "\n",
        "with torch.no_grad():\n",
        "    last_hidden_states6 = model(input_ids6)"
      ],
      "metadata": {
        "id": "3Tr4vxliBIMa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features6 = last_hidden_states6[0][:,0,:].numpy()"
      ],
      "metadata": {
        "id": "ZgtBElouBKwz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids7 = torch.tensor(np.array(padded1[1038:1211]))\n",
        "\n",
        "with torch.no_grad():\n",
        "    last_hidden_states7 = model(input_ids7)"
      ],
      "metadata": {
        "id": "FWX9ZH7SBNDI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features7 = last_hidden_states7[0][:,0,:].numpy()"
      ],
      "metadata": {
        "id": "cgFcV9exBPWu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids8 = torch.tensor(np.array(padded1[1211:1384]))\n",
        "\n",
        "with torch.no_grad():\n",
        "    last_hidden_states8 = model(input_ids8)\n",
        "\n",
        "features8 = last_hidden_states8[0][:,0,:].numpy()"
      ],
      "metadata": {
        "id": "bvZ07qLEBRR4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features_full = np.concatenate((features1, features2, features3, features4, features5, features6, features7, features8),axis = 0)"
      ],
      "metadata": {
        "id": "PVj200iOBTku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(features_full))"
      ],
      "metadata": {
        "id": "FIUKZh8qBWhq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(L_cluster_verified_super.head())"
      ],
      "metadata": {
        "id": "ERTftKN_BaE_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cols = L_cluster_verified_super.axes[1]\n",
        "\n",
        "print(cols)\n",
        "print(len(cols))"
      ],
      "metadata": {
        "id": "hzV_IydYBdDN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas import DataFrame\n",
        "feat_full = pd.DataFrame(data=features_full)"
      ],
      "metadata": {
        "id": "Nw_sbLFlBe4_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "L_cluster_verified_super = DataFrame (L_cluster_verified_super,columns=['Unnamed: 0', 'response_id','rating_chooses_appropriate_action',\n",
        "       'rating_commits_to_action', 'rating_gathers_information',\n",
        "       'rating_identifies_issues_opportunities',\n",
        "       'rating_interprets_information', 'rating_involves_others',\n",
        "       'rating_decision_making_final_score', 'text_exercise_4',\n",
        "       'text_exercise_5', 'text_exercise_6', 'text_exercise_7',\n",
        "       'text_exercise_8', 'text_exercise_9', 'text_exercise_10',\n",
        "       'text_exercise_11', 'text_exercise_12', 'text_exercise_13',\n",
        "       'text_exercise_14', 'text_exercise_15', 'text_exercise_16',\n",
        "       'text_exercise_17', 'text_exercise_18', 'text_exercise_19',\n",
        "       'text_exercise_final', 'super', \"label\"])\n",
        "frames1 = [L_cluster_verified_super, feat_full]\n",
        "out1 = pd.concat(frames1, axis=1, ignore_index=True)\n",
        "out1.head()"
      ],
      "metadata": {
        "id": "iGz4aEDDBlDN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out1.rename(columns={0 : 'Unnamed: 0', 1 : 'response_id', 2 : 'rating_chooses_appropriate_action',\n",
        "       3 : 'rating_commits_to_action', 4 : 'rating_gathers_information',\n",
        "       5 : 'rating_identifies_issues_opportunities',\n",
        "       6 : 'rating_interprets_information', 7 : 'rating_involves_others',\n",
        "       8 : 'rating_decision_making_final_score', 9 : 'text_exercise_4',\n",
        "       10 : 'text_exercise_5', 11 : 'text_exercise_6', 12 : 'text_exercise_7',\n",
        "       13 : 'text_exercise_8', 14 : 'text_exercise_9', 15 : 'text_exercise_10',\n",
        "       16 : 'text_exercise_11', 17 : 'text_exercise_12', 18 : 'text_exercise_13',\n",
        "       19 : 'text_exercise_14', 20 : 'text_exercise_15', 21 : 'text_exercise_16',\n",
        "       22 : 'text_exercise_17', 23 : 'text_exercise_18', 24 : 'text_exercise_19',\n",
        "       25 : 'text_exercise_final', 26 : 'super', 27 : 'label'}, inplace=True)\n",
        "\n",
        "#out.columns =['participant', 'transcript', 'r1_hd9']\n",
        "out1.to_csv('L_cluster_verified_super_w_distiblert_full_text_encoding_truly_clean_text_w_splits_FINAL_TEST_SET.csv')\n",
        "out1.head()"
      ],
      "metadata": {
        "id": "vIQH_551BoMr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# still distilbert embeddings but for S_cluster below here \n",
        "S_cluster_verified_super = pd.read_csv(\"/content/S_cluster_truly_correct_spelling_splits_cleaned_text_FINAL_TEST_SET.csv\")\n",
        "\n",
        "print(S_cluster_verified_super.iloc[0,0])"
      ],
      "metadata": {
        "id": "nGPyKc22C91b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized1 = S_cluster_verified_super['super'].apply((lambda x: tokenizer.encode(x, padding=True, truncation=True, add_special_tokens=True)))"
      ],
      "metadata": {
        "id": "TwnWIT00DAce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = 0\n",
        "for i in tokenized1.values:\n",
        "    if len(i) > max_len:\n",
        "        max_len = len(i)\n",
        "\n",
        "padded1 = np.array([i + [0]*(max_len-len(i)) for i in tokenized1.values])\n",
        "\n",
        "np.array(padded1).shape"
      ],
      "metadata": {
        "id": "O3XmKxA5DB-Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attention_mask1 = np.where(padded1 != 0, 1, 0)\n",
        "attention_mask1.shape"
      ],
      "metadata": {
        "id": "sAH9fQraDEIv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(S_cluster_verified_super))"
      ],
      "metadata": {
        "id": "gS30YOiYDKv6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids1 = torch.tensor(np.array(padded1[0:159]))\n",
        "\n",
        "with torch.no_grad():\n",
        "    last_hidden_states1 = model(input_ids1)"
      ],
      "metadata": {
        "id": "jRjQ3ptdDMnK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features1 = last_hidden_states1[0][:,0,:].numpy()"
      ],
      "metadata": {
        "id": "oiCpG1m2DNXC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids2 = torch.tensor(np.array(padded1[159:318]))\n",
        "\n",
        "with torch.no_grad():\n",
        "    last_hidden_states2 = model(input_ids2)"
      ],
      "metadata": {
        "id": "yTaaNxkwDPBu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features2 = last_hidden_states2[0][:,0,:].numpy()"
      ],
      "metadata": {
        "id": "xbt4VeSaDQ0S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features_full = np.concatenate((features1, features2),axis = 0)"
      ],
      "metadata": {
        "id": "TS9JOsZqDSZA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(features_full))"
      ],
      "metadata": {
        "id": "t5NkMSV1DT6I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(S_cluster_verified_super.head())"
      ],
      "metadata": {
        "id": "DHhVM927DXDU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cols = S_cluster_verified_super.axes[1]\n",
        "\n",
        "print(cols)\n",
        "print(len(cols))"
      ],
      "metadata": {
        "id": "ubhcxhnLDcFZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feat_full = pd.DataFrame(data=features_full)"
      ],
      "metadata": {
        "id": "ekz1MMyqDXKz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "S_cluster_verified_super = DataFrame (S_cluster_verified_super,columns=['Unnamed: 0', 'response_id','rating_chooses_appropriate_action',\n",
        "       'rating_commits_to_action', 'rating_gathers_information',\n",
        "       'rating_identifies_issues_opportunities',\n",
        "       'rating_interprets_information', 'rating_involves_others',\n",
        "       'rating_decision_making_final_score', 'text_exercise_4',\n",
        "       'text_exercise_5', 'text_exercise_6', 'text_exercise_7',\n",
        "       'text_exercise_8', 'text_exercise_9', 'text_exercise_10',\n",
        "       'text_exercise_11', 'text_exercise_12', 'text_exercise_13',\n",
        "       'text_exercise_14', 'text_exercise_15', 'text_exercise_16',\n",
        "       'text_exercise_17', 'text_exercise_18', 'text_exercise_19',\n",
        "       'text_exercise_final', 'super', \"label\"])\n",
        "frames1 = [S_cluster_verified_super, feat_full]\n",
        "out1 = pd.concat(frames1, axis=1, ignore_index=True)\n",
        "out1.head()"
      ],
      "metadata": {
        "id": "-iLTqKpRDedr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out1.rename(columns={0 : 'Unnamed: 0', 1 : 'response_id', 2 : 'rating_chooses_appropriate_action',\n",
        "       3 : 'rating_commits_to_action', 4 : 'rating_gathers_information',\n",
        "       5 : 'rating_identifies_issues_opportunities',\n",
        "       6 : 'rating_interprets_information', 7 : 'rating_involves_others',\n",
        "       8 : 'rating_decision_making_final_score', 9 : 'text_exercise_4',\n",
        "       10 : 'text_exercise_5', 11 : 'text_exercise_6', 12 : 'text_exercise_7',\n",
        "       13 : 'text_exercise_8', 14 : 'text_exercise_9', 15 : 'text_exercise_10',\n",
        "       16 : 'text_exercise_11', 17 : 'text_exercise_12', 18 : 'text_exercise_13',\n",
        "       19 : 'text_exercise_14', 20 : 'text_exercise_15', 21 : 'text_exercise_16',\n",
        "       22 : 'text_exercise_17', 23 : 'text_exercise_18', 24 : 'text_exercise_19',\n",
        "       25 : 'text_exercise_final', 26 : 'super', 27 : 'label'}, inplace=True)\n",
        "\n",
        "out1.to_csv('S_cluster_verified_super_w_distiblert_full_text_encoding_clean_text_w_splits_FINAL_TEST_SET.csv')\n",
        "out1.head()"
      ],
      "metadata": {
        "id": "HQa7pt8iDjVz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# still distilbert embeddings but for T_cluster below here \n",
        "T_cluster_verified_super = pd.read_csv(\"/content/T_cluster_truly_correct_spelling_splits_cleaned_text_FINAL_TEST_SET.csv\")\n",
        "\n",
        "print(T_cluster_verified_super.iloc[0,0])"
      ],
      "metadata": {
        "id": "EZvk_W7BDkHX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(T_cluster_verified_super))"
      ],
      "metadata": {
        "id": "oM4UH8IZDnpg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized1 = T_cluster_verified_super['super'].apply((lambda x: tokenizer.encode(x, padding=True, truncation=True, add_special_tokens=True)))"
      ],
      "metadata": {
        "id": "SjzshyNdDrBg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = 0\n",
        "for i in tokenized1.values:\n",
        "    if len(i) > max_len:\n",
        "        max_len = len(i)\n",
        "\n",
        "padded1 = np.array([i + [0]*(max_len-len(i)) for i in tokenized1.values])\n",
        "\n",
        "np.array(padded1).shape"
      ],
      "metadata": {
        "id": "Y42JQW-KDtvG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attention_mask1 = np.where(padded1 != 0, 1, 0)\n",
        "attention_mask1.shape"
      ],
      "metadata": {
        "id": "B-HSdkMtDvtM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(T_cluster_verified_super))"
      ],
      "metadata": {
        "id": "0o1tWCYNDxTq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids1 = torch.tensor(np.array(padded1[0:23]))\n",
        "\n",
        "with torch.no_grad():\n",
        "    last_hidden_states1 = model(input_ids1)"
      ],
      "metadata": {
        "id": "D2kt47a6Dxzo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features1 = last_hidden_states1[0][:,0,:].numpy()"
      ],
      "metadata": {
        "id": "K-9jODliD0HQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids2 = torch.tensor(np.array(padded1[23:46]))\n",
        "\n",
        "with torch.no_grad():\n",
        "    last_hidden_states2 = model(input_ids2)"
      ],
      "metadata": {
        "id": "IYJ-Ig3uD1sf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features2 = last_hidden_states2[0][:,0,:].numpy()"
      ],
      "metadata": {
        "id": "dJoIMEoxD3ir"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids3 = torch.tensor(np.array(padded1[46:69]))\n",
        "\n",
        "with torch.no_grad():\n",
        "    last_hidden_states3 = model(input_ids3)\n",
        "\n",
        "features3 = last_hidden_states3[0][:,0,:].numpy()"
      ],
      "metadata": {
        "id": "sYQJ14ZwCuL3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids4 = torch.tensor(np.array(padded1[69:92]))\n",
        "\n",
        "with torch.no_grad():\n",
        "    last_hidden_states4 = model(input_ids4)\n",
        "\n",
        "features4 = last_hidden_states4[0][:,0,:].numpy()"
      ],
      "metadata": {
        "id": "2szjHV8sC57s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids5 = torch.tensor(np.array(padded1[92:115]))\n",
        "\n",
        "with torch.no_grad():\n",
        "    last_hidden_states5 = model(input_ids5)\n",
        "\n",
        "features5 = last_hidden_states5[0][:,0,:].numpy()"
      ],
      "metadata": {
        "id": "DNYDNW_qC6iJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids6 = torch.tensor(np.array(padded1[115:138]))\n",
        "\n",
        "with torch.no_grad():\n",
        "    last_hidden_states6 = model(input_ids6)\n",
        "\n",
        "features6 = last_hidden_states6[0][:,0,:].numpy()"
      ],
      "metadata": {
        "id": "lMlMv2f2C6r4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids7 = torch.tensor(np.array(padded1[138:161]))\n",
        "\n",
        "with torch.no_grad():\n",
        "    last_hidden_states7 = model(input_ids7)\n",
        "\n",
        "features7 = last_hidden_states7[0][:,0,:].numpy()"
      ],
      "metadata": {
        "id": "fR-UItZIC62h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids8 = torch.tensor(np.array(padded1[161:184]))\n",
        "\n",
        "with torch.no_grad():\n",
        "    last_hidden_states8 = model(input_ids8)\n",
        "\n",
        "features8 = last_hidden_states8[0][:,0,:].numpy()"
      ],
      "metadata": {
        "id": "96bH0iTqC7AJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids9 = torch.tensor(np.array(padded1[184:207]))\n",
        "\n",
        "with torch.no_grad():\n",
        "    last_hidden_states9 = model(input_ids9)\n",
        "\n",
        "features9 = last_hidden_states9[0][:,0,:].numpy()"
      ],
      "metadata": {
        "id": "FlaG0o6RC7K_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids10 = torch.tensor(np.array(padded1[207:230]))\n",
        "\n",
        "with torch.no_grad():\n",
        "    last_hidden_states10 = model(input_ids10)\n",
        "\n",
        "features10 = last_hidden_states10[0][:,0,:].numpy()"
      ],
      "metadata": {
        "id": "e5CLoQEpC7Um"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids11 = torch.tensor(np.array(padded1[230:253]))\n",
        "\n",
        "with torch.no_grad():\n",
        "    last_hidden_states11 = model(input_ids11)\n",
        "\n",
        "features11 = last_hidden_states11[0][:,0,:].numpy()"
      ],
      "metadata": {
        "id": "Su-mzMz0C7iw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features_full = np.concatenate((features1, features2, features3, features4, features5, features6, features7, features8, features9, features10, features11),axis = 0)"
      ],
      "metadata": {
        "id": "MhPx7ktmD6cd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(features_full))"
      ],
      "metadata": {
        "id": "S-zIw26DD7Ah"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cols = T_cluster_verified_super.axes[1]\n",
        "\n",
        "print(cols)\n",
        "print(len(cols))"
      ],
      "metadata": {
        "id": "xy10KS9HD-N5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feat_full = pd.DataFrame(data=features_full)"
      ],
      "metadata": {
        "id": "c1HA2KwqEA9s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "T_cluster_verified_super = DataFrame (T_cluster_verified_super,columns=['Unnamed: 0', 'response_id','rating_chooses_appropriate_action',\n",
        "       'rating_commits_to_action', 'rating_gathers_information',\n",
        "       'rating_identifies_issues_opportunities',\n",
        "       'rating_interprets_information', 'rating_involves_others',\n",
        "       'rating_decision_making_final_score', 'text_exercise_4',\n",
        "       'text_exercise_5', 'text_exercise_6', 'text_exercise_7',\n",
        "       'text_exercise_8', 'text_exercise_9', 'text_exercise_10',\n",
        "       'text_exercise_11', 'text_exercise_12', 'text_exercise_13',\n",
        "       'text_exercise_14', 'text_exercise_15', 'text_exercise_16',\n",
        "       'text_exercise_17', 'text_exercise_18', 'text_exercise_19',\n",
        "       'text_exercise_final', 'super', \"label\"])\n",
        "frames1 = [T_cluster_verified_super, feat_full]\n",
        "out1 = pd.concat(frames1, axis=1, ignore_index=True)\n",
        "out1.head()"
      ],
      "metadata": {
        "id": "SY0ixGKBEC84"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out1.rename(columns={0 : 'Unnamed: 0', 1 : 'response_id', 2 : 'rating_chooses_appropriate_action',\n",
        "       3 : 'rating_commits_to_action', 4 : 'rating_gathers_information',\n",
        "       5 : 'rating_identifies_issues_opportunities',\n",
        "       6 : 'rating_interprets_information', 7 : 'rating_involves_others',\n",
        "       8 : 'rating_decision_making_final_score', 9 : 'text_exercise_4',\n",
        "       10 : 'text_exercise_5', 11 : 'text_exercise_6', 12 : 'text_exercise_7',\n",
        "       13 : 'text_exercise_8', 14 : 'text_exercise_9', 15 : 'text_exercise_10',\n",
        "       16 : 'text_exercise_11', 17 : 'text_exercise_12', 18 : 'text_exercise_13',\n",
        "       19 : 'text_exercise_14', 20 : 'text_exercise_15', 21 : 'text_exercise_16',\n",
        "       22 : 'text_exercise_17', 23 : 'text_exercise_18', 24 : 'text_exercise_19',\n",
        "       25 : 'text_exercise_final', 26 : 'super', 27 : 'label'}, inplace=True)\n",
        "\n",
        "#out.columns =['participant', 'transcript', 'r1_hd9']\n",
        "out1.to_csv('T_cluster_verified_super_w_distiblert_full_text_encoding_clean_text_w_splits_FINAL_TEST_SET.csv')\n",
        "out1.head()"
      ],
      "metadata": {
        "id": "XkS_ZlMXEF36"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Changing the column names of the embeddings to prevents errors when adding cosine similarity columns, as they both were simply X1, X2, etc:**"
      ],
      "metadata": {
        "id": "ACFbDrnnOzmy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "\n",
        "L_cluster_verified_super_w_distiblert_full_text_encoding = read.csv(\"/content/L_cluster_verified_super_w_distiblert_full_text_encoding_truly_clean_text_w_splits_FINAL_TEST_SET.csv\")\n",
        "\n",
        "S_cluster_verified_super_w_distiblert_full_text_encoding = read.csv(\"/content/S_cluster_verified_super_w_distiblert_full_text_encoding_clean_text_w_splits_FINAL_TEST_SET.csv\")\n",
        "\n",
        "T_cluster_verified_super_w_distiblert_full_text_encoding = read.csv(\"/content/T_cluster_verified_super_w_distiblert_full_text_encoding_clean_text_w_splits_FINAL_TEST_SET.csv\")\n",
        "\n",
        "\n",
        "colnames(T_cluster_verified_super_w_distiblert_full_text_encoding)[1:20]\n",
        "\n",
        "colnames(L_cluster_verified_super_w_distiblert_full_text_encoding)[1] = 'unnamed'\n",
        "colnames(S_cluster_verified_super_w_distiblert_full_text_encoding)[1] = 'unnamed'\n",
        "colnames(T_cluster_verified_super_w_distiblert_full_text_encoding)[1] = 'unnamed'\n",
        "\n",
        "colnames(L_cluster_verified_super_w_distiblert_full_text_encoding)[2] = 'unnamedtwo'\n",
        "colnames(S_cluster_verified_super_w_distiblert_full_text_encoding)[2] = 'unnamedtwo'\n",
        "colnames(T_cluster_verified_super_w_distiblert_full_text_encoding)[2] = 'unnamedtwo'\n",
        "\n",
        "L_cluster_verified_super_w_distiblert_full_text_encoding = subset(L_cluster_verified_super_w_distiblert_full_text_encoding, select = -c(unnamed, unnamedtwo))\n",
        "\n",
        "S_cluster_verified_super_w_distiblert_full_text_encoding = subset(S_cluster_verified_super_w_distiblert_full_text_encoding, select = -c(unnamed, unnamedtwo))\n",
        "\n",
        "T_cluster_verified_super_w_distiblert_full_text_encoding = subset(T_cluster_verified_super_w_distiblert_full_text_encoding, select = -c(unnamed, unnamedtwo))\n",
        "\n",
        "\n",
        "colnames(L_cluster_verified_super_w_distiblert_full_text_encoding)[1:40]\n",
        "\n",
        "# Changing names of columns that start with x so we can add new columns that start with x \n",
        "i = 28\n",
        "while(i <= ncol(L_cluster_verified_super_w_distiblert_full_text_encoding))\n",
        "{\n",
        "  prev = colnames(L_cluster_verified_super_w_distiblert_full_text_encoding)[i]\n",
        "  curr = str_c(\"distilbert_embedding\", prev, sep = \"_\")\n",
        "  colnames(L_cluster_verified_super_w_distiblert_full_text_encoding)[i] = curr\n",
        "  colnames(S_cluster_verified_super_w_distiblert_full_text_encoding)[i] = curr\n",
        "  colnames(T_cluster_verified_super_w_distiblert_full_text_encoding)[i] = curr\n",
        "  i = i + 1\n",
        "}\n",
        "\n",
        "colnames(L_cluster_verified_super_w_distiblert_full_text_encoding)[1:40]\n",
        "colnames(S_cluster_verified_super_w_distiblert_full_text_encoding)[1:40]\n",
        "colnames(T_cluster_verified_super_w_distiblert_full_text_encoding)[1:40]\n",
        "\n",
        "# For FINAL_TEST_SET:\n",
        "write.csv(L_cluster_verified_super_w_distiblert_full_text_encoding, file = \"L_cluster_verified_super_w_distiblert_full_text_encoding_proper_clean_text_w_splits_FINAL_TEST_SET.csv\")\n",
        "write.csv(S_cluster_verified_super_w_distiblert_full_text_encoding, file = \"S_cluster_verified_super_w_distiblert_full_text_encoding_proper_clean_text_w_splits_FINAL_TEST_SET.csv\")\n",
        "write.csv(T_cluster_verified_super_w_distiblert_full_text_encoding, file = \"T_cluster_verified_super_w_distiblert_full_text_encoding_proper_clean_text_w_splits_FINAL_TEST_SET.csv\")\n"
      ],
      "metadata": {
        "id": "FjXG3Ztym7aH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Using the generated distilbert embeddings vector to get cosine similarity vs each other participant's vector. Again, appends n columns of cosine similarity scores, where n is the number of particpants in that group.**"
      ],
      "metadata": {
        "id": "buiNcAKTL_1I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.model_selection import train_test_split\n",
        "import sys\n",
        "from sklearn.linear_model import Ridge\n",
        "import time\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "# import torch\n",
        "\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.preprocessing import scale, StandardScaler\n",
        "from sklearn.linear_model import Ridge, RidgeCV, Lasso, LassoCV\n",
        "\n",
        "\n",
        "# Set pandas options to allow more printing rows/columns\n",
        "pd.set_option(\"display.max_rows\", 4000)\n",
        "pd.set_option(\"display.max_columns\", 4000)\n",
        "\n",
        "super_cos_sim_df = pd.read_csv(\"/content/L_cluster_verified_super_w_distiblert_full_text_encoding_proper_clean_text_w_splits_FINAL_TEST_SET.csv\")\n",
        "\n",
        "cols_1 = super_cos_sim_df.axes[1]\n",
        "print(cols_1)\n",
        "print(len(cols_1))\n",
        "print()\n",
        "print(super_cos_sim_df.iloc[0,28])\n",
        "\n",
        "super_cos_sim_df = pd.concat([super_cos_sim_df, pd.DataFrame(cosine_similarity(super_cos_sim_df.iloc[:,28:]))], axis=1)\n",
        "\n",
        "super_cos_sim_df.columns = super_cos_sim_df.columns.astype(str)\n",
        "\n",
        "for i in range(28,796):\n",
        "    drop_string = f\"distilbert_embedding_X{i}\"\n",
        "    super_cos_sim_df = super_cos_sim_df.drop([drop_string], axis=1)\n",
        "\n",
        "super_cos_sim_df.to_csv('L_cluster_distiblert_cos_similarties_clean_text_w_splits_FINAL_TEST_SET.csv',index=False)"
      ],
      "metadata": {
        "id": "sfOBNxmQlsk6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "super_cos_sim_df = pd.read_csv(\"/content/S_cluster_verified_super_w_distiblert_full_text_encoding_proper_clean_text_w_splits_FINAL_TEST_SET.csv\")\n",
        "\n",
        "cols_1 = super_cos_sim_df.axes[1]\n",
        "print(cols_1)\n",
        "print(len(cols_1))\n",
        "print()\n",
        "print(super_cos_sim_df.iloc[0,28])\n",
        "\n",
        "super_cos_sim_df = pd.concat([super_cos_sim_df, pd.DataFrame(cosine_similarity(super_cos_sim_df.iloc[:,28:]))], axis=1)\n",
        "\n",
        "super_cos_sim_df.columns = super_cos_sim_df.columns.astype(str)\n",
        "\n",
        "for i in range(28,796):\n",
        "    drop_string = f\"distilbert_embedding_X{i}\"\n",
        "    super_cos_sim_df = super_cos_sim_df.drop([drop_string], axis=1)\n",
        "\n",
        "super_cos_sim_df.to_csv('S_cluster_distiblert_cos_similarties_clean_text_w_splits_FINAL_TEST_SET.csv',index=False)"
      ],
      "metadata": {
        "id": "c8adttGMl3rA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "super_cos_sim_df = pd.read_csv(\"/content/T_cluster_verified_super_w_distiblert_full_text_encoding_proper_clean_text_w_splits_FINAL_TEST_SET.csv\")\n",
        "\n",
        "cols_1 = super_cos_sim_df.axes[1]\n",
        "print(cols_1)\n",
        "print(len(cols_1))\n",
        "print()\n",
        "print(super_cos_sim_df.iloc[0,28])\n",
        "\n",
        "super_cos_sim_df = pd.concat([super_cos_sim_df, pd.DataFrame(cosine_similarity(super_cos_sim_df.iloc[:,28:]))], axis=1)\n",
        "\n",
        "super_cos_sim_df.columns = super_cos_sim_df.columns.astype(str)\n",
        "\n",
        "for i in range(28,796):\n",
        "    drop_string = f\"distilbert_embedding_X{i}\"\n",
        "    super_cos_sim_df = super_cos_sim_df.drop([drop_string], axis=1)\n",
        "\n",
        "super_cos_sim_df.to_csv('T_cluster_distiblert_cos_similarties_clean_text_w_splits_FINAL_TEST_SET.csv',index=False)"
      ],
      "metadata": {
        "id": "tl4IipBXo-mM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "\n",
        "# Now reading those in: \n",
        "L_cluster_distiblert_cos_similarties = read.csv(\"/content/L_cluster_distiblert_cos_similarties_clean_text_w_splits_FINAL_TEST_SET.csv\")\n",
        "S_cluster_distiblert_cos_similarties = read.csv(\"/content/S_cluster_distiblert_cos_similarties_clean_text_w_splits_FINAL_TEST_SET.csv\")\n",
        "T_cluster_distiblert_cos_similarties = read.csv(\"/content/T_cluster_distiblert_cos_similarties_clean_text_w_splits_FINAL_TEST_SET.csv\")\n",
        "\n",
        "\n",
        "colnames(L_cluster_distiblert_cos_similarties)[1:40]\n",
        "\n",
        "colnames(L_cluster_distiblert_cos_similarties)[1] = \"unnamed\"\n",
        "colnames(S_cluster_distiblert_cos_similarties)[1] = \"unnamed\"\n",
        "colnames(T_cluster_distiblert_cos_similarties)[1] = \"unnamed\"\n",
        "\n",
        "L_cluster_distiblert_cos_similarties = subset(L_cluster_distiblert_cos_similarties, select = -c(unnamed))\n",
        "S_cluster_distiblert_cos_similarties = subset(S_cluster_distiblert_cos_similarties, select = -c(unnamed))\n",
        "T_cluster_distiblert_cos_similarties = subset(T_cluster_distiblert_cos_similarties, select = -c(unnamed))\n",
        "\n",
        "\n",
        "colnames(L_cluster_distiblert_cos_similarties)[1:40]\n",
        "colnames(S_cluster_distiblert_cos_similarties)[1:40]\n",
        "colnames(T_cluster_distiblert_cos_similarties)[1:40]\n",
        "\n",
        "# Changing colnames that start w X so we can add TFIDF without issue \n",
        "i = 28\n",
        "while(i <= ncol(L_cluster_distiblert_cos_similarties))\n",
        "{\n",
        "  prev = colnames(L_cluster_distiblert_cos_similarties)[i]\n",
        "  curr = str_c(\"distilbert_cosine_similarities\", prev, sep = \"_\")\n",
        "  colnames(L_cluster_distiblert_cos_similarties)[i] = curr\n",
        "  i = i + 1\n",
        "}\n",
        "\n",
        "i = 28\n",
        "while(i <= ncol(S_cluster_distiblert_cos_similarties))\n",
        "{\n",
        "  prev = colnames(S_cluster_distiblert_cos_similarties)[i]\n",
        "  curr = str_c(\"distilbert_cosine_similarities\", prev, sep = \"_\")\n",
        "  colnames(S_cluster_distiblert_cos_similarties)[i] = curr\n",
        "  i = i + 1\n",
        "}\n",
        "\n",
        "i = 28\n",
        "while(i <= ncol(T_cluster_distiblert_cos_similarties))\n",
        "{\n",
        "  prev = colnames(T_cluster_distiblert_cos_similarties)[i]\n",
        "  curr = str_c(\"distilbert_cosine_similarities\", prev, sep = \"_\")\n",
        "  colnames(T_cluster_distiblert_cos_similarties)[i] = curr\n",
        "  i = i + 1\n",
        "}\n",
        "\n",
        "# now I need to get rid of everything but the response Id and embeddings, and merge w b_t for each cluster \n",
        "\n",
        "L_cluster_distiblert_cos_similarties = subset(L_cluster_distiblert_cos_similarties, select = -c(\n",
        "  rating_chooses_appropriate_action,\n",
        "  rating_commits_to_action,\n",
        "  rating_gathers_information,\n",
        "  rating_identifies_issues_opportunities,\n",
        "  rating_interprets_information,\n",
        "  rating_involves_others,\n",
        "  rating_decision_making_final_score,\n",
        "  text_exercise_4,\n",
        "  text_exercise_5,\n",
        "  text_exercise_6,\n",
        "  text_exercise_7,\n",
        "  text_exercise_8,\n",
        "  text_exercise_9,\n",
        "  text_exercise_10,\n",
        "  text_exercise_11,\n",
        "  text_exercise_12,\n",
        "  text_exercise_13,\n",
        "  text_exercise_14,\n",
        "  text_exercise_15,\n",
        "  text_exercise_16,\n",
        "  text_exercise_17,\n",
        "  text_exercise_18,\n",
        "  text_exercise_19,\n",
        "  text_exercise_final,\n",
        "  super,\n",
        "  label\n",
        "))\n",
        "\n",
        "S_cluster_distiblert_cos_similarties = subset(S_cluster_distiblert_cos_similarties, select = -c(\n",
        "  rating_chooses_appropriate_action,\n",
        "  rating_commits_to_action,\n",
        "  rating_gathers_information,\n",
        "  rating_identifies_issues_opportunities,\n",
        "  rating_interprets_information,\n",
        "  rating_involves_others,\n",
        "  rating_decision_making_final_score,\n",
        "  text_exercise_4,\n",
        "  text_exercise_5,\n",
        "  text_exercise_6,\n",
        "  text_exercise_7,\n",
        "  text_exercise_8,\n",
        "  text_exercise_9,\n",
        "  text_exercise_10,\n",
        "  text_exercise_11,\n",
        "  text_exercise_12,\n",
        "  text_exercise_13,\n",
        "  text_exercise_14,\n",
        "  text_exercise_15,\n",
        "  text_exercise_16,\n",
        "  text_exercise_17,\n",
        "  text_exercise_18,\n",
        "  text_exercise_19,\n",
        "  text_exercise_final,\n",
        "  super,\n",
        "  label\n",
        "))\n",
        "\n",
        "T_cluster_distiblert_cos_similarties = subset(T_cluster_distiblert_cos_similarties, select = -c(\n",
        "  rating_chooses_appropriate_action,\n",
        "  rating_commits_to_action,\n",
        "  rating_gathers_information,\n",
        "  rating_identifies_issues_opportunities,\n",
        "  rating_interprets_information,\n",
        "  rating_involves_others,\n",
        "  rating_decision_making_final_score,\n",
        "  text_exercise_4,\n",
        "  text_exercise_5,\n",
        "  text_exercise_6,\n",
        "  text_exercise_7,\n",
        "  text_exercise_8,\n",
        "  text_exercise_9,\n",
        "  text_exercise_10,\n",
        "  text_exercise_11,\n",
        "  text_exercise_12,\n",
        "  text_exercise_13,\n",
        "  text_exercise_14,\n",
        "  text_exercise_15,\n",
        "  text_exercise_16,\n",
        "  text_exercise_17,\n",
        "  text_exercise_18,\n",
        "  text_exercise_19,\n",
        "  text_exercise_final,\n",
        "  super,\n",
        "  label\n",
        "))\n"
      ],
      "metadata": {
        "id": "Da728Wji2X2x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Merging the unigram/bigram cosine similarity dataframe with the distilbert vector cosine similarity dataframe. End up with a dataframe with the 28 original columns and 2n more columns, where n is the number of participants in each group (2n because it now has n cosine similarity scores for unigrams/bigrams vectors and n scores for distilbert vectors):**"
      ],
      "metadata": {
        "id": "Q0HhF1LKMzv0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "\n",
        "L_cluster_w_cos_sim_from_distilbert_and_bigrams_truly_clean_w_splits = merge(L_cluster_verified_super_w_bigrams_cos_sim, L_cluster_distiblert_cos_similarties, on = 'response_id')\n",
        "S_cluster_w_cos_sim_from_distilbert_and_bigrams_truly_clean_w_splits = merge(S_cluster_verified_super_w_bigrams_cos_sim, S_cluster_distiblert_cos_similarties, on = 'response_id')\n",
        "T_cluster_w_cos_sim_from_distilbert_and_bigrams_truly_clean_w_splits = merge(T_cluster_verified_super_w_bigrams_cos_sim, T_cluster_distiblert_cos_similarties, on = 'response_id')\n",
        "\n",
        "\n",
        "train_L_cluster_w_cos_sim_from_distilbert_and_bigrams_truly_clean_w_splits = subset(L_cluster_w_cos_sim_from_distilbert_and_bigrams_truly_clean_w_splits, subset = L_cluster_w_cos_sim_from_distilbert_and_bigrams_truly_clean_w_splits$label == 'train')\n",
        "dev_L_cluster_w_cos_sim_from_distilbert_and_bigrams_truly_clean_w_splits = subset(L_cluster_w_cos_sim_from_distilbert_and_bigrams_truly_clean_w_splits, subset = L_cluster_w_cos_sim_from_distilbert_and_bigrams_truly_clean_w_splits$label == 'dev')\n",
        "\n",
        "train_S_cluster_w_cos_sim_from_distilbert_and_bigrams_truly_clean_w_splits = subset(S_cluster_w_cos_sim_from_distilbert_and_bigrams_truly_clean_w_splits, subset = S_cluster_w_cos_sim_from_distilbert_and_bigrams_truly_clean_w_splits$label == 'train')\n",
        "dev_S_cluster_w_cos_sim_from_distilbert_and_bigrams_truly_clean_w_splits = subset(S_cluster_w_cos_sim_from_distilbert_and_bigrams_truly_clean_w_splits, subset = S_cluster_w_cos_sim_from_distilbert_and_bigrams_truly_clean_w_splits$label == 'dev')\n",
        "\n",
        "train_T_cluster_w_cos_sim_from_distilbert_and_bigrams_truly_clean_w_splits = subset(T_cluster_w_cos_sim_from_distilbert_and_bigrams_truly_clean_w_splits, subset = T_cluster_w_cos_sim_from_distilbert_and_bigrams_truly_clean_w_splits$label == 'train')\n",
        "dev_T_cluster_w_cos_sim_from_distilbert_and_bigrams_truly_clean_w_splits = subset(T_cluster_w_cos_sim_from_distilbert_and_bigrams_truly_clean_w_splits, subset = T_cluster_w_cos_sim_from_distilbert_and_bigrams_truly_clean_w_splits$label == 'dev')\n",
        "\n",
        "write.csv(train_L_cluster_w_cos_sim_from_distilbert_and_bigrams_truly_clean_w_splits, file = \"train_L_cluster_w_cos_sim_from_distilbert_and_bigrams_truly_clean_w_splits_FINAL_TEST_SET.csv\")\n",
        "write.csv(train_S_cluster_w_cos_sim_from_distilbert_and_bigrams_truly_clean_w_splits, file = \"train_S_cluster_w_cos_sim_from_distilbert_and_bigrams_truly_clean_w_splits_FINAL_TEST_SET.csv\")\n",
        "write.csv(train_T_cluster_w_cos_sim_from_distilbert_and_bigrams_truly_clean_w_splits, file = \"train_T_cluster_w_cos_sim_from_distilbert_and_bigrams_truly_clean_w_splits_FINAL_TEST_SET.csv\")\n",
        "\n",
        "write.csv(dev_L_cluster_w_cos_sim_from_distilbert_and_bigrams_truly_clean_w_splits, file = \"dev_L_cluster_w_cos_sim_from_distilbert_and_bigrams_truly_clean_w_splits_FINAL_TEST_SET.csv\")\n",
        "write.csv(dev_S_cluster_w_cos_sim_from_distilbert_and_bigrams_truly_clean_w_splits, file = \"dev_S_cluster_w_cos_sim_from_distilbert_and_bigrams_truly_clean_w_splits_FINAL_TEST_SET.csv\")\n",
        "write.csv(dev_T_cluster_w_cos_sim_from_distilbert_and_bigrams_truly_clean_w_splits, file = \"dev_T_cluster_w_cos_sim_from_distilbert_and_bigrams_truly_clean_w_splits_FINAL_TEST_SET.csv\")\n",
        "\n",
        "\n",
        "# now generate predictions in python scripts:"
      ],
      "metadata": {
        "id": "u2Ng5oYuEgaM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Using the cosine similarity columns as predictors in machine learning algorithms. Chose algorithms based on which produced highest r scores for each category and highest mean_r scores (commented out was code used for testing/determining which algorithms to use in final output):**"
      ],
      "metadata": {
        "id": "sAhCUgWhNawe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.model_selection import train_test_split\n",
        "import sys\n",
        "from sklearn.linear_model import Ridge\n",
        "import time\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "# import torch\n",
        "from sklearn.linear_model import Ridge, RidgeCV, Lasso, LassoCV\n",
        "from sklearn.preprocessing import scale\n",
        "from sklearn.preprocessing import scale, StandardScaler\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "\n",
        "# Set pandas options to allow more printing rows/columns\n",
        "pd.set_option(\"display.max_rows\", 4000)\n",
        "pd.set_option(\"display.max_columns\", 4000)\n",
        "\n",
        "train_pub_df = pd.read_csv(\"/content/train_L_cluster_w_cos_sim_from_distilbert_and_bigrams_truly_clean_w_splits_FINAL_TEST_SET.csv\")\n",
        "dev_pub_df = pd.read_csv(\"/content/dev_L_cluster_w_cos_sim_from_distilbert_and_bigrams_truly_clean_w_splits_FINAL_TEST_SET.csv\")\n",
        "\n",
        "\n",
        "# computing number of columns\n",
        "cols = len(train_pub_df.axes[1])\n",
        "print(cols)\n",
        "\n",
        "\n",
        "cols = train_pub_df.axes[1]\n",
        "print(cols)\n",
        "\n",
        "\n",
        "print('got that ')\n",
        "X = train_pub_df.drop(['Unnamed: 0', 'response_id', 'super', 'rating_chooses_appropriate_action','rating_commits_to_action','rating_gathers_information','rating_identifies_issues_opportunities','rating_interprets_information', 'rating_involves_others', \"rating_decision_making_final_score\", 'text_exercise_4',\n",
        "    'text_exercise_5',\n",
        "    'text_exercise_6',\n",
        "    'text_exercise_7',\n",
        "    \"text_exercise_8\",\n",
        "    \"text_exercise_9\",\n",
        "    \"text_exercise_10\",\n",
        "    \"text_exercise_11\",\n",
        "    \"text_exercise_12\",\n",
        "    \"text_exercise_13\",\n",
        "    \"text_exercise_14\",\n",
        "    \"text_exercise_15\",\n",
        "    \"text_exercise_16\",\n",
        "    \"text_exercise_17\",\n",
        "    \"text_exercise_18\",\n",
        "    \"text_exercise_19\",\n",
        "    \"text_exercise_final\", \n",
        "    'label'], axis=1)\n",
        "\n",
        "ys = train_pub_df[['rating_chooses_appropriate_action','rating_commits_to_action','rating_gathers_information','rating_identifies_issues_opportunities','rating_interprets_information', 'rating_involves_others', \"rating_decision_making_final_score\"]]\n",
        "\n",
        "cols = len(X.axes[1])\n",
        "print(cols)\n",
        "\n",
        "cols_div_3 = (cols) // 3 \n",
        "print(f\"{cols_div_3=}\")\n",
        "\n",
        "X_dev = dev_pub_df.drop(['Unnamed: 0', 'response_id', 'super', 'rating_chooses_appropriate_action','rating_commits_to_action','rating_gathers_information','rating_identifies_issues_opportunities','rating_interprets_information', 'rating_involves_others', \"rating_decision_making_final_score\", 'text_exercise_4',\n",
        "    'text_exercise_5',\n",
        "    'text_exercise_6',\n",
        "    'text_exercise_7',\n",
        "    \"text_exercise_8\",\n",
        "    \"text_exercise_9\",\n",
        "    \"text_exercise_10\",\n",
        "    \"text_exercise_11\",\n",
        "    \"text_exercise_12\",\n",
        "    \"text_exercise_13\",\n",
        "    \"text_exercise_14\",\n",
        "    \"text_exercise_15\",\n",
        "    \"text_exercise_16\",\n",
        "    \"text_exercise_17\",\n",
        "    \"text_exercise_18\",\n",
        "    \"text_exercise_19\",\n",
        "    \"text_exercise_final\", \n",
        "    \"label\"], axis=1)\n",
        "\n",
        "\n",
        "# ys = train_pub_df[[\"rating_decision_making_final_score\"]]\n",
        "\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,ys, test_size = 0.2 ,random_state= 42)\n",
        "\n",
        "def run_ridge(X_train, X_test, y_train, y_test, y_label, prediction_vector):\n",
        "    ridge = Ridge()\n",
        "    ridge.fit(X_train,y_train[y_label])\n",
        "    # test_preds = ridge.predict(X_test)\n",
        "    # test = pd.DataFrame(y_test[y_label])\n",
        "    # test['Pred_score'] = test_preds\n",
        "    # return test.corr().values[0][1]\n",
        "    dev_pred = ridge.predict(prediction_vector)\n",
        "    return dev_pred\n",
        "\n",
        "\n",
        "def run_rf(X_train, X_test, y_train, y_test, y_label, prediction_vector):\n",
        "    rf = RandomForestRegressor(max_depth=5, random_state=42, max_features=cols_div_3 + 1) #, max_features=9962 # or .333\n",
        "    rf.fit(X_train,np.ravel(y_train[y_label],order='C'))\n",
        "    # test_preds = rf.predict(X_test)\n",
        "    # test = pd.DataFrame(y_test[y_label])\n",
        "    # test['Pred_score'] = test_preds\n",
        "    # return test.corr().values[0][1]\n",
        "    dev_pred = rf.predict(prediction_vector)\n",
        "    return dev_pred\n",
        "\n",
        "def run_bag(X_train, X_test, y_train, y_test, y_label, prediction_vector):\n",
        "    rf = RandomForestRegressor(max_depth=5, random_state=42) #, max_features=9962 # or .333\n",
        "    rf.fit(X_train,np.ravel(y_train[y_label],order='C'))\n",
        "    # test_preds = rf.predict(X_test)\n",
        "    # test = pd.DataFrame(y_test[y_label])\n",
        "    # test['Pred_score'] = test_preds\n",
        "    # return test.corr().values[0][1]\n",
        "    dev_pred = rf.predict(prediction_vector)\n",
        "    return dev_pred\n",
        "\n",
        "\n",
        "def run_knn(X_train, X_test, y_train, y_test, y_label, prediction_vector):\n",
        "    knn = KNeighborsRegressor(n_neighbors=93, p=2, weights=\"distance\")\n",
        "    knn.fit(X_train,y_train[y_label])\n",
        "    # test_preds = knn.predict(X_test)\n",
        "    # test = pd.DataFrame(y_test[y_label])\n",
        "    # test['Pred_score'] = test_preds\n",
        "    # return test.corr().values[0][1]\n",
        "    dev_pred = knn.predict(prediction_vector)\n",
        "    return dev_pred\n",
        "\n",
        "\n",
        "def new_run_ridge(X_train, X_test, y_train, y_test, y_label, prediction_vector):\n",
        "    scaler = StandardScaler().set_output(transform=\"pandas\")\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "    X_test = scaler.fit_transform(X_test)\n",
        "    grid = 10 ** np.linspace(3,-2,100)\n",
        "    ridge_cv = RidgeCV(alphas=grid, scoring='neg_mean_squared_error')\n",
        "    ridge_cv.fit(X_train,y_train[y_label])\n",
        "    ridge_cv.alpha_\n",
        "    ridge5 = Ridge(alpha=ridge_cv.alpha_)\n",
        "    ridge5_fit = ridge5.fit(X_train,y_train[y_label])\n",
        "    # test_preds = ridge5_fit.predict(X_test)\n",
        "    # test = pd.DataFrame(y_test[y_label])\n",
        "    # test['Pred_score'] = test_preds\n",
        "    # return test.corr().values[0][1]\n",
        "    dev_pred = ridge5_fit.predict(prediction_vector)\n",
        "    return dev_pred\n",
        "\n",
        "\n",
        "def run_lasso(X_train, X_test, y_train, y_test, y_label, prediction_vector):\n",
        "    scaler = StandardScaler().set_output(transform=\"pandas\")\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "    X_test = scaler.fit_transform(X_test)\n",
        "    grid = 10 ** np.linspace(3,-2,100)\n",
        "    lasso_cv = LassoCV(alphas=grid, cv=10)#,max_iter=100000,)\n",
        "    lasso_cv.fit(X_train,np.ravel(y_train[y_label],order='C'))\n",
        "    lasso_cv.alpha_\n",
        "    lasso2 = Lasso(alpha=lasso_cv.alpha_)#, max_iter=10000)\n",
        "    lasso2_fit = lasso2.fit(X_train,np.ravel(y_train[y_label],order='C'))\n",
        "    # test_preds = lasso2_fit.predict(X_test)\n",
        "    # test = pd.DataFrame(y_test[y_label])\n",
        "    # test['Pred_score'] = test_preds\n",
        "    # return test.corr().values[0][1]\n",
        "    dev_pred = lasso2_fit.predict(prediction_vector)\n",
        "    return dev_pred\n",
        "\n",
        "\n",
        "# [rf, rf, newridge, newridge, newridge, newridge, lasso ]\n",
        "\n",
        "# rating_chooses_appropriate_action\n",
        "rating_chooses_appropriate_action_pred = run_ridge(X, X, ys, ys, ['rating_chooses_appropriate_action'], X_dev)\n",
        "print('finished one of those')\n",
        "dev_pub_df['rating_chooses_appropriate_action_pred'] = rating_chooses_appropriate_action_pred\n",
        "# rating_commits_to_action\n",
        "rating_commits_to_action_pred = run_ridge(X, X, ys, ys, ['rating_commits_to_action'], X_dev)\n",
        "dev_pub_df['rating_commits_to_action_pred'] = rating_commits_to_action_pred\n",
        "\n",
        "# rating_gathers_information\n",
        "rating_gathers_information_pred = run_ridge(X, X, ys, ys, ['rating_gathers_information'], X_dev)\n",
        "dev_pub_df['rating_gathers_information_pred'] = rating_gathers_information_pred\n",
        "\n",
        "# rating_identifies_issues_opportunities\n",
        "rating_identifies_issues_opportunities_pred = run_ridge(X, X, ys, ys, ['rating_identifies_issues_opportunities'], X_dev)\n",
        "dev_pub_df['rating_identifies_issues_opportunities_pred'] = rating_identifies_issues_opportunities_pred\n",
        "\n",
        "# rating_interprets_information\n",
        "rating_interprets_information_pred = run_ridge(X, X, ys, ys, ['rating_interprets_information'], X_dev)\n",
        "dev_pub_df['rating_interprets_information_pred'] = rating_interprets_information_pred\n",
        "\n",
        "# rating_involves_others\n",
        "rating_involves_others_pred = run_ridge(X, X, ys, ys, ['rating_involves_others'], X_dev)\n",
        "dev_pub_df['rating_involves_others_pred'] = rating_involves_others_pred\n",
        "\n",
        "# rating_decision_making_final_score\n",
        "rating_decision_making_final_score_pred = run_ridge(X, X, ys, ys, ['rating_decision_making_final_score'], X_dev)\n",
        "dev_pub_df['rating_decision_making_final_score_pred'] = rating_decision_making_final_score_pred\n",
        "\n",
        "dev_pub_df.to_csv('old_ridge_L_cluster_cleaned_text_truly_clean_w_splits_w_bigrams_cos_sim_and_distilbert_cos_sim_FINAL_TEST_SET.csv',index=False)\n",
        "print('done')\n",
        "\n",
        "# print(np.array([rating_chooses_appropriate_action_pred, rating_commits_to_action_pred, rating_gathers_information_pred, rating_identifies_issues_opportunities_pred, rating_interprets_information_pred, rating_involves_others_pred, rating_decision_making_final_score_pred]))\n",
        "# print(\"mean correlation rf: \", round(np.array([rating_chooses_appropriate_action_pred, rating_commits_to_action_pred, rating_gathers_information_pred, rating_identifies_issues_opportunities_pred, rating_interprets_information_pred, rating_involves_others_pred, rating_decision_making_final_score_pred]).mean(),3)) # 0.257\n",
        "\n",
        "# mean_r = (rating_chooses_appropriate_action_pred + rating_commits_to_action_pred + rating_gathers_information_pred + rating_identifies_issues_opportunities_pred + rating_interprets_information_pred + rating_involves_others_pred) * .1 + rating_decision_making_final_score_pred * .4\n",
        "\n",
        "# print(f\"mean_r: {mean_r}\")"
      ],
      "metadata": {
        "id": "VzfvnaC5GuOy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_pub_df = pd.read_csv(\"/content/train_S_cluster_w_cos_sim_from_distilbert_and_bigrams_truly_clean_w_splits_FINAL_TEST_SET.csv\")\n",
        "dev_pub_df = pd.read_csv(\"/content/dev_S_cluster_w_cos_sim_from_distilbert_and_bigrams_truly_clean_w_splits_FINAL_TEST_SET.csv\")\n",
        "\n",
        "# computing number of columns\n",
        "cols = len(train_pub_df.axes[1])\n",
        "print(cols)\n",
        "\n",
        "cols = train_pub_df.axes[1]\n",
        "print(cols)\n",
        "\n",
        "\n",
        "print('got that ')\n",
        "X = train_pub_df.drop(['Unnamed: 0', 'response_id', 'super', 'rating_chooses_appropriate_action','rating_commits_to_action','rating_gathers_information','rating_identifies_issues_opportunities','rating_interprets_information', 'rating_involves_others', \"rating_decision_making_final_score\", 'text_exercise_4',\n",
        "    'text_exercise_5',\n",
        "    'text_exercise_6',\n",
        "    'text_exercise_7',\n",
        "    \"text_exercise_8\",\n",
        "    \"text_exercise_9\",\n",
        "    \"text_exercise_10\",\n",
        "    \"text_exercise_11\",\n",
        "    \"text_exercise_12\",\n",
        "    \"text_exercise_13\",\n",
        "    \"text_exercise_14\",\n",
        "    \"text_exercise_15\",\n",
        "    \"text_exercise_16\",\n",
        "    \"text_exercise_17\",\n",
        "    \"text_exercise_18\",\n",
        "    \"text_exercise_19\",\n",
        "    \"text_exercise_final\", \n",
        "    'label'], axis=1)\n",
        "\n",
        "# X = new_train_pub_df[['te_final_compound','te_final_neg','te_final_neu','te_final_pos','te_19_compound','te_19_neg','te_19_neu','te_19_pos','te_17_compound','te_17_neg','te_17_neu','te_17_pos', 'te_15_compound','te_15_neg','te_15_neu','te_15_pos', 'te_14_compound','te_14_neg','te_14_neu','te_14_pos', 'te_12_compound','te_12_neg','te_12_neu','te_12_pos', 'te_11_compound','te_11_neg','te_11_neu','te_11_pos', 'te_9_compound','te_9_neg','te_9_neu','te_9_pos', 'te_7_compound','te_7_neg','te_7_neu','te_7_pos', 'te_6_compound','te_6_neg','te_6_neu','te_6_pos']]\n",
        "ys = train_pub_df[['rating_chooses_appropriate_action','rating_commits_to_action','rating_gathers_information','rating_identifies_issues_opportunities','rating_interprets_information', 'rating_involves_others', \"rating_decision_making_final_score\"]]\n",
        "\n",
        "cols = len(X.axes[1])\n",
        "print(cols)\n",
        "\n",
        "cols_div_3 = (cols) // 3 \n",
        "print(f\"{cols_div_3=}\")\n",
        "\n",
        "X_dev = dev_pub_df.drop(['Unnamed: 0', 'response_id', 'super', 'rating_chooses_appropriate_action','rating_commits_to_action','rating_gathers_information','rating_identifies_issues_opportunities','rating_interprets_information', 'rating_involves_others', \"rating_decision_making_final_score\", 'text_exercise_4',\n",
        "    'text_exercise_5',\n",
        "    'text_exercise_6',\n",
        "    'text_exercise_7',\n",
        "    \"text_exercise_8\",\n",
        "    \"text_exercise_9\",\n",
        "    \"text_exercise_10\",\n",
        "    \"text_exercise_11\",\n",
        "    \"text_exercise_12\",\n",
        "    \"text_exercise_13\",\n",
        "    \"text_exercise_14\",\n",
        "    \"text_exercise_15\",\n",
        "    \"text_exercise_16\",\n",
        "    \"text_exercise_17\",\n",
        "    \"text_exercise_18\",\n",
        "    \"text_exercise_19\",\n",
        "    \"text_exercise_final\", \n",
        "    \"label\"], axis=1)\n",
        "\n",
        "\n",
        "# ys = train_pub_df[[\"rating_decision_making_final_score\"]]\n",
        "\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,ys, test_size = 0.2 ,random_state= 42)\n",
        "\n",
        "def run_ridge(X_train, X_test, y_train, y_test, y_label, prediction_vector):\n",
        "    ridge = Ridge()\n",
        "    ridge.fit(X_train,y_train[y_label])\n",
        "    # test_preds = ridge.predict(X_test)\n",
        "    # test = pd.DataFrame(y_test[y_label])\n",
        "    # test['Pred_score'] = test_preds\n",
        "    # return test.corr().values[0][1]\n",
        "    dev_pred = ridge.predict(prediction_vector)\n",
        "    return dev_pred\n",
        "\n",
        "\n",
        "def run_rf(X_train, X_test, y_train, y_test, y_label, prediction_vector):\n",
        "    rf = RandomForestRegressor(max_depth=5, random_state=42, max_features=cols_div_3 + 1) #, max_features=9962 # or .333\n",
        "    rf.fit(X_train,np.ravel(y_train[y_label],order='C'))\n",
        "    # test_preds = rf.predict(X_test)\n",
        "    # test = pd.DataFrame(y_test[y_label])\n",
        "    # test['Pred_score'] = test_preds\n",
        "    # return test.corr().values[0][1]\n",
        "    dev_pred = rf.predict(prediction_vector)\n",
        "    return dev_pred\n",
        "\n",
        "def run_bag(X_train, X_test, y_train, y_test, y_label, prediction_vector):\n",
        "    rf = RandomForestRegressor(max_depth=5, random_state=42) #, max_features=9962 # or .333\n",
        "    rf.fit(X_train,np.ravel(y_train[y_label],order='C'))\n",
        "    # test_preds = rf.predict(X_test)\n",
        "    # test = pd.DataFrame(y_test[y_label])\n",
        "    # test['Pred_score'] = test_preds\n",
        "    # return test.corr().values[0][1]\n",
        "    dev_pred = rf.predict(prediction_vector)\n",
        "    return dev_pred\n",
        "\n",
        "def run_knn(X_train, X_test, y_train, y_test, y_label, prediction_vector):\n",
        "    knn = KNeighborsRegressor(n_neighbors=93, p=2, weights=\"distance\")\n",
        "    knn.fit(X_train,y_train[y_label])\n",
        "    # test_preds = knn.predict(X_test)\n",
        "    # test = pd.DataFrame(y_test[y_label])\n",
        "    # test['Pred_score'] = test_preds\n",
        "    # return test.corr().values[0][1]\n",
        "    dev_pred = knn.predict(prediction_vector)\n",
        "    return dev_pred\n",
        "\n",
        "\n",
        "def new_run_ridge(X_train, X_test, y_train, y_test, y_label, prediction_vector):\n",
        "    scaler = StandardScaler().set_output(transform=\"pandas\")\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "    X_test = scaler.fit_transform(X_test)\n",
        "    grid = 10 ** np.linspace(3,-2,100)\n",
        "    ridge_cv = RidgeCV(alphas=grid, scoring='neg_mean_squared_error')\n",
        "    ridge_cv.fit(X_train,y_train[y_label])\n",
        "    ridge_cv.alpha_\n",
        "    ridge5 = Ridge(alpha=ridge_cv.alpha_)\n",
        "    ridge5_fit = ridge5.fit(X_train,y_train[y_label])\n",
        "    # test_preds = ridge5_fit.predict(X_test)\n",
        "    # test = pd.DataFrame(y_test[y_label])\n",
        "    # test['Pred_score'] = test_preds\n",
        "    # return test.corr().values[0][1]\n",
        "    dev_pred = ridge5_fit.predict(prediction_vector)\n",
        "    return dev_pred\n",
        "\n",
        "\n",
        "def run_lasso(X_train, X_test, y_train, y_test, y_label, prediction_vector):\n",
        "    scaler = StandardScaler().set_output(transform=\"pandas\")\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "    X_test = scaler.fit_transform(X_test)\n",
        "    grid = 10 ** np.linspace(3,-2,100)\n",
        "    lasso_cv = LassoCV(alphas=grid, cv=10)#,max_iter=100000,)\n",
        "    lasso_cv.fit(X_train,np.ravel(y_train[y_label],order='C'))\n",
        "    lasso_cv.alpha_\n",
        "    lasso2 = Lasso(alpha=lasso_cv.alpha_)#, max_iter=10000)\n",
        "    lasso2_fit = lasso2.fit(X_train,np.ravel(y_train[y_label],order='C'))\n",
        "    # test_preds = lasso2_fit.predict(X_test)\n",
        "    # test = pd.DataFrame(y_test[y_label])\n",
        "    # test['Pred_score'] = test_preds\n",
        "    # return test.corr().values[0][1]\n",
        "    dev_pred = lasso2_fit.predict(prediction_vector)\n",
        "    return dev_pred\n",
        "\n",
        "\n",
        "# [ bag, rf, bag, bag, rf, rf, rf ]\n",
        "\n",
        "# rating_chooses_appropriate_action\n",
        "rating_chooses_appropriate_action_pred = run_bag(X, X, ys, ys, ['rating_chooses_appropriate_action'], X_dev)\n",
        "print('finished one of those')\n",
        "dev_pub_df['rating_chooses_appropriate_action_pred'] = rating_chooses_appropriate_action_pred\n",
        "# rating_commits_to_action\n",
        "rating_commits_to_action_pred = run_rf(X, X, ys, ys, ['rating_commits_to_action'], X_dev)\n",
        "dev_pub_df['rating_commits_to_action_pred'] = rating_commits_to_action_pred\n",
        "\n",
        "# rating_gathers_information\n",
        "rating_gathers_information_pred = run_bag(X, X, ys, ys, ['rating_gathers_information'], X_dev)\n",
        "dev_pub_df['rating_gathers_information_pred'] = rating_gathers_information_pred\n",
        "\n",
        "# rating_identifies_issues_opportunities\n",
        "rating_identifies_issues_opportunities_pred = run_bag(X, X, ys, ys, ['rating_identifies_issues_opportunities'], X_dev)\n",
        "dev_pub_df['rating_identifies_issues_opportunities_pred'] = rating_identifies_issues_opportunities_pred\n",
        "\n",
        "# rating_interprets_information\n",
        "rating_interprets_information_pred = run_rf(X, X, ys, ys, ['rating_interprets_information'], X_dev)\n",
        "dev_pub_df['rating_interprets_information_pred'] = rating_interprets_information_pred\n",
        "\n",
        "# rating_involves_others\n",
        "rating_involves_others_pred = run_rf(X, X, ys, ys, ['rating_involves_others'], X_dev)\n",
        "dev_pub_df['rating_involves_others_pred'] = rating_involves_others_pred\n",
        "\n",
        "# rating_decision_making_final_score\n",
        "rating_decision_making_final_score_pred = run_rf(X, X, ys, ys, ['rating_decision_making_final_score'], X_dev)\n",
        "dev_pub_df['rating_decision_making_final_score_pred'] = rating_decision_making_final_score_pred\n",
        "\n",
        "dev_pub_df.to_csv('old_ridge_S_cluster_cleaned_text_truly_clean_w_splits_w_bigrams_cos_sim_and_distilbert_cos_sim_FINAL_TEST_SET.csv',index=False)\n",
        "print('done')\n",
        "\n",
        "# print(np.array([rating_chooses_appropriate_action_pred, rating_commits_to_action_pred, rating_gathers_information_pred, rating_identifies_issues_opportunities_pred, rating_interprets_information_pred, rating_involves_others_pred, rating_decision_making_final_score_pred]))\n",
        "# print(\"mean correlation rf: \", round(np.array([rating_chooses_appropriate_action_pred, rating_commits_to_action_pred, rating_gathers_information_pred, rating_identifies_issues_opportunities_pred, rating_interprets_information_pred, rating_involves_others_pred, rating_decision_making_final_score_pred]).mean(),3)) # 0.257\n",
        "\n",
        "# mean_r = (rating_chooses_appropriate_action_pred + rating_commits_to_action_pred + rating_gathers_information_pred + rating_identifies_issues_opportunities_pred + rating_interprets_information_pred + rating_involves_others_pred) * .1 + rating_decision_making_final_score_pred * .4\n",
        "\n",
        "# print(f\"mean_r: {mean_r}\")"
      ],
      "metadata": {
        "id": "ENraBdhsGy6W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_pub_df = pd.read_csv(\"/content/train_T_cluster_w_cos_sim_from_distilbert_and_bigrams_truly_clean_w_splits_FINAL_TEST_SET.csv\")\n",
        "dev_pub_df = pd.read_csv(\"/content/dev_T_cluster_w_cos_sim_from_distilbert_and_bigrams_truly_clean_w_splits_FINAL_TEST_SET.csv\")\n",
        "\n",
        "# computing number of columns\n",
        "cols = len(train_pub_df.axes[1])\n",
        "print(cols)\n",
        "\n",
        "cols = train_pub_df.axes[1]\n",
        "print(cols)\n",
        "\n",
        "\n",
        "print('got that ')\n",
        "X = train_pub_df.drop(['Unnamed: 0', 'response_id', 'super', 'rating_chooses_appropriate_action','rating_commits_to_action','rating_gathers_information','rating_identifies_issues_opportunities','rating_interprets_information', 'rating_involves_others', \"rating_decision_making_final_score\", 'text_exercise_4',\n",
        "    'text_exercise_5',\n",
        "    'text_exercise_6',\n",
        "    'text_exercise_7',\n",
        "    \"text_exercise_8\",\n",
        "    \"text_exercise_9\",\n",
        "    \"text_exercise_10\",\n",
        "    \"text_exercise_11\",\n",
        "    \"text_exercise_12\",\n",
        "    \"text_exercise_13\",\n",
        "    \"text_exercise_14\",\n",
        "    \"text_exercise_15\",\n",
        "    \"text_exercise_16\",\n",
        "    \"text_exercise_17\",\n",
        "    \"text_exercise_18\",\n",
        "    \"text_exercise_19\",\n",
        "    \"text_exercise_final\", \n",
        "    'label'], axis=1)\n",
        "\n",
        "# X = new_train_pub_df[['te_final_compound','te_final_neg','te_final_neu','te_final_pos','te_19_compound','te_19_neg','te_19_neu','te_19_pos','te_17_compound','te_17_neg','te_17_neu','te_17_pos', 'te_15_compound','te_15_neg','te_15_neu','te_15_pos', 'te_14_compound','te_14_neg','te_14_neu','te_14_pos', 'te_12_compound','te_12_neg','te_12_neu','te_12_pos', 'te_11_compound','te_11_neg','te_11_neu','te_11_pos', 'te_9_compound','te_9_neg','te_9_neu','te_9_pos', 'te_7_compound','te_7_neg','te_7_neu','te_7_pos', 'te_6_compound','te_6_neg','te_6_neu','te_6_pos']]\n",
        "ys = train_pub_df[['rating_chooses_appropriate_action','rating_commits_to_action','rating_gathers_information','rating_identifies_issues_opportunities','rating_interprets_information', 'rating_involves_others', \"rating_decision_making_final_score\"]]\n",
        "\n",
        "cols = len(X.axes[1])\n",
        "print(cols)\n",
        "\n",
        "cols_div_3 = (cols) // 3 \n",
        "print(f\"{cols_div_3=}\")\n",
        "\n",
        "X_dev = dev_pub_df.drop(['Unnamed: 0', 'response_id', 'super', 'rating_chooses_appropriate_action','rating_commits_to_action','rating_gathers_information','rating_identifies_issues_opportunities','rating_interprets_information', 'rating_involves_others', \"rating_decision_making_final_score\", 'text_exercise_4',\n",
        "    'text_exercise_5',\n",
        "    'text_exercise_6',\n",
        "    'text_exercise_7',\n",
        "    \"text_exercise_8\",\n",
        "    \"text_exercise_9\",\n",
        "    \"text_exercise_10\",\n",
        "    \"text_exercise_11\",\n",
        "    \"text_exercise_12\",\n",
        "    \"text_exercise_13\",\n",
        "    \"text_exercise_14\",\n",
        "    \"text_exercise_15\",\n",
        "    \"text_exercise_16\",\n",
        "    \"text_exercise_17\",\n",
        "    \"text_exercise_18\",\n",
        "    \"text_exercise_19\",\n",
        "    \"text_exercise_final\", \n",
        "    \"label\"], axis=1)\n",
        "\n",
        "\n",
        "# ys = train_pub_df[[\"rating_decision_making_final_score\"]]\n",
        "\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,ys, test_size = 0.2 ,random_state= 42)\n",
        "\n",
        "def run_ridge(X_train, X_test, y_train, y_test, y_label, prediction_vector):\n",
        "    ridge = Ridge()\n",
        "    ridge.fit(X_train,y_train[y_label])\n",
        "    # test_preds = ridge.predict(X_test)\n",
        "    # test = pd.DataFrame(y_test[y_label])\n",
        "    # test['Pred_score'] = test_preds\n",
        "    # return test.corr().values[0][1]\n",
        "    dev_pred = ridge.predict(prediction_vector)\n",
        "    return dev_pred\n",
        "\n",
        "\n",
        "def run_rf(X_train, X_test, y_train, y_test, y_label, prediction_vector):\n",
        "    rf = RandomForestRegressor(max_depth=5, random_state=42, max_features=cols_div_3 + 1) #, max_features=9962 # or .333\n",
        "    rf.fit(X_train,np.ravel(y_train[y_label],order='C'))\n",
        "    # test_preds = rf.predict(X_test)\n",
        "    # test = pd.DataFrame(y_test[y_label])\n",
        "    # test['Pred_score'] = test_preds\n",
        "    # return test.corr().values[0][1]\n",
        "    dev_pred = rf.predict(prediction_vector)\n",
        "    return dev_pred\n",
        "\n",
        "def run_bag(X_train, X_test, y_train, y_test, y_label, prediction_vector):\n",
        "    rf = RandomForestRegressor(max_depth=5, random_state=42) #, max_features=9962 # or .333\n",
        "    rf.fit(X_train,np.ravel(y_train[y_label],order='C'))\n",
        "    # test_preds = rf.predict(X_test)\n",
        "    # test = pd.DataFrame(y_test[y_label])\n",
        "    # test['Pred_score'] = test_preds\n",
        "    # return test.corr().values[0][1]\n",
        "    dev_pred = rf.predict(prediction_vector)\n",
        "    return dev_pred\n",
        "\n",
        "def run_knn(X_train, X_test, y_train, y_test, y_label, prediction_vector):\n",
        "    knn = KNeighborsRegressor(n_neighbors=93, p=2, weights=\"distance\")\n",
        "    knn.fit(X_train,y_train[y_label])\n",
        "    # test_preds = knn.predict(X_test)\n",
        "    # test = pd.DataFrame(y_test[y_label])\n",
        "    # test['Pred_score'] = test_preds\n",
        "    # return test.corr().values[0][1]\n",
        "    dev_pred = knn.predict(prediction_vector)\n",
        "    return dev_pred\n",
        "\n",
        "\n",
        "def new_run_ridge(X_train, X_test, y_train, y_test, y_label, prediction_vector):\n",
        "    scaler = StandardScaler().set_output(transform=\"pandas\")\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "    X_test = scaler.fit_transform(X_test)\n",
        "    grid = 10 ** np.linspace(3,-2,100)\n",
        "    ridge_cv = RidgeCV(alphas=grid, scoring='neg_mean_squared_error')\n",
        "    ridge_cv.fit(X_train,y_train[y_label])\n",
        "    ridge_cv.alpha_\n",
        "    ridge5 = Ridge(alpha=ridge_cv.alpha_)\n",
        "    ridge5_fit = ridge5.fit(X_train,y_train[y_label])\n",
        "    # test_preds = ridge5_fit.predict(X_test)\n",
        "    # test = pd.DataFrame(y_test[y_label])\n",
        "    # test['Pred_score'] = test_preds\n",
        "    # return test.corr().values[0][1]\n",
        "    dev_pred = ridge5_fit.predict(prediction_vector)\n",
        "    return dev_pred\n",
        "\n",
        "\n",
        "def run_lasso(X_train, X_test, y_train, y_test, y_label, prediction_vector):\n",
        "    scaler = StandardScaler().set_output(transform=\"pandas\")\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "    X_test = scaler.fit_transform(X_test)\n",
        "    grid = 10 ** np.linspace(3,-2,100)\n",
        "    lasso_cv = LassoCV(alphas=grid, cv=10)#,max_iter=100000,)\n",
        "    lasso_cv.fit(X_train,np.ravel(y_train[y_label],order='C'))\n",
        "    lasso_cv.alpha_\n",
        "    lasso2 = Lasso(alpha=lasso_cv.alpha_)#, max_iter=10000)\n",
        "    lasso2_fit = lasso2.fit(X_train,np.ravel(y_train[y_label],order='C'))\n",
        "    # test_preds = lasso2_fit.predict(X_test)\n",
        "    # test = pd.DataFrame(y_test[y_label])\n",
        "    # test['Pred_score'] = test_preds\n",
        "    # return test.corr().values[0][1]\n",
        "    dev_pred = lasso2_fit.predict(prediction_vector)\n",
        "    return dev_pred\n",
        "\n",
        "\n",
        "# [ bag, rf, old_ridge, old_ridge, rf, bag, rf ]  \n",
        "\n",
        "# rating_chooses_appropriate_action\n",
        "rating_chooses_appropriate_action_pred = run_bag(X, X, ys, ys, ['rating_chooses_appropriate_action'], X_dev)\n",
        "print('finished one of those')\n",
        "dev_pub_df['rating_chooses_appropriate_action_pred'] = rating_chooses_appropriate_action_pred\n",
        "# rating_commits_to_action\n",
        "rating_commits_to_action_pred = run_rf(X, X, ys, ys, ['rating_commits_to_action'], X_dev)\n",
        "dev_pub_df['rating_commits_to_action_pred'] = rating_commits_to_action_pred\n",
        "\n",
        "# rating_gathers_information\n",
        "rating_gathers_information_pred = run_ridge(X, X, ys, ys, ['rating_gathers_information'], X_dev)\n",
        "dev_pub_df['rating_gathers_information_pred'] = rating_gathers_information_pred\n",
        "\n",
        "# rating_identifies_issues_opportunities\n",
        "rating_identifies_issues_opportunities_pred = run_ridge(X, X, ys, ys, ['rating_identifies_issues_opportunities'], X_dev)\n",
        "dev_pub_df['rating_identifies_issues_opportunities_pred'] = rating_identifies_issues_opportunities_pred\n",
        "\n",
        "# rating_interprets_information\n",
        "rating_interprets_information_pred = run_rf(X, X, ys, ys, ['rating_interprets_information'], X_dev)\n",
        "dev_pub_df['rating_interprets_information_pred'] = rating_interprets_information_pred\n",
        "\n",
        "# rating_involves_others\n",
        "rating_involves_others_pred = run_bag(X, X, ys, ys, ['rating_involves_others'], X_dev)\n",
        "dev_pub_df['rating_involves_others_pred'] = rating_involves_others_pred\n",
        "\n",
        "# rating_decision_making_final_score\n",
        "rating_decision_making_final_score_pred = run_rf(X, X, ys, ys, ['rating_decision_making_final_score'], X_dev)\n",
        "dev_pub_df['rating_decision_making_final_score_pred'] = rating_decision_making_final_score_pred\n",
        "\n",
        "dev_pub_df.to_csv('all_old_ridge_T_cluster_cleaned_text_truly_clean_w_splits_w_bigrams_cos_sim_and_distilbert_cos_sim_FINAL_TEST_SET.csv',index=False)\n",
        "print('done')\n",
        "\n",
        "# print(np.array([rating_chooses_appropriate_action_pred, rating_commits_to_action_pred, rating_gathers_information_pred, rating_identifies_issues_opportunities_pred, rating_interprets_information_pred, rating_involves_others_pred, rating_decision_making_final_score_pred]))\n",
        "# print(\"mean correlation rf: \", round(np.array([rating_chooses_appropriate_action_pred, rating_commits_to_action_pred, rating_gathers_information_pred, rating_identifies_issues_opportunities_pred, rating_interprets_information_pred, rating_involves_others_pred, rating_decision_making_final_score_pred]).mean(),3)) # 0.257\n",
        "\n",
        "# mean_r = (rating_chooses_appropriate_action_pred + rating_commits_to_action_pred + rating_gathers_information_pred + rating_identifies_issues_opportunities_pred + rating_interprets_information_pred + rating_involves_others_pred) * .1 + rating_decision_making_final_score_pred * .4\n",
        "\n",
        "# print(f\"mean_r: {mean_r}\")"
      ],
      "metadata": {
        "id": "FWrLB6F3GzGA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Merging the predictions for each group of particpants into a single dataframe of predictions:**"
      ],
      "metadata": {
        "id": "LVH81dekOKoA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "\n",
        "# now reading those back in from python: \n",
        "\n",
        "old_ridge_L_cluster_cleaned_text_truly_clean_w_splits_w_bigrams_cos_sim_and_distilbert_cos_sim = read.csv(\"/content/old_ridge_L_cluster_cleaned_text_truly_clean_w_splits_w_bigrams_cos_sim_and_distilbert_cos_sim_FINAL_TEST_SET.csv\")\n",
        "old_ridge_S_cluster_cleaned_text_truly_clean_w_splits_w_bigrams_cos_sim_and_distilbert_cos_sim = read.csv(\"/content/old_ridge_S_cluster_cleaned_text_truly_clean_w_splits_w_bigrams_cos_sim_and_distilbert_cos_sim_FINAL_TEST_SET.csv\")\n",
        "old_ridge_T_cluster_cleaned_text_truly_clean_w_splits_w_bigrams_cos_sim_and_distilbert_cos_sim = read.csv(\"/content/all_old_ridge_T_cluster_cleaned_text_truly_clean_w_splits_w_bigrams_cos_sim_and_distilbert_cos_sim_FINAL_TEST_SET.csv\")\n",
        "\n",
        "old_ridge_L_cluster_cleaned_text_truly_clean_w_splits_w_bigrams_cos_sim_and_distilbert_cos_sim = subset(old_ridge_L_cluster_cleaned_text_truly_clean_w_splits_w_bigrams_cos_sim_and_distilbert_cos_sim, select = c(response_id, rating_chooses_appropriate_action_pred, rating_commits_to_action_pred, rating_gathers_information_pred, rating_identifies_issues_opportunities_pred, rating_interprets_information_pred, rating_involves_others_pred, rating_decision_making_final_score_pred))\n",
        "old_ridge_S_cluster_cleaned_text_truly_clean_w_splits_w_bigrams_cos_sim_and_distilbert_cos_sim = subset(old_ridge_S_cluster_cleaned_text_truly_clean_w_splits_w_bigrams_cos_sim_and_distilbert_cos_sim, select = c(response_id, rating_chooses_appropriate_action_pred, rating_commits_to_action_pred, rating_gathers_information_pred, rating_identifies_issues_opportunities_pred, rating_interprets_information_pred, rating_involves_others_pred, rating_decision_making_final_score_pred))\n",
        "old_ridge_T_cluster_cleaned_text_truly_clean_w_splits_w_bigrams_cos_sim_and_distilbert_cos_sim = subset(old_ridge_T_cluster_cleaned_text_truly_clean_w_splits_w_bigrams_cos_sim_and_distilbert_cos_sim, select = c(response_id, rating_chooses_appropriate_action_pred, rating_commits_to_action_pred, rating_gathers_information_pred, rating_identifies_issues_opportunities_pred, rating_interprets_information_pred, rating_involves_others_pred, rating_decision_making_final_score_pred))\n",
        "\n",
        "dev_pub_w_preds = rbind(old_ridge_L_cluster_cleaned_text_truly_clean_w_splits_w_bigrams_cos_sim_and_distilbert_cos_sim, old_ridge_S_cluster_cleaned_text_truly_clean_w_splits_w_bigrams_cos_sim_and_distilbert_cos_sim, old_ridge_T_cluster_cleaned_text_truly_clean_w_splits_w_bigrams_cos_sim_and_distilbert_cos_sim)"
      ],
      "metadata": {
        "id": "h5mKUqzjKKEf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Using quantile function to round predictions based on distribution of training set to get the final predictions for model 1, which was used for 5 out of 7 rating columns (mean_r for model 1 = .491):**"
      ],
      "metadata": {
        "id": "PBh7ybKwKgMt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This technique involving quantiles was utilized because two sample KolmogorovSmirnov tests showed that while the vast majority of predictors between the training and test set came from the same distribution, the predictions (when rounding to the nearest value) did not.\n",
        "\n",
        "Using the quantile function in R to round predictions to have the same distribution as the outcomes on the train set improved the model. \n",
        "\n",
        "If there is reason to believe the test sample is not from the same distribution as the train data, (e.g., a new set of applicants all highly recommended with high levels of expertise are the only applicants in a certain cycle), this type of technique is not advised. \n",
        "\n",
        "Best to utilize the two-sample KS tests as mentioned above on all predictors and then on the predictions after running model to see if it's warranted, if using this script. "
      ],
      "metadata": {
        "id": "1JO7B56I1w95"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "\n",
        "\n",
        "ret_df_before_rounding = subset(dev_pub_w_preds, select = c(response_id, rating_chooses_appropriate_action_pred, rating_commits_to_action_pred, rating_gathers_information_pred, rating_identifies_issues_opportunities_pred, rating_interprets_information_pred, rating_involves_others_pred, rating_decision_making_final_score_pred))\n",
        "\n",
        "copy_of_ret_df_before_rounding = ret_df_before_rounding\n",
        "\n",
        "round_df <- function(x, digits) {\n",
        "  # round all numeric variables\n",
        "  # x: data frame \n",
        "  # digits: number of digits to round\n",
        "  numeric_columns <- sapply(x, mode) == 'numeric'\n",
        "  x[numeric_columns] <-  round(x[numeric_columns], digits)\n",
        "  x\n",
        "}\n",
        "\n",
        "after_rounding_ret = round_df(copy_of_ret_df_before_rounding, 0)\n",
        "\n",
        "colnames(after_rounding_ret)[2] = \"rating_chooses_appropriate_action\"\n",
        "colnames(after_rounding_ret)[3] = \"rating_commits_to_action\"\n",
        "colnames(after_rounding_ret)[4] = \"rating_gathers_information\"\n",
        "colnames(after_rounding_ret)[5] = \"rating_identifies_issues_opportunities\"\n",
        "colnames(after_rounding_ret)[6] = \"rating_interprets_information\"\n",
        "colnames(after_rounding_ret)[7] = \"rating_involves_others\"\n",
        "colnames(after_rounding_ret)[8] = \"rating_decision_making_final_score\"\n",
        "\n",
        "\n",
        "########## QUANTILES ##########\n",
        "\n",
        "## CHOOSES APPROPRIATE ACTION QUANTILE\n",
        "\n",
        "table(train_pub_df$rating_chooses_appropriate_action)\n",
        "8 + 436 + 819 +  123 # = 1386\n",
        "436 + 8\n",
        "444 / 1386 # = 0.3203463 = lower_cutoff_chooses_appropriate_action\n",
        "(444 + 819) / 1386 # = 0.9112554 = upper_cutoff_chooses_appropriate_action\n",
        "lower_cutoff_chooses_appropriate_action = 0.3203463\n",
        "upper_cutoff_chooses_appropriate_action = 0.9112554\n",
        "\n",
        "actual_value_lower_cutoff_chooses_appropriate_action = quantile(copy_of_ret_df_before_rounding$rating_chooses_appropriate_action_pred, probs = lower_cutoff_chooses_appropriate_action, names = FALSE)\n",
        "\n",
        "actual_value_upper_cutoff_chooses_appropriate_action = quantile(copy_of_ret_df_before_rounding$rating_chooses_appropriate_action_pred, probs = upper_cutoff_chooses_appropriate_action, names = FALSE)\n",
        "\n",
        "\n",
        "after_rounding_ret$rating_chooses_appropriate_action = ifelse(copy_of_ret_df_before_rounding$rating_chooses_appropriate_action_pred < actual_value_lower_cutoff_chooses_appropriate_action, 2, ifelse(copy_of_ret_df_before_rounding$rating_chooses_appropriate_action_pred > actual_value_upper_cutoff_chooses_appropriate_action, 4, 3))\n",
        "\n",
        "hist(train_pub_df$rating_chooses_appropriate_action)\n",
        "hist(after_rounding_ret$rating_chooses_appropriate_action)\n",
        "\n",
        "\n",
        "\n",
        "### COMMITS TO ACTION QUANTILE\n",
        "\n",
        "table(train_pub_df$rating_commits_to_action)\n",
        "\n",
        "# 1   2   3   4 \n",
        "# 3 203 915 345 \n",
        "# 3 + 203 + 915 + 345 # = 1466\n",
        "# 206/1466 # = 0.1405184\n",
        "\n",
        "lower_cutoff_commits_to_action = 0.1405184\n",
        "\n",
        "\n",
        "# (206 + 915) / 1466 # = 0.7646658\n",
        "\n",
        "upper_cutoff_commits_to_action = 0.7646658\n",
        "\n",
        "actual_value_lower_cutoff_commits_to_action = quantile(copy_of_ret_df_before_rounding$rating_commits_to_action_pred, probs = lower_cutoff_commits_to_action, names = FALSE)\n",
        "\n",
        "actual_value_upper_cutoff_commits_to_action = quantile(copy_of_ret_df_before_rounding$rating_commits_to_action_pred, probs = upper_cutoff_commits_to_action, names = FALSE)\n",
        "\n",
        "quantile_test_commits_to_action = ifelse(copy_of_ret_df_before_rounding$rating_commits_to_action_pred < actual_value_lower_cutoff_commits_to_action, 2, ifelse(copy_of_ret_df_before_rounding$rating_commits_to_action_pred > actual_value_upper_cutoff_commits_to_action, 4, 3))\n",
        "\n",
        "after_rounding_ret$rating_commits_to_action = quantile_test_commits_to_action\n",
        "\n",
        "hist(after_rounding_ret$rating_commits_to_action)\n",
        "hist(train_pub_df$rating_commits_to_action)\n",
        "\n",
        "\n",
        "## GATHERS INFORMATION QUANTILE \n",
        "\n",
        "table(train_pub_df$rating_gathers_information)\n",
        "# 1   2   3   4 \n",
        "# 3 581 730 152 \n",
        "3 + 581 + 730 + 152 # = 1466\n",
        "\n",
        "lower_cutoff_gathers_information = 584 / 1466\n",
        "\n",
        "upper_cutoff_gathers_information = (584 + 730) / 1466\n",
        "\n",
        "actual_value_lower_cutoff_gathers_information = quantile(copy_of_ret_df_before_rounding$rating_gathers_information_pred, probs = lower_cutoff_gathers_information, names = FALSE)\n",
        "\n",
        "actual_value_upper_cutoff_gathers_information = quantile(copy_of_ret_df_before_rounding$rating_gathers_information_pred, probs = upper_cutoff_gathers_information, names = FALSE)\n",
        "\n",
        "\n",
        "after_rounding_ret$rating_gathers_information = ifelse(copy_of_ret_df_before_rounding$rating_gathers_information_pred < actual_value_lower_cutoff_gathers_information, 2, ifelse(copy_of_ret_df_before_rounding$rating_gathers_information_pred > actual_value_upper_cutoff_gathers_information, 4, 3))\n",
        "\n",
        "hist(after_rounding_ret$rating_gathers_information)\n",
        "hist(train_pub_df$rating_gathers_information)\n",
        "\n",
        "\n",
        "## IDENTIFIES ISSUES OPPS QUANTILE \n",
        "\n",
        "table(train_pub_df$rating_identifies_issues_opportunities)\n",
        "# 1   2   3   4 \n",
        "# 3 517 802  64 \n",
        "\n",
        "3 + 517 + 802 + 64 # = 1386\n",
        "\n",
        "lower_cutoff_identifies_issues_oppurtunities = 520 / 1386\n",
        "\n",
        "upper_cutoff_identifies_issues_oppurtunities = (520 + 802) / 1386\n",
        "\n",
        "actual_value_lower_cutoff_identifies_issues_oppurtunities = quantile(copy_of_ret_df_before_rounding$rating_identifies_issues_opportunities_pred, probs = lower_cutoff_identifies_issues_oppurtunities, names = FALSE)\n",
        "\n",
        "actual_value_upper_cutoff_identifies_issues_oppurtunities  = quantile(copy_of_ret_df_before_rounding$rating_identifies_issues_opportunities_pred, probs = upper_cutoff_identifies_issues_oppurtunities, names = FALSE)\n",
        "\n",
        "\n",
        "after_rounding_ret$rating_identifies_issues_opportunities = ifelse(copy_of_ret_df_before_rounding$rating_identifies_issues_opportunities_pred < actual_value_lower_cutoff_identifies_issues_oppurtunities, 2, ifelse(copy_of_ret_df_before_rounding$rating_identifies_issues_opportunities_pred > actual_value_upper_cutoff_identifies_issues_oppurtunities, 4, 3))\n",
        "\n",
        "\n",
        "hist(train_pub_df$rating_identifies_issues_opportunities)\n",
        "hist(after_rounding_ret$rating_identifies_issues_opportunities)\n",
        "\n",
        "table(after_rounding_ret$rating_identifies_issues_opportunities)\n",
        "\n",
        "# INTERPRETS INFORMATION QUANTILE \n",
        "\n",
        "table(train_pub_df$rating_interprets_information)\n",
        "\n",
        "# 2   3   4 \n",
        "# 883 484  99 \n",
        "\n",
        "883 + 484 + 99 # = 1466\n",
        "\n",
        "lower_cutoff_interprets_information = 883/1466\n",
        "\n",
        "upper_cutoff_interprets_information = (883 + 484) / 1466\n",
        "\n",
        "actual_value_lower_cutoff_interprets_information = quantile(copy_of_ret_df_before_rounding$rating_interprets_information_pred, probs = lower_cutoff_interprets_information, names = FALSE)\n",
        "\n",
        "actual_value_upper_cutoff_interprets_information  = quantile(copy_of_ret_df_before_rounding$rating_interprets_information_pred, probs = upper_cutoff_interprets_information, names = FALSE)\n",
        "\n",
        "\n",
        "after_rounding_ret$rating_interprets_information = ifelse(copy_of_ret_df_before_rounding$rating_interprets_information_pred < actual_value_lower_cutoff_interprets_information, 2, ifelse(copy_of_ret_df_before_rounding$rating_interprets_information_pred > actual_value_upper_cutoff_interprets_information, 4, 3))\n",
        "\n",
        "hist(train_pub_df$rating_interprets_information)\n",
        "hist(after_rounding_ret$rating_interprets_information)\n",
        "\n",
        "\n",
        "# INVOLVES OTHERS QUANTILE \n",
        "\n",
        "table(train_pub_df$rating_involves_others)\n",
        "# 2   3   4 \n",
        "# 474 703 204 \n",
        "\n",
        "\n",
        "474 + 703 + 204 # = 1381\n",
        "\n",
        "lower_cutoff_involves_others = 474 / 1381\n",
        "upper_cutoff_involves_others = (474 + 703) / 1381\n",
        "\n",
        "actual_value_lower_cutoff_involves_others = quantile(copy_of_ret_df_before_rounding$rating_involves_others_pred, probs = lower_cutoff_involves_others, names = FALSE)\n",
        "\n",
        "actual_value_upper_cutoff_involves_others  = quantile(copy_of_ret_df_before_rounding$rating_involves_others_pred, probs = upper_cutoff_involves_others, names = FALSE)\n",
        "\n",
        "\n",
        "after_rounding_ret$rating_involves_others = ifelse(copy_of_ret_df_before_rounding$rating_involves_others_pred < actual_value_lower_cutoff_involves_others, 2, ifelse(copy_of_ret_df_before_rounding$rating_involves_others_pred > actual_value_upper_cutoff_involves_others, 4, 3))\n",
        "\n",
        "hist(train_pub_df$rating_involves_others)\n",
        "hist(after_rounding_ret$rating_involves_others)\n",
        "\n",
        "# FINAL DECISION QUANTILE \n",
        "\n",
        "table(train_pub_df$rating_decision_making_final_score)\n",
        "# 1   2   3   4   5   6   7 \n",
        "# 24 522 402 283 111 107  17 \n",
        "\n",
        "24 + 522 + 402 + 283 + 111 + 107 + 17 # = 1466\n",
        "\n",
        "final_decision_1_cutoff = 24 / 1466\n",
        "final_decision_2_cutoff = (24 + 522) / 1466\n",
        "final_decision_3_cutoff = (24 + 522 + 402) / 1466\n",
        "final_decision_4_cutoff = (24 + 522 + 402 + 283) / 1466\n",
        "final_decision_5_cutoff = (24 + 522 + 402 + 283 + 111) / 1466\n",
        "final_decision_6_cutoff = (24 + 522 + 402 + 283 + 111 + 107) / 1466\n",
        "\n",
        "actual_value_final_decision_1_cutoff = quantile(copy_of_ret_df_before_rounding$rating_decision_making_final_score_pred, probs = final_decision_1_cutoff, names = FALSE)\n",
        "actual_value_final_decision_2_cutoff = quantile(copy_of_ret_df_before_rounding$rating_decision_making_final_score_pred, probs = final_decision_2_cutoff, names = FALSE)\n",
        "actual_value_final_decision_3_cutoff = quantile(copy_of_ret_df_before_rounding$rating_decision_making_final_score_pred, probs = final_decision_3_cutoff, names = FALSE)\n",
        "actual_value_final_decision_4_cutoff = quantile(copy_of_ret_df_before_rounding$rating_decision_making_final_score_pred, probs = final_decision_4_cutoff, names = FALSE)\n",
        "actual_value_final_decision_5_cutoff = quantile(copy_of_ret_df_before_rounding$rating_decision_making_final_score_pred, probs = final_decision_5_cutoff, names = FALSE)\n",
        "actual_value_final_decision_6_cutoff = quantile(copy_of_ret_df_before_rounding$rating_decision_making_final_score_pred, probs = final_decision_6_cutoff, names = FALSE)\n",
        "\n",
        "\n",
        "after_rounding_ret$rating_decision_making_final_score = ifelse(copy_of_ret_df_before_rounding$rating_decision_making_final_score_pred < actual_value_final_decision_1_cutoff, 1, ifelse(copy_of_ret_df_before_rounding$rating_decision_making_final_score_pred <= actual_value_final_decision_2_cutoff, 2, ifelse(copy_of_ret_df_before_rounding$rating_decision_making_final_score_pred < actual_value_final_decision_3_cutoff, 3, ifelse(copy_of_ret_df_before_rounding$rating_decision_making_final_score_pred < actual_value_final_decision_4_cutoff, 4, ifelse(copy_of_ret_df_before_rounding$rating_decision_making_final_score_pred < actual_value_final_decision_5_cutoff, 5, ifelse(copy_of_ret_df_before_rounding$rating_decision_making_final_score_pred <= actual_value_final_decision_6_cutoff, 6, 7))))))\n",
        "\n",
        "hist(train_pub_df$rating_decision_making_final_score)\n",
        "hist(after_rounding_ret$rating_decision_making_final_score)\n",
        "\n",
        "write.csv(after_rounding_ret, 'model_1_predictions.csv')"
      ],
      "metadata": {
        "id": "jEtDgwgVKfo4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model 2 simply adds TFIDF cosine similarities to model 1:**"
      ],
      "metadata": {
        "id": "0LKJJxUBLcEC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "unwanted_pipes = [\"ner\", \"parser\"]\n",
        "\n",
        "def spacy_tokenizer(doc):\n",
        "  with nlp.disable_pipes(*unwanted_pipes):\n",
        "    return [t.lemma_ for t in nlp(doc) if \\\n",
        "            not t.is_punct and \\\n",
        "            not t.is_space and \\\n",
        "            t.is_alpha]\n",
        "\n",
        "vectorizer = TfidfVectorizer(tokenizer=spacy_tokenizer)"
      ],
      "metadata": {
        "id": "k27DVfy-Ljx2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "\n",
        "print(ncol(L_cluster_w_cos_sim_from_distilbert_and_bigrams_truly_clean_w_splits))\n",
        "\n",
        "\n",
        "write.csv(L_cluster_w_cos_sim_from_distilbert_and_bigrams_truly_clean_w_splits, file = \"L_cluster_w_cos_sim_from_distilbert_and_bigrams_truly_clean_w_splits.csv\")\n",
        "\n",
        "write.csv(S_cluster_w_cos_sim_from_distilbert_and_bigrams_truly_clean_w_splits, file = \"S_cluster_w_cos_sim_from_distilbert_and_bigrams_truly_clean_w_splits.csv\")\n",
        "\n",
        "write.csv(T_cluster_w_cos_sim_from_distilbert_and_bigrams_truly_clean_w_splits, file = \"T_cluster_w_cos_sim_from_distilbert_and_bigrams_truly_clean_w_splits.csv\")\n",
        "\n"
      ],
      "metadata": {
        "id": "yTf0WjupMBMD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "L_cluster_verified_super = pd.read_csv(\"/content/L_cluster_truly_correct_spelling_splits_cleaned_text_FINAL_TEST_SET.csv\")\n",
        "\n",
        "L_cluster_verified_super_w_tfidf_cos_sim = pd.concat([L_cluster_verified_super, pd.DataFrame(cosine_similarity(vectorizer.fit_transform(L_cluster_verified_super.iloc[:,26].tolist())))], axis=1)\n",
        "\n",
        "L_cluster_verified_super_w_tfidf_cos_sim.to_csv('L_cluster_w_tfidf_cos_sim_FINAL_TEST_SET.csv',index=False)"
      ],
      "metadata": {
        "id": "prHlyhU9Tmns"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "S_cluster_verified_super = pd.read_csv(\"/content/S_cluster_truly_correct_spelling_splits_cleaned_text_FINAL_TEST_SET.csv\")\n",
        "\n",
        "S_cluster_verified_super_w_tfidf_cos_sim = pd.concat([S_cluster_verified_super, pd.DataFrame(cosine_similarity(vectorizer.fit_transform(S_cluster_verified_super.iloc[:,26].tolist())))], axis=1)\n",
        "\n",
        "S_cluster_verified_super_w_tfidf_cos_sim.to_csv('S_cluster_w_tfidf_cos_sim_FINAL_TEST_SET.csv',index=False)"
      ],
      "metadata": {
        "id": "tug5JGndTVM8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "T_cluster_verified_super = pd.read_csv(\"/content/T_cluster_truly_correct_spelling_splits_cleaned_text_FINAL_TEST_SET.csv\")\n",
        "\n",
        "T_cluster_verified_super_w_tfidf_cos_sim = pd.concat([T_cluster_verified_super, pd.DataFrame(cosine_similarity(vectorizer.fit_transform(T_cluster_verified_super.iloc[:,26].tolist())))], axis=1)\n",
        "\n",
        "T_cluster_verified_super_w_tfidf_cos_sim.to_csv('T_cluster_w_tfidf_cos_sim_FINAL_TEST_SET.csv',index=False)"
      ],
      "metadata": {
        "id": "9NOyu2CPTvuF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# then, tfidf (common col and other method), alone and get the ones from that \n",
        "\n",
        "L_cluster_w_tfidf_cos_sim_FINAL_TEST_SET = read.csv(\"/content/L_cluster_w_tfidf_cos_sim_FINAL_TEST_SET.csv\")\n",
        "S_cluster_w_tfidf_cos_sim_FINAL_TEST_SET = read.csv(\"/content/S_cluster_w_tfidf_cos_sim_FINAL_TEST_SET.csv\")\n",
        "T_cluster_w_tfidf_cos_sim_FINAL_TEST_SET = read.csv(\"/content/T_cluster_w_tfidf_cos_sim_FINAL_TEST_SET.csv\")\n",
        "\n",
        "# So first I need to get rid of the column names from being X\n",
        "colnames(L_cluster_w_tfidf_cos_sim_FINAL_TEST_SET)[1] = 'unnamed'\n",
        "colnames(S_cluster_w_tfidf_cos_sim_FINAL_TEST_SET)[1] = 'unnamed'\n",
        "colnames(T_cluster_w_tfidf_cos_sim_FINAL_TEST_SET)[1] = 'unnamed'\n",
        "\n",
        "L_cluster_w_tfidf_cos_sim_FINAL_TEST_SET = subset(L_cluster_w_tfidf_cos_sim_FINAL_TEST_SET, select = -c(unnamed))\n",
        "S_cluster_w_tfidf_cos_sim_FINAL_TEST_SET = subset(S_cluster_w_tfidf_cos_sim_FINAL_TEST_SET, select = -c(unnamed))\n",
        "T_cluster_w_tfidf_cos_sim_FINAL_TEST_SET = subset(T_cluster_w_tfidf_cos_sim_FINAL_TEST_SET, select = -c(unnamed))\n",
        "\n",
        "i = 28\n",
        "while(i <= ncol(L_cluster_w_tfidf_cos_sim_FINAL_TEST_SET))\n",
        "{\n",
        "  prev = colnames(L_cluster_w_tfidf_cos_sim_FINAL_TEST_SET)[i]\n",
        "  curr = str_c(\"tfidf_cosine_similarities\", prev, sep = \"_\")\n",
        "  colnames(L_cluster_w_tfidf_cos_sim_FINAL_TEST_SET)[i] = curr\n",
        "  i = i + 1\n",
        "}\n",
        "\n",
        "i = 28\n",
        "while(i <= ncol(S_cluster_w_tfidf_cos_sim_FINAL_TEST_SET))\n",
        "{\n",
        "  prev = colnames(S_cluster_w_tfidf_cos_sim_FINAL_TEST_SET)[i]\n",
        "  curr = str_c(\"tfidf_cosine_similarities\", prev, sep = \"_\")\n",
        "  colnames(S_cluster_w_tfidf_cos_sim_FINAL_TEST_SET)[i] = curr\n",
        "  i = i + 1\n",
        "}\n",
        "\n",
        "i = 28\n",
        "while(i <= ncol(T_cluster_w_tfidf_cos_sim_FINAL_TEST_SET))\n",
        "{\n",
        "  prev = colnames(T_cluster_w_tfidf_cos_sim_FINAL_TEST_SET)[i]\n",
        "  curr = str_c(\"tfidf_cosine_similarities\", prev, sep = \"_\")\n",
        "  colnames(T_cluster_w_tfidf_cos_sim_FINAL_TEST_SET)[i] = curr\n",
        "  i = i + 1\n",
        "}\n",
        "\n",
        "# Now I have to get rid of extraneous columns, and then merge with the distilbert_cs and bigrams_cs one \n",
        "\n",
        "L_cluster_w_tfidf_cos_sim_FINAL_TEST_SET = subset(L_cluster_w_tfidf_cos_sim_FINAL_TEST_SET, select = -c(\n",
        "  rating_chooses_appropriate_action,\n",
        "  rating_commits_to_action,\n",
        "  rating_gathers_information,\n",
        "  rating_identifies_issues_opportunities,\n",
        "  rating_interprets_information,\n",
        "  rating_involves_others,\n",
        "  rating_decision_making_final_score,\n",
        "  text_exercise_4,\n",
        "  text_exercise_5,\n",
        "  text_exercise_6,\n",
        "  text_exercise_7,\n",
        "  text_exercise_8,\n",
        "  text_exercise_9,\n",
        "  text_exercise_10,\n",
        "  text_exercise_11,\n",
        "  text_exercise_12,\n",
        "  text_exercise_13,\n",
        "  text_exercise_14,\n",
        "  text_exercise_15,\n",
        "  text_exercise_16,\n",
        "  text_exercise_17,\n",
        "  text_exercise_18,\n",
        "  text_exercise_19,\n",
        "  text_exercise_final,\n",
        "  super,\n",
        "  label\n",
        "))\n",
        "\n",
        "S_cluster_w_tfidf_cos_sim_FINAL_TEST_SET = subset(S_cluster_w_tfidf_cos_sim_FINAL_TEST_SET, select = -c(\n",
        "  rating_chooses_appropriate_action,\n",
        "  rating_commits_to_action,\n",
        "  rating_gathers_information,\n",
        "  rating_identifies_issues_opportunities,\n",
        "  rating_interprets_information,\n",
        "  rating_involves_others,\n",
        "  rating_decision_making_final_score,\n",
        "  text_exercise_4,\n",
        "  text_exercise_5,\n",
        "  text_exercise_6,\n",
        "  text_exercise_7,\n",
        "  text_exercise_8,\n",
        "  text_exercise_9,\n",
        "  text_exercise_10,\n",
        "  text_exercise_11,\n",
        "  text_exercise_12,\n",
        "  text_exercise_13,\n",
        "  text_exercise_14,\n",
        "  text_exercise_15,\n",
        "  text_exercise_16,\n",
        "  text_exercise_17,\n",
        "  text_exercise_18,\n",
        "  text_exercise_19,\n",
        "  text_exercise_final,\n",
        "  super,\n",
        "  label\n",
        "))\n",
        "\n",
        "T_cluster_w_tfidf_cos_sim_FINAL_TEST_SET = subset(T_cluster_w_tfidf_cos_sim_FINAL_TEST_SET, select = -c(\n",
        "  rating_chooses_appropriate_action,\n",
        "  rating_commits_to_action,\n",
        "  rating_gathers_information,\n",
        "  rating_identifies_issues_opportunities,\n",
        "  rating_interprets_information,\n",
        "  rating_involves_others,\n",
        "  rating_decision_making_final_score,\n",
        "  text_exercise_4,\n",
        "  text_exercise_5,\n",
        "  text_exercise_6,\n",
        "  text_exercise_7,\n",
        "  text_exercise_8,\n",
        "  text_exercise_9,\n",
        "  text_exercise_10,\n",
        "  text_exercise_11,\n",
        "  text_exercise_12,\n",
        "  text_exercise_13,\n",
        "  text_exercise_14,\n",
        "  text_exercise_15,\n",
        "  text_exercise_16,\n",
        "  text_exercise_17,\n",
        "  text_exercise_18,\n",
        "  text_exercise_19,\n",
        "  text_exercise_final,\n",
        "  super,\n",
        "  label\n",
        "))\n",
        "\n",
        "# Perfect, now I just need to merge with d_cs_b_cs_final_test_set one \n",
        "\n",
        "L_cluster_w_cos_sim_from_distilbert_and_bigrams_and_tfidf_truly_clean_w_splits = merge(L_cluster_w_cos_sim_from_distilbert_and_bigrams_truly_clean_w_splits, L_cluster_w_tfidf_cos_sim_FINAL_TEST_SET)\n",
        "S_cluster_w_cos_sim_from_distilbert_and_bigrams_and_tfidf_truly_clean_w_splits = merge(S_cluster_w_cos_sim_from_distilbert_and_bigrams_truly_clean_w_splits, S_cluster_w_tfidf_cos_sim_FINAL_TEST_SET)\n",
        "T_cluster_w_cos_sim_from_distilbert_and_bigrams_and_tfidf_truly_clean_w_splits = merge(T_cluster_w_cos_sim_from_distilbert_and_bigrams_truly_clean_w_splits, T_cluster_w_tfidf_cos_sim_FINAL_TEST_SET)\n",
        "\n",
        "train_L_cluster_w_cos_sim_from_distilbert_and_bigrams_and_tfidf_truly_clean_w_splits = subset(L_cluster_w_cos_sim_from_distilbert_and_bigrams_and_tfidf_truly_clean_w_splits, subset = L_cluster_w_cos_sim_from_distilbert_and_bigrams_and_tfidf_truly_clean_w_splits$label == 'train')\n",
        "dev_L_cluster_w_cos_sim_from_distilbert_and_bigrams_and_tfidf_truly_clean_w_splits = subset(L_cluster_w_cos_sim_from_distilbert_and_bigrams_and_tfidf_truly_clean_w_splits, subset = L_cluster_w_cos_sim_from_distilbert_and_bigrams_and_tfidf_truly_clean_w_splits$label == 'dev')\n",
        "\n",
        "train_S_cluster_w_cos_sim_from_distilbert_and_bigrams_and_tfidf_truly_clean_w_splits = subset(S_cluster_w_cos_sim_from_distilbert_and_bigrams_and_tfidf_truly_clean_w_splits, subset = S_cluster_w_cos_sim_from_distilbert_and_bigrams_and_tfidf_truly_clean_w_splits$label == 'train')\n",
        "dev_S_cluster_w_cos_sim_from_distilbert_and_bigrams_and_tfidf_truly_clean_w_splits = subset(S_cluster_w_cos_sim_from_distilbert_and_bigrams_and_tfidf_truly_clean_w_splits, subset = S_cluster_w_cos_sim_from_distilbert_and_bigrams_and_tfidf_truly_clean_w_splits$label == 'dev')\n",
        "\n",
        "train_T_cluster_w_cos_sim_from_distilbert_and_bigrams_and_tfidf_truly_clean_w_splits = subset(T_cluster_w_cos_sim_from_distilbert_and_bigrams_and_tfidf_truly_clean_w_splits, subset = T_cluster_w_cos_sim_from_distilbert_and_bigrams_and_tfidf_truly_clean_w_splits$label == 'train')\n",
        "dev_T_cluster_w_cos_sim_from_distilbert_and_bigrams_and_tfidf_truly_clean_w_splits = subset(T_cluster_w_cos_sim_from_distilbert_and_bigrams_and_tfidf_truly_clean_w_splits, subset = T_cluster_w_cos_sim_from_distilbert_and_bigrams_and_tfidf_truly_clean_w_splits$label == 'dev')\n",
        "\n",
        "write.csv(train_L_cluster_w_cos_sim_from_distilbert_and_bigrams_and_tfidf_truly_clean_w_splits, file = \"train_L_cluster_w_cos_sim_from_distilbert_and_bigrams_and_tfidf_truly_clean_w_splits_FINAL_TEST_SET.csv\")\n",
        "write.csv(train_S_cluster_w_cos_sim_from_distilbert_and_bigrams_and_tfidf_truly_clean_w_splits, file = \"train_S_cluster_w_cos_sim_from_distilbert_and_bigrams_and_tfidf_truly_clean_w_splits_FINAL_TEST_SET.csv\")\n",
        "write.csv(train_T_cluster_w_cos_sim_from_distilbert_and_bigrams_and_tfidf_truly_clean_w_splits, file = \"train_T_cluster_w_cos_sim_from_distilbert_and_bigrams_and_tfidf_truly_clean_w_splits_FINAL_TEST_SET.csv\")\n",
        "\n",
        "write.csv(dev_L_cluster_w_cos_sim_from_distilbert_and_bigrams_and_tfidf_truly_clean_w_splits, file = \"dev_L_cluster_w_cos_sim_from_distilbert_and_bigrams_and_tfidf_truly_clean_w_splits_FINAL_TEST_SET.csv\")\n",
        "write.csv(dev_S_cluster_w_cos_sim_from_distilbert_and_bigrams_and_tfidf_truly_clean_w_splits, file = \"dev_S_cluster_w_cos_sim_from_distilbert_and_bigrams_and_tfidf_truly_clean_w_splits_FINAL_TEST_SET.csv\")\n",
        "write.csv(dev_T_cluster_w_cos_sim_from_distilbert_and_bigrams_and_tfidf_truly_clean_w_splits, file = \"dev_T_cluster_w_cos_sim_from_distilbert_and_bigrams_and_tfidf_truly_clean_w_splits_FINAL_TEST_SET.csv\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-7qVgCoIT6cu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.model_selection import train_test_split\n",
        "import sys\n",
        "from sklearn.linear_model import Ridge\n",
        "import time\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "# import torch\n",
        "from sklearn.linear_model import Ridge, RidgeCV, Lasso, LassoCV\n",
        "from sklearn.preprocessing import scale\n",
        "from sklearn.preprocessing import scale, StandardScaler\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "\n",
        "# Set pandas options to allow more printing rows/columns\n",
        "pd.set_option(\"display.max_rows\", 4000)\n",
        "pd.set_option(\"display.max_columns\", 4000)\n",
        "\n",
        "\n",
        "train_pub_df = pd.read_csv(\"/content/train_L_cluster_w_cos_sim_from_distilbert_and_bigrams_and_tfidf_truly_clean_w_splits_FINAL_TEST_SET.csv\")\n",
        "dev_pub_df = pd.read_csv(\"/content/dev_L_cluster_w_cos_sim_from_distilbert_and_bigrams_and_tfidf_truly_clean_w_splits_FINAL_TEST_SET.csv\")\n",
        "\n",
        "\n",
        "# computing number of columns\n",
        "cols = len(train_pub_df.axes[1])\n",
        "# print(cols)\n",
        "\n",
        "\n",
        "cols = train_pub_df.axes[1]\n",
        "# print(cols)\n",
        "\n",
        "\n",
        "print('got that ')\n",
        "X = train_pub_df.drop(['Unnamed: 0', 'response_id', 'super', 'rating_chooses_appropriate_action','rating_commits_to_action','rating_gathers_information','rating_identifies_issues_opportunities','rating_interprets_information', 'rating_involves_others', \"rating_decision_making_final_score\", 'text_exercise_4',\n",
        "    'text_exercise_5',\n",
        "    'text_exercise_6',\n",
        "    'text_exercise_7',\n",
        "    \"text_exercise_8\",\n",
        "    \"text_exercise_9\",\n",
        "    \"text_exercise_10\",\n",
        "    \"text_exercise_11\",\n",
        "    \"text_exercise_12\",\n",
        "    \"text_exercise_13\",\n",
        "    \"text_exercise_14\",\n",
        "    \"text_exercise_15\",\n",
        "    \"text_exercise_16\",\n",
        "    \"text_exercise_17\",\n",
        "    \"text_exercise_18\",\n",
        "    \"text_exercise_19\",\n",
        "    \"text_exercise_final\", \n",
        "    'label'], axis=1)\n",
        "\n",
        "ys = train_pub_df[['rating_chooses_appropriate_action','rating_commits_to_action','rating_gathers_information','rating_identifies_issues_opportunities','rating_interprets_information', 'rating_involves_others', \"rating_decision_making_final_score\"]]\n",
        "\n",
        "cols = len(X.axes[1])\n",
        "# print(cols)\n",
        "\n",
        "cols_div_3 = (cols) // 3 \n",
        "print(f\"{cols_div_3=}\")\n",
        "\n",
        "X_dev = dev_pub_df.drop(['Unnamed: 0', 'response_id', 'super', 'rating_chooses_appropriate_action','rating_commits_to_action','rating_gathers_information','rating_identifies_issues_opportunities','rating_interprets_information', 'rating_involves_others', \"rating_decision_making_final_score\", 'text_exercise_4',\n",
        "    'text_exercise_5',\n",
        "    'text_exercise_6',\n",
        "    'text_exercise_7',\n",
        "    \"text_exercise_8\",\n",
        "    \"text_exercise_9\",\n",
        "    \"text_exercise_10\",\n",
        "    \"text_exercise_11\",\n",
        "    \"text_exercise_12\",\n",
        "    \"text_exercise_13\",\n",
        "    \"text_exercise_14\",\n",
        "    \"text_exercise_15\",\n",
        "    \"text_exercise_16\",\n",
        "    \"text_exercise_17\",\n",
        "    \"text_exercise_18\",\n",
        "    \"text_exercise_19\",\n",
        "    \"text_exercise_final\", \n",
        "    \"label\"], axis=1)\n",
        "\n",
        "\n",
        "\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,ys, test_size = 0.2 ,random_state= 42)\n",
        "\n",
        "def run_ridge(X_train, X_test, y_train, y_test, y_label, prediction_vector):\n",
        "    ridge = Ridge()\n",
        "    ridge.fit(X_train,y_train[y_label])\n",
        "    # test_preds = ridge.predict(X_test)\n",
        "    # test = pd.DataFrame(y_test[y_label])\n",
        "    # test['Pred_score'] = test_preds\n",
        "    # return test.corr().values[0][1]\n",
        "    dev_pred = ridge.predict(prediction_vector)\n",
        "    return dev_pred\n",
        "\n",
        "\n",
        "def run_rf(X_train, X_test, y_train, y_test, y_label, prediction_vector):\n",
        "    rf = RandomForestRegressor(max_depth=5, random_state=42, max_features=cols_div_3 + 1) #, max_features=9962 # or .333\n",
        "    rf.fit(X_train,np.ravel(y_train[y_label],order='C'))\n",
        "    # test_preds = rf.predict(X_test)\n",
        "    # test = pd.DataFrame(y_test[y_label])\n",
        "    # test['Pred_score'] = test_preds\n",
        "    # return test.corr().values[0][1]\n",
        "    dev_pred = rf.predict(prediction_vector)\n",
        "    return dev_pred\n",
        "\n",
        "def run_bag(X_train, X_test, y_train, y_test, y_label, prediction_vector):\n",
        "    rf = RandomForestRegressor(max_depth=5, random_state=42) #, max_features=9962 # or .333\n",
        "    rf.fit(X_train,np.ravel(y_train[y_label],order='C'))\n",
        "    # test_preds = rf.predict(X_test)\n",
        "    # test = pd.DataFrame(y_test[y_label])\n",
        "    # test['Pred_score'] = test_preds\n",
        "    # return test.corr().values[0][1]\n",
        "    dev_pred = rf.predict(prediction_vector)\n",
        "    return dev_pred\n",
        "\n",
        "\n",
        "def run_knn(X_train, X_test, y_train, y_test, y_label, prediction_vector):\n",
        "    knn = KNeighborsRegressor(n_neighbors=93, p=2, weights=\"distance\")\n",
        "    knn.fit(X_train,y_train[y_label])\n",
        "    # test_preds = knn.predict(X_test)\n",
        "    # test = pd.DataFrame(y_test[y_label])\n",
        "    # test['Pred_score'] = test_preds\n",
        "    # return test.corr().values[0][1]\n",
        "    dev_pred = knn.predict(prediction_vector)\n",
        "    return dev_pred\n",
        "\n",
        "\n",
        "def new_run_ridge(X_train, X_test, y_train, y_test, y_label, prediction_vector):\n",
        "    scaler = StandardScaler().set_output(transform=\"pandas\")\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "    X_test = scaler.fit_transform(X_test)\n",
        "    grid = 10 ** np.linspace(3,-2,100)\n",
        "    ridge_cv = RidgeCV(alphas=grid, scoring='neg_mean_squared_error')\n",
        "    ridge_cv.fit(X_train,y_train[y_label])\n",
        "    ridge_cv.alpha_\n",
        "    ridge5 = Ridge(alpha=ridge_cv.alpha_)\n",
        "    ridge5_fit = ridge5.fit(X_train,y_train[y_label])\n",
        "    # test_preds = ridge5_fit.predict(X_test)\n",
        "    # test = pd.DataFrame(y_test[y_label])\n",
        "    # test['Pred_score'] = test_preds\n",
        "    # return test.corr().values[0][1]\n",
        "    dev_pred = ridge5_fit.predict(prediction_vector)\n",
        "    return dev_pred\n",
        "\n",
        "\n",
        "def run_lasso(X_train, X_test, y_train, y_test, y_label, prediction_vector):\n",
        "    scaler = StandardScaler().set_output(transform=\"pandas\")\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "    X_test = scaler.fit_transform(X_test)\n",
        "    grid = 10 ** np.linspace(3,-2,100)\n",
        "    lasso_cv = LassoCV(alphas=grid, cv=10)#,max_iter=100000,)\n",
        "    lasso_cv.fit(X_train,np.ravel(y_train[y_label],order='C'))\n",
        "    lasso_cv.alpha_\n",
        "    lasso2 = Lasso(alpha=lasso_cv.alpha_)#, max_iter=10000)\n",
        "    lasso2_fit = lasso2.fit(X_train,np.ravel(y_train[y_label],order='C'))\n",
        "    # test_preds = lasso2_fit.predict(X_test)\n",
        "    # test = pd.DataFrame(y_test[y_label])\n",
        "    # test['Pred_score'] = test_preds\n",
        "    # return test.corr().values[0][1]\n",
        "    dev_pred = lasso2_fit.predict(prediction_vector)\n",
        "    return dev_pred\n",
        "\n",
        "\n",
        "# [rf, rf, newridge, newridge, newridge, newridge, lasso ]\n",
        "\n",
        "# rating_chooses_appropriate_action\n",
        "rating_chooses_appropriate_action_pred = run_ridge(X, X, ys, ys, ['rating_chooses_appropriate_action'], X_dev)\n",
        "print('finished one of those')\n",
        "dev_pub_df['rating_chooses_appropriate_action_pred'] = rating_chooses_appropriate_action_pred\n",
        "# rating_commits_to_action\n",
        "rating_commits_to_action_pred = run_ridge(X, X, ys, ys, ['rating_commits_to_action'], X_dev)\n",
        "dev_pub_df['rating_commits_to_action_pred'] = rating_commits_to_action_pred\n",
        "\n",
        "# rating_gathers_information\n",
        "rating_gathers_information_pred = run_ridge(X, X, ys, ys, ['rating_gathers_information'], X_dev)\n",
        "dev_pub_df['rating_gathers_information_pred'] = rating_gathers_information_pred\n",
        "\n",
        "# rating_identifies_issues_opportunities\n",
        "rating_identifies_issues_opportunities_pred = run_ridge(X, X, ys, ys, ['rating_identifies_issues_opportunities'], X_dev)\n",
        "dev_pub_df['rating_identifies_issues_opportunities_pred'] = rating_identifies_issues_opportunities_pred\n",
        "\n",
        "# rating_interprets_information\n",
        "rating_interprets_information_pred = run_ridge(X, X, ys, ys, ['rating_interprets_information'], X_dev)\n",
        "dev_pub_df['rating_interprets_information_pred'] = rating_interprets_information_pred\n",
        "\n",
        "# rating_involves_others\n",
        "rating_involves_others_pred = run_ridge(X, X, ys, ys, ['rating_involves_others'], X_dev)\n",
        "dev_pub_df['rating_involves_others_pred'] = rating_involves_others_pred\n",
        "\n",
        "# rating_decision_making_final_score\n",
        "rating_decision_making_final_score_pred = run_ridge(X, X, ys, ys, ['rating_decision_making_final_score'], X_dev)\n",
        "dev_pub_df['rating_decision_making_final_score_pred'] = rating_decision_making_final_score_pred\n",
        "\n",
        "dev_pub_df.to_csv('old_ridge_L_cluster_cleaned_text_truly_clean_w_splits_w_bigrams_cos_sim_and_distilbert_cos_sim_and_tfidf_cos_sim_FINAL_TEST_SET.csv',index=False)\n",
        "print('done')\n"
      ],
      "metadata": {
        "id": "aLZx7GyTkB6j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.model_selection import train_test_split\n",
        "import sys\n",
        "from sklearn.linear_model import Ridge\n",
        "import time\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "# import torch\n",
        "from sklearn.linear_model import Ridge, RidgeCV, Lasso, LassoCV\n",
        "from sklearn.preprocessing import scale\n",
        "from sklearn.preprocessing import scale, StandardScaler\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "\n",
        "# Set pandas options to allow more printing rows/columns\n",
        "pd.set_option(\"display.max_rows\", 4000)\n",
        "pd.set_option(\"display.max_columns\", 4000)\n",
        "\n",
        "train_pub_df = pd.read_csv(\"/content/train_S_cluster_w_cos_sim_from_distilbert_and_bigrams_and_tfidf_truly_clean_w_splits_FINAL_TEST_SET.csv\")\n",
        "dev_pub_df = pd.read_csv(\"/content/dev_S_cluster_w_cos_sim_from_distilbert_and_bigrams_and_tfidf_truly_clean_w_splits_FINAL_TEST_SET.csv\")\n",
        "\n",
        "# computing number of columns\n",
        "cols = len(train_pub_df.axes[1])\n",
        "# print(cols)\n",
        "\n",
        "cols = train_pub_df.axes[1]\n",
        "# print(cols)\n",
        "\n",
        "\n",
        "print('got that ')\n",
        "X = train_pub_df.drop(['Unnamed: 0', 'response_id', 'super', 'rating_chooses_appropriate_action','rating_commits_to_action','rating_gathers_information','rating_identifies_issues_opportunities','rating_interprets_information', 'rating_involves_others', \"rating_decision_making_final_score\", 'text_exercise_4',\n",
        "    'text_exercise_5',\n",
        "    'text_exercise_6',\n",
        "    'text_exercise_7',\n",
        "    \"text_exercise_8\",\n",
        "    \"text_exercise_9\",\n",
        "    \"text_exercise_10\",\n",
        "    \"text_exercise_11\",\n",
        "    \"text_exercise_12\",\n",
        "    \"text_exercise_13\",\n",
        "    \"text_exercise_14\",\n",
        "    \"text_exercise_15\",\n",
        "    \"text_exercise_16\",\n",
        "    \"text_exercise_17\",\n",
        "    \"text_exercise_18\",\n",
        "    \"text_exercise_19\",\n",
        "    \"text_exercise_final\", \n",
        "    'label'], axis=1)\n",
        "\n",
        "# X = new_train_pub_df[['te_final_compound','te_final_neg','te_final_neu','te_final_pos','te_19_compound','te_19_neg','te_19_neu','te_19_pos','te_17_compound','te_17_neg','te_17_neu','te_17_pos', 'te_15_compound','te_15_neg','te_15_neu','te_15_pos', 'te_14_compound','te_14_neg','te_14_neu','te_14_pos', 'te_12_compound','te_12_neg','te_12_neu','te_12_pos', 'te_11_compound','te_11_neg','te_11_neu','te_11_pos', 'te_9_compound','te_9_neg','te_9_neu','te_9_pos', 'te_7_compound','te_7_neg','te_7_neu','te_7_pos', 'te_6_compound','te_6_neg','te_6_neu','te_6_pos']]\n",
        "ys = train_pub_df[['rating_chooses_appropriate_action','rating_commits_to_action','rating_gathers_information','rating_identifies_issues_opportunities','rating_interprets_information', 'rating_involves_others', \"rating_decision_making_final_score\"]]\n",
        "\n",
        "cols = len(X.axes[1])\n",
        "# print(cols)\n",
        "\n",
        "cols_div_3 = (cols) // 3 \n",
        "print(f\"{cols_div_3=}\")\n",
        "\n",
        "X_dev = dev_pub_df.drop(['Unnamed: 0', 'response_id', 'super', 'rating_chooses_appropriate_action','rating_commits_to_action','rating_gathers_information','rating_identifies_issues_opportunities','rating_interprets_information', 'rating_involves_others', \"rating_decision_making_final_score\", 'text_exercise_4',\n",
        "    'text_exercise_5',\n",
        "    'text_exercise_6',\n",
        "    'text_exercise_7',\n",
        "    \"text_exercise_8\",\n",
        "    \"text_exercise_9\",\n",
        "    \"text_exercise_10\",\n",
        "    \"text_exercise_11\",\n",
        "    \"text_exercise_12\",\n",
        "    \"text_exercise_13\",\n",
        "    \"text_exercise_14\",\n",
        "    \"text_exercise_15\",\n",
        "    \"text_exercise_16\",\n",
        "    \"text_exercise_17\",\n",
        "    \"text_exercise_18\",\n",
        "    \"text_exercise_19\",\n",
        "    \"text_exercise_final\", \n",
        "    \"label\"], axis=1)\n",
        "\n",
        "\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,ys, test_size = 0.2 ,random_state= 42)\n",
        "\n",
        "def run_ridge(X_train, X_test, y_train, y_test, y_label, prediction_vector):\n",
        "    ridge = Ridge()\n",
        "    ridge.fit(X_train,y_train[y_label])\n",
        "    # test_preds = ridge.predict(X_test)\n",
        "    # test = pd.DataFrame(y_test[y_label])\n",
        "    # test['Pred_score'] = test_preds\n",
        "    # return test.corr().values[0][1]\n",
        "    dev_pred = ridge.predict(prediction_vector)\n",
        "    return dev_pred\n",
        "\n",
        "\n",
        "def run_rf(X_train, X_test, y_train, y_test, y_label, prediction_vector):\n",
        "    rf = RandomForestRegressor(max_depth=5, random_state=42, max_features=cols_div_3 + 1) #, max_features=9962 # or .333\n",
        "    rf.fit(X_train,np.ravel(y_train[y_label],order='C'))\n",
        "    # test_preds = rf.predict(X_test)\n",
        "    # test = pd.DataFrame(y_test[y_label])\n",
        "    # test['Pred_score'] = test_preds\n",
        "    # return test.corr().values[0][1]\n",
        "    dev_pred = rf.predict(prediction_vector)\n",
        "    return dev_pred\n",
        "\n",
        "def run_bag(X_train, X_test, y_train, y_test, y_label, prediction_vector):\n",
        "    rf = RandomForestRegressor(max_depth=5, random_state=42) #, max_features=9962 # or .333\n",
        "    rf.fit(X_train,np.ravel(y_train[y_label],order='C'))\n",
        "    # test_preds = rf.predict(X_test)\n",
        "    # test = pd.DataFrame(y_test[y_label])\n",
        "    # test['Pred_score'] = test_preds\n",
        "    # return test.corr().values[0][1]\n",
        "    dev_pred = rf.predict(prediction_vector)\n",
        "    return dev_pred\n",
        "\n",
        "\n",
        "def run_knn(X_train, X_test, y_train, y_test, y_label, prediction_vector):\n",
        "    knn = KNeighborsRegressor(n_neighbors=93, p=2, weights=\"distance\")\n",
        "    knn.fit(X_train,y_train[y_label])\n",
        "    # test_preds = knn.predict(X_test)\n",
        "    # test = pd.DataFrame(y_test[y_label])\n",
        "    # test['Pred_score'] = test_preds\n",
        "    # return test.corr().values[0][1]\n",
        "    dev_pred = knn.predict(prediction_vector)\n",
        "    return dev_pred\n",
        "\n",
        "\n",
        "def new_run_ridge(X_train, X_test, y_train, y_test, y_label, prediction_vector):\n",
        "    scaler = StandardScaler().set_output(transform=\"pandas\")\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "    X_test = scaler.fit_transform(X_test)\n",
        "    grid = 10 ** np.linspace(3,-2,100)\n",
        "    ridge_cv = RidgeCV(alphas=grid, scoring='neg_mean_squared_error')\n",
        "    ridge_cv.fit(X_train,y_train[y_label])\n",
        "    ridge_cv.alpha_\n",
        "    ridge5 = Ridge(alpha=ridge_cv.alpha_)\n",
        "    ridge5_fit = ridge5.fit(X_train,y_train[y_label])\n",
        "    # test_preds = ridge5_fit.predict(X_test)\n",
        "    # test = pd.DataFrame(y_test[y_label])\n",
        "    # test['Pred_score'] = test_preds\n",
        "    # return test.corr().values[0][1]\n",
        "    dev_pred = ridge5_fit.predict(prediction_vector)\n",
        "    return dev_pred\n",
        "\n",
        "\n",
        "def run_lasso(X_train, X_test, y_train, y_test, y_label, prediction_vector):\n",
        "    scaler = StandardScaler().set_output(transform=\"pandas\")\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "    X_test = scaler.fit_transform(X_test)\n",
        "    grid = 10 ** np.linspace(3,-2,100)\n",
        "    lasso_cv = LassoCV(alphas=grid, cv=10)#,max_iter=100000,)\n",
        "    lasso_cv.fit(X_train,np.ravel(y_train[y_label],order='C'))\n",
        "    lasso_cv.alpha_\n",
        "    lasso2 = Lasso(alpha=lasso_cv.alpha_)#, max_iter=10000)\n",
        "    lasso2_fit = lasso2.fit(X_train,np.ravel(y_train[y_label],order='C'))\n",
        "    # test_preds = lasso2_fit.predict(X_test)\n",
        "    # test = pd.DataFrame(y_test[y_label])\n",
        "    # test['Pred_score'] = test_preds\n",
        "    # return test.corr().values[0][1]\n",
        "    dev_pred = lasso2_fit.predict(prediction_vector)\n",
        "    return dev_pred\n",
        "\n",
        "\n",
        "# [ bag, rf, rf, bag, bag, bag, rf ]\n",
        "\n",
        "# rating_chooses_appropriate_action\n",
        "rating_chooses_appropriate_action_pred = run_bag(X, X, ys, ys, ['rating_chooses_appropriate_action'], X_dev)\n",
        "print('finished one of those')\n",
        "dev_pub_df['rating_chooses_appropriate_action_pred'] = rating_chooses_appropriate_action_pred\n",
        "# rating_commits_to_action\n",
        "rating_commits_to_action_pred = run_rf(X, X, ys, ys, ['rating_commits_to_action'], X_dev)\n",
        "dev_pub_df['rating_commits_to_action_pred'] = rating_commits_to_action_pred\n",
        "\n",
        "# rating_gathers_information\n",
        "rating_gathers_information_pred = run_rf(X, X, ys, ys, ['rating_gathers_information'], X_dev)\n",
        "dev_pub_df['rating_gathers_information_pred'] = rating_gathers_information_pred\n",
        "\n",
        "# rating_identifies_issues_opportunities\n",
        "rating_identifies_issues_opportunities_pred = run_bag(X, X, ys, ys, ['rating_identifies_issues_opportunities'], X_dev)\n",
        "dev_pub_df['rating_identifies_issues_opportunities_pred'] = rating_identifies_issues_opportunities_pred\n",
        "\n",
        "# rating_interprets_information\n",
        "rating_interprets_information_pred = run_bag(X, X, ys, ys, ['rating_interprets_information'], X_dev)\n",
        "dev_pub_df['rating_interprets_information_pred'] = rating_interprets_information_pred\n",
        "\n",
        "# rating_involves_others\n",
        "rating_involves_others_pred = run_bag(X, X, ys, ys, ['rating_involves_others'], X_dev)\n",
        "dev_pub_df['rating_involves_others_pred'] = rating_involves_others_pred\n",
        "\n",
        "# rating_decision_making_final_score\n",
        "rating_decision_making_final_score_pred = run_rf(X, X, ys, ys, ['rating_decision_making_final_score'], X_dev)\n",
        "dev_pub_df['rating_decision_making_final_score_pred'] = rating_decision_making_final_score_pred\n",
        "\n",
        "dev_pub_df.to_csv('old_ridge_S_cluster_cleaned_text_truly_clean_w_splits_w_bigrams_cos_sim_and_distilbert_cos_sim_and_tfidf_cos_sim_FINAL_TEST_SET.csv',index=False)\n",
        "print('done')\n"
      ],
      "metadata": {
        "id": "uf-8kSq6kCJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.model_selection import train_test_split\n",
        "import sys\n",
        "from sklearn.linear_model import Ridge\n",
        "import time\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "# import torch\n",
        "from sklearn.linear_model import Ridge, RidgeCV, Lasso, LassoCV\n",
        "from sklearn.preprocessing import scale\n",
        "from sklearn.preprocessing import scale, StandardScaler\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "\n",
        "# Set pandas options to allow more printing rows/columns\n",
        "pd.set_option(\"display.max_rows\", 4000)\n",
        "pd.set_option(\"display.max_columns\", 4000)\n",
        "\n",
        "train_pub_df = pd.read_csv(\"/content/train_T_cluster_w_cos_sim_from_distilbert_and_bigrams_and_tfidf_truly_clean_w_splits_FINAL_TEST_SET.csv\")\n",
        "dev_pub_df = pd.read_csv(\"/content/dev_T_cluster_w_cos_sim_from_distilbert_and_bigrams_and_tfidf_truly_clean_w_splits_FINAL_TEST_SET.csv\")\n",
        "\n",
        "# computing number of columns\n",
        "cols = len(train_pub_df.axes[1])\n",
        "# print(cols)\n",
        "\n",
        "cols = train_pub_df.axes[1]\n",
        "# print(cols)\n",
        "\n",
        "print('got that ')\n",
        "X = train_pub_df.drop(['Unnamed: 0', 'response_id', 'super', 'rating_chooses_appropriate_action','rating_commits_to_action','rating_gathers_information','rating_identifies_issues_opportunities','rating_interprets_information', 'rating_involves_others', \"rating_decision_making_final_score\", 'text_exercise_4',\n",
        "    'text_exercise_5',\n",
        "    'text_exercise_6',\n",
        "    'text_exercise_7',\n",
        "    \"text_exercise_8\",\n",
        "    \"text_exercise_9\",\n",
        "    \"text_exercise_10\",\n",
        "    \"text_exercise_11\",\n",
        "    \"text_exercise_12\",\n",
        "    \"text_exercise_13\",\n",
        "    \"text_exercise_14\",\n",
        "    \"text_exercise_15\",\n",
        "    \"text_exercise_16\",\n",
        "    \"text_exercise_17\",\n",
        "    \"text_exercise_18\",\n",
        "    \"text_exercise_19\",\n",
        "    \"text_exercise_final\", \n",
        "    'label'], axis=1)\n",
        "\n",
        "# X = new_train_pub_df[['te_final_compound','te_final_neg','te_final_neu','te_final_pos','te_19_compound','te_19_neg','te_19_neu','te_19_pos','te_17_compound','te_17_neg','te_17_neu','te_17_pos', 'te_15_compound','te_15_neg','te_15_neu','te_15_pos', 'te_14_compound','te_14_neg','te_14_neu','te_14_pos', 'te_12_compound','te_12_neg','te_12_neu','te_12_pos', 'te_11_compound','te_11_neg','te_11_neu','te_11_pos', 'te_9_compound','te_9_neg','te_9_neu','te_9_pos', 'te_7_compound','te_7_neg','te_7_neu','te_7_pos', 'te_6_compound','te_6_neg','te_6_neu','te_6_pos']]\n",
        "ys = train_pub_df[['rating_chooses_appropriate_action','rating_commits_to_action','rating_gathers_information','rating_identifies_issues_opportunities','rating_interprets_information', 'rating_involves_others', \"rating_decision_making_final_score\"]]\n",
        "\n",
        "cols = len(X.axes[1])\n",
        "# print(cols)\n",
        "\n",
        "cols_div_3 = (cols) // 3 \n",
        "# print(f\"{cols_div_3=}\")\n",
        "\n",
        "X_dev = dev_pub_df.drop(['Unnamed: 0', 'response_id', 'super', 'rating_chooses_appropriate_action','rating_commits_to_action','rating_gathers_information','rating_identifies_issues_opportunities','rating_interprets_information', 'rating_involves_others', \"rating_decision_making_final_score\", 'text_exercise_4',\n",
        "    'text_exercise_5',\n",
        "    'text_exercise_6',\n",
        "    'text_exercise_7',\n",
        "    \"text_exercise_8\",\n",
        "    \"text_exercise_9\",\n",
        "    \"text_exercise_10\",\n",
        "    \"text_exercise_11\",\n",
        "    \"text_exercise_12\",\n",
        "    \"text_exercise_13\",\n",
        "    \"text_exercise_14\",\n",
        "    \"text_exercise_15\",\n",
        "    \"text_exercise_16\",\n",
        "    \"text_exercise_17\",\n",
        "    \"text_exercise_18\",\n",
        "    \"text_exercise_19\",\n",
        "    \"text_exercise_final\", \n",
        "    \"label\"], axis=1)\n",
        "\n",
        "\n",
        "# ys = train_pub_df[[\"rating_decision_making_final_score\"]]\n",
        "\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,ys, test_size = 0.2 ,random_state= 42)\n",
        "\n",
        "def run_ridge(X_train, X_test, y_train, y_test, y_label, prediction_vector):\n",
        "    ridge = Ridge()\n",
        "    ridge.fit(X_train,y_train[y_label])\n",
        "    # test_preds = ridge.predict(X_test)\n",
        "    # test = pd.DataFrame(y_test[y_label])\n",
        "    # test['Pred_score'] = test_preds\n",
        "    # return test.corr().values[0][1]\n",
        "    dev_pred = ridge.predict(prediction_vector)\n",
        "    return dev_pred\n",
        "\n",
        "\n",
        "def run_rf(X_train, X_test, y_train, y_test, y_label, prediction_vector):\n",
        "    rf = RandomForestRegressor(max_depth=5, random_state=42, max_features=cols_div_3 + 1) #, max_features=9962 # or .333\n",
        "    rf.fit(X_train,np.ravel(y_train[y_label],order='C'))\n",
        "    # test_preds = rf.predict(X_test)\n",
        "    # test = pd.DataFrame(y_test[y_label])\n",
        "    # test['Pred_score'] = test_preds\n",
        "    # return test.corr().values[0][1]\n",
        "    dev_pred = rf.predict(prediction_vector)\n",
        "    return dev_pred\n",
        "\n",
        "def run_bag(X_train, X_test, y_train, y_test, y_label, prediction_vector):\n",
        "    rf = RandomForestRegressor(max_depth=5, random_state=42) #, max_features=9962 # or .333\n",
        "    rf.fit(X_train,np.ravel(y_train[y_label],order='C'))\n",
        "    # test_preds = rf.predict(X_test)\n",
        "    # test = pd.DataFrame(y_test[y_label])\n",
        "    # test['Pred_score'] = test_preds\n",
        "    # return test.corr().values[0][1]\n",
        "    dev_pred = rf.predict(prediction_vector)\n",
        "    return dev_pred\n",
        "\n",
        "\n",
        "def run_knn(X_train, X_test, y_train, y_test, y_label, prediction_vector):\n",
        "    knn = KNeighborsRegressor(n_neighbors=93, p=2, weights=\"distance\")\n",
        "    knn.fit(X_train,y_train[y_label])\n",
        "    # test_preds = knn.predict(X_test)\n",
        "    # test = pd.DataFrame(y_test[y_label])\n",
        "    # test['Pred_score'] = test_preds\n",
        "    # return test.corr().values[0][1]\n",
        "    dev_pred = knn.predict(prediction_vector)\n",
        "    return dev_pred\n",
        "\n",
        "\n",
        "def new_run_ridge(X_train, X_test, y_train, y_test, y_label, prediction_vector):\n",
        "    scaler = StandardScaler().set_output(transform=\"pandas\")\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "    X_test = scaler.fit_transform(X_test)\n",
        "    grid = 10 ** np.linspace(3,-2,100)\n",
        "    ridge_cv = RidgeCV(alphas=grid, scoring='neg_mean_squared_error')\n",
        "    ridge_cv.fit(X_train,y_train[y_label])\n",
        "    ridge_cv.alpha_\n",
        "    ridge5 = Ridge(alpha=ridge_cv.alpha_)\n",
        "    ridge5_fit = ridge5.fit(X_train,y_train[y_label])\n",
        "    # test_preds = ridge5_fit.predict(X_test)\n",
        "    # test = pd.DataFrame(y_test[y_label])\n",
        "    # test['Pred_score'] = test_preds\n",
        "    # return test.corr().values[0][1]\n",
        "    dev_pred = ridge5_fit.predict(prediction_vector)\n",
        "    return dev_pred\n",
        "\n",
        "\n",
        "def run_lasso(X_train, X_test, y_train, y_test, y_label, prediction_vector):\n",
        "    scaler = StandardScaler().set_output(transform=\"pandas\")\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "    X_test = scaler.fit_transform(X_test)\n",
        "    grid = 10 ** np.linspace(3,-2,100)\n",
        "    lasso_cv = LassoCV(alphas=grid, cv=10)#,max_iter=100000,)\n",
        "    lasso_cv.fit(X_train,np.ravel(y_train[y_label],order='C'))\n",
        "    lasso_cv.alpha_\n",
        "    lasso2 = Lasso(alpha=lasso_cv.alpha_)#, max_iter=10000)\n",
        "    lasso2_fit = lasso2.fit(X_train,np.ravel(y_train[y_label],order='C'))\n",
        "    # test_preds = lasso2_fit.predict(X_test)\n",
        "    # test = pd.DataFrame(y_test[y_label])\n",
        "    # test['Pred_score'] = test_preds\n",
        "    # return test.corr().values[0][1]\n",
        "    dev_pred = lasso2_fit.predict(prediction_vector)\n",
        "    return dev_pred\n",
        "\n",
        "\n",
        "# [ rf, bag, old_ridge, old_ridge, rf, rf, old_ridge ]\n",
        "\n",
        "# rating_chooses_appropriate_action\n",
        "rating_chooses_appropriate_action_pred = run_rf(X, X, ys, ys, ['rating_chooses_appropriate_action'], X_dev)\n",
        "print('finished one of those')\n",
        "dev_pub_df['rating_chooses_appropriate_action_pred'] = rating_chooses_appropriate_action_pred\n",
        "# rating_commits_to_action\n",
        "rating_commits_to_action_pred = run_bag(X, X, ys, ys, ['rating_commits_to_action'], X_dev)\n",
        "dev_pub_df['rating_commits_to_action_pred'] = rating_commits_to_action_pred\n",
        "\n",
        "# rating_gathers_information\n",
        "rating_gathers_information_pred = run_ridge(X, X, ys, ys, ['rating_gathers_information'], X_dev)\n",
        "dev_pub_df['rating_gathers_information_pred'] = rating_gathers_information_pred\n",
        "\n",
        "# rating_identifies_issues_opportunities\n",
        "rating_identifies_issues_opportunities_pred = run_ridge(X, X, ys, ys, ['rating_identifies_issues_opportunities'], X_dev)\n",
        "dev_pub_df['rating_identifies_issues_opportunities_pred'] = rating_identifies_issues_opportunities_pred\n",
        "\n",
        "# rating_interprets_information\n",
        "rating_interprets_information_pred = run_rf(X, X, ys, ys, ['rating_interprets_information'], X_dev)\n",
        "dev_pub_df['rating_interprets_information_pred'] = rating_interprets_information_pred\n",
        "\n",
        "# rating_involves_others\n",
        "rating_involves_others_pred = run_rf(X, X, ys, ys, ['rating_involves_others'], X_dev)\n",
        "dev_pub_df['rating_involves_others_pred'] = rating_involves_others_pred\n",
        "\n",
        "# rating_decision_making_final_score\n",
        "rating_decision_making_final_score_pred = run_ridge(X, X, ys, ys, ['rating_decision_making_final_score'], X_dev)\n",
        "dev_pub_df['rating_decision_making_final_score_pred'] = rating_decision_making_final_score_pred\n",
        "\n",
        "dev_pub_df.to_csv('old_ridge_T_cluster_cleaned_text_truly_clean_w_splits_w_bigrams_cos_sim_and_distilbert_cos_sim_and_tfidf_cos_sim_FINAL_TEST_SET.csv',index=False)\n",
        "print('done')\n"
      ],
      "metadata": {
        "id": "aZrLD3AYkCVw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "\n",
        "# Now read it back from python \n",
        "\n",
        "old_ridge_L_cluster_ctws_dbt_cs_FINAL_TEST_SET = read.csv(\"/content/old_ridge_L_cluster_cleaned_text_truly_clean_w_splits_w_bigrams_cos_sim_and_distilbert_cos_sim_and_tfidf_cos_sim_FINAL_TEST_SET.csv\")\n",
        "old_ridge_S_cluster_ctws_dbt_cs_FINAL_TEST_SET = read.csv(\"/content/old_ridge_S_cluster_cleaned_text_truly_clean_w_splits_w_bigrams_cos_sim_and_distilbert_cos_sim_and_tfidf_cos_sim_FINAL_TEST_SET.csv\")\n",
        "old_ridge_T_cluster_ctws_dbt_cs_FINAL_TEST_SET = read.csv(\"/content/old_ridge_T_cluster_cleaned_text_truly_clean_w_splits_w_bigrams_cos_sim_and_distilbert_cos_sim_and_tfidf_cos_sim_FINAL_TEST_SET.csv\")\n",
        "\n",
        "old_ridge_L_cluster_ctws_dbt_cs_FINAL_TEST_SET = subset(old_ridge_L_cluster_ctws_dbt_cs_FINAL_TEST_SET, select = c(response_id, rating_chooses_appropriate_action_pred, rating_commits_to_action_pred, rating_gathers_information_pred, rating_identifies_issues_opportunities_pred, rating_interprets_information_pred, rating_involves_others_pred, rating_decision_making_final_score_pred))\n",
        "old_ridge_S_cluster_ctws_dbt_cs_FINAL_TEST_SET = subset(old_ridge_S_cluster_ctws_dbt_cs_FINAL_TEST_SET, select = c(response_id, rating_chooses_appropriate_action_pred, rating_commits_to_action_pred, rating_gathers_information_pred, rating_identifies_issues_opportunities_pred, rating_interprets_information_pred, rating_involves_others_pred, rating_decision_making_final_score_pred))\n",
        "old_ridge_T_cluster_ctws_dbt_cs_FINAL_TEST_SET = subset(old_ridge_T_cluster_ctws_dbt_cs_FINAL_TEST_SET, select = c(response_id, rating_chooses_appropriate_action_pred, rating_commits_to_action_pred, rating_gathers_information_pred, rating_identifies_issues_opportunities_pred, rating_interprets_information_pred, rating_involves_others_pred, rating_decision_making_final_score_pred))\n",
        "\n",
        "dev_pub_w_preds = rbind(old_ridge_L_cluster_ctws_dbt_cs_FINAL_TEST_SET, old_ridge_S_cluster_ctws_dbt_cs_FINAL_TEST_SET, old_ridge_T_cluster_ctws_dbt_cs_FINAL_TEST_SET)\n"
      ],
      "metadata": {
        "id": "xLMK3Y3XlkEO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "\n",
        "\n",
        "ret_df_before_rounding = subset(dev_pub_w_preds, select = c(response_id, rating_chooses_appropriate_action_pred, rating_commits_to_action_pred, rating_gathers_information_pred, rating_identifies_issues_opportunities_pred, rating_interprets_information_pred, rating_involves_others_pred, rating_decision_making_final_score_pred))\n",
        "\n",
        "\n",
        "copy_of_ret_df_before_rounding = ret_df_before_rounding\n",
        "\n",
        "round_df <- function(x, digits) {\n",
        "  # round all numeric variables\n",
        "  # x: data frame \n",
        "  # digits: number of digits to round\n",
        "  numeric_columns <- sapply(x, mode) == 'numeric'\n",
        "  x[numeric_columns] <-  round(x[numeric_columns], digits)\n",
        "  x\n",
        "}\n",
        "\n",
        "after_rounding_ret = round_df(copy_of_ret_df_before_rounding, 0)\n",
        "\n",
        "\n",
        "colnames(after_rounding_ret)[2] = \"rating_chooses_appropriate_action\"\n",
        "colnames(after_rounding_ret)[3] = \"rating_commits_to_action\"\n",
        "colnames(after_rounding_ret)[4] = \"rating_gathers_information\"\n",
        "colnames(after_rounding_ret)[5] = \"rating_identifies_issues_opportunities\"\n",
        "colnames(after_rounding_ret)[6] = \"rating_interprets_information\"\n",
        "colnames(after_rounding_ret)[7] = \"rating_involves_others\"\n",
        "colnames(after_rounding_ret)[8] = \"rating_decision_making_final_score\"\n",
        "\n",
        "\n",
        "########## QUANTILES ##########\n",
        "\n",
        "## CHOOSES APPROPRIATE ACTION QUANTILE\n",
        "\n",
        "table(train_pub_df$rating_chooses_appropriate_action)\n",
        "8 + 436 + 819 +  123 # = 1386\n",
        "436 + 8\n",
        "444 / 1386 # = 0.3203463 = lower_cutoff_chooses_appropriate_action\n",
        "(444 + 819) / 1386 # = 0.9112554 = upper_cutoff_chooses_appropriate_action\n",
        "lower_cutoff_chooses_appropriate_action = 0.3203463\n",
        "upper_cutoff_chooses_appropriate_action = 0.9112554\n",
        "\n",
        "actual_value_lower_cutoff_chooses_appropriate_action = quantile(copy_of_ret_df_before_rounding$rating_chooses_appropriate_action_pred, probs = lower_cutoff_chooses_appropriate_action, names = FALSE)\n",
        "\n",
        "actual_value_upper_cutoff_chooses_appropriate_action = quantile(copy_of_ret_df_before_rounding$rating_chooses_appropriate_action_pred, probs = upper_cutoff_chooses_appropriate_action, names = FALSE)\n",
        "\n",
        "\n",
        "after_rounding_ret$rating_chooses_appropriate_action = ifelse(copy_of_ret_df_before_rounding$rating_chooses_appropriate_action_pred < actual_value_lower_cutoff_chooses_appropriate_action, 2, ifelse(copy_of_ret_df_before_rounding$rating_chooses_appropriate_action_pred > actual_value_upper_cutoff_chooses_appropriate_action, 4, 3))\n",
        "\n",
        "hist(train_pub_df$rating_chooses_appropriate_action)\n",
        "hist(after_rounding_ret$rating_chooses_appropriate_action)\n",
        "\n",
        "\n",
        "\n",
        "### COMMITS TO ACTION QUANTILE\n",
        "\n",
        "table(train_pub_df$rating_commits_to_action)\n",
        "\n",
        "# 1   2   3   4 \n",
        "# 3 203 915 345 \n",
        "# 3 + 203 + 915 + 345 # = 1466\n",
        "# 206/1466 # = 0.1405184\n",
        "\n",
        "lower_cutoff_commits_to_action = 0.1405184\n",
        "\n",
        "\n",
        "# (206 + 915) / 1466 # = 0.7646658\n",
        "\n",
        "upper_cutoff_commits_to_action = 0.7646658\n",
        "\n",
        "actual_value_lower_cutoff_commits_to_action = quantile(copy_of_ret_df_before_rounding$rating_commits_to_action_pred, probs = lower_cutoff_commits_to_action, names = FALSE)\n",
        "\n",
        "actual_value_upper_cutoff_commits_to_action = quantile(copy_of_ret_df_before_rounding$rating_commits_to_action_pred, probs = upper_cutoff_commits_to_action, names = FALSE)\n",
        "\n",
        "quantile_test_commits_to_action = ifelse(copy_of_ret_df_before_rounding$rating_commits_to_action_pred < actual_value_lower_cutoff_commits_to_action, 2, ifelse(copy_of_ret_df_before_rounding$rating_commits_to_action_pred > actual_value_upper_cutoff_commits_to_action, 4, 3))\n",
        "\n",
        "after_rounding_ret$rating_commits_to_action = quantile_test_commits_to_action\n",
        "\n",
        "hist(after_rounding_ret$rating_commits_to_action)\n",
        "hist(train_pub_df$rating_commits_to_action)\n",
        "\n",
        "\n",
        "## GATHERS INFORMATION QUANTILE \n",
        "\n",
        "table(train_pub_df$rating_gathers_information)\n",
        "# 1   2   3   4 \n",
        "# 3 581 730 152 \n",
        "3 + 581 + 730 + 152 # = 1466\n",
        "\n",
        "lower_cutoff_gathers_information = 584 / 1466\n",
        "\n",
        "upper_cutoff_gathers_information = (584 + 730) / 1466\n",
        "\n",
        "actual_value_lower_cutoff_gathers_information = quantile(copy_of_ret_df_before_rounding$rating_gathers_information_pred, probs = lower_cutoff_gathers_information, names = FALSE)\n",
        "\n",
        "actual_value_upper_cutoff_gathers_information = quantile(copy_of_ret_df_before_rounding$rating_gathers_information_pred, probs = upper_cutoff_gathers_information, names = FALSE)\n",
        "\n",
        "\n",
        "after_rounding_ret$rating_gathers_information = ifelse(copy_of_ret_df_before_rounding$rating_gathers_information_pred < actual_value_lower_cutoff_gathers_information, 2, ifelse(copy_of_ret_df_before_rounding$rating_gathers_information_pred > actual_value_upper_cutoff_gathers_information, 4, 3))\n",
        "\n",
        "hist(after_rounding_ret$rating_gathers_information)\n",
        "hist(train_pub_df$rating_gathers_information)\n",
        "\n",
        "\n",
        "## IDENTIFIES ISSUES OPPS QUANTILE \n",
        "\n",
        "table(train_pub_df$rating_identifies_issues_opportunities)\n",
        "# 1   2   3   4 \n",
        "# 3 517 802  64 \n",
        "\n",
        "3 + 517 + 802 + 64 # = 1386\n",
        "\n",
        "lower_cutoff_identifies_issues_oppurtunities = 520 / 1386\n",
        "\n",
        "upper_cutoff_identifies_issues_oppurtunities = (520 + 802) / 1386\n",
        "\n",
        "actual_value_lower_cutoff_identifies_issues_oppurtunities = quantile(copy_of_ret_df_before_rounding$rating_identifies_issues_opportunities_pred, probs = lower_cutoff_identifies_issues_oppurtunities, names = FALSE)\n",
        "\n",
        "actual_value_upper_cutoff_identifies_issues_oppurtunities  = quantile(copy_of_ret_df_before_rounding$rating_identifies_issues_opportunities_pred, probs = upper_cutoff_identifies_issues_oppurtunities, names = FALSE)\n",
        "\n",
        "\n",
        "after_rounding_ret$rating_identifies_issues_opportunities = ifelse(copy_of_ret_df_before_rounding$rating_identifies_issues_opportunities_pred < actual_value_lower_cutoff_identifies_issues_oppurtunities, 2, ifelse(copy_of_ret_df_before_rounding$rating_identifies_issues_opportunities_pred > actual_value_upper_cutoff_identifies_issues_oppurtunities, 4, 3))\n",
        "\n",
        "\n",
        "hist(train_pub_df$rating_identifies_issues_opportunities)\n",
        "hist(after_rounding_ret$rating_identifies_issues_opportunities)\n",
        "\n",
        "table(after_rounding_ret$rating_identifies_issues_opportunities)\n",
        "\n",
        "# INTERPRETS INFORMATION QUANTILE \n",
        "\n",
        "table(train_pub_df$rating_interprets_information)\n",
        "\n",
        "# 2   3   4 \n",
        "# 883 484  99 \n",
        "\n",
        "883 + 484 + 99 # = 1466\n",
        "\n",
        "lower_cutoff_interprets_information = 883/1466\n",
        "\n",
        "upper_cutoff_interprets_information = (883 + 484) / 1466\n",
        "\n",
        "actual_value_lower_cutoff_interprets_information = quantile(copy_of_ret_df_before_rounding$rating_interprets_information_pred, probs = lower_cutoff_interprets_information, names = FALSE)\n",
        "\n",
        "actual_value_upper_cutoff_interprets_information  = quantile(copy_of_ret_df_before_rounding$rating_interprets_information_pred, probs = upper_cutoff_interprets_information, names = FALSE)\n",
        "\n",
        "\n",
        "after_rounding_ret$rating_interprets_information = ifelse(copy_of_ret_df_before_rounding$rating_interprets_information_pred < actual_value_lower_cutoff_interprets_information, 2, ifelse(copy_of_ret_df_before_rounding$rating_interprets_information_pred > actual_value_upper_cutoff_interprets_information, 4, 3))\n",
        "\n",
        "hist(train_pub_df$rating_interprets_information)\n",
        "hist(after_rounding_ret$rating_interprets_information)\n",
        "\n",
        "\n",
        "# INVOLVES OTHERS QUANTILE \n",
        "\n",
        "table(train_pub_df$rating_involves_others)\n",
        "# 2   3   4 \n",
        "# 474 703 204 \n",
        "\n",
        "\n",
        "474 + 703 + 204 # = 1381\n",
        "\n",
        "lower_cutoff_involves_others = 474 / 1381\n",
        "upper_cutoff_involves_others = (474 + 703) / 1381\n",
        "\n",
        "actual_value_lower_cutoff_involves_others = quantile(copy_of_ret_df_before_rounding$rating_involves_others_pred, probs = lower_cutoff_involves_others, names = FALSE)\n",
        "\n",
        "actual_value_upper_cutoff_involves_others  = quantile(copy_of_ret_df_before_rounding$rating_involves_others_pred, probs = upper_cutoff_involves_others, names = FALSE)\n",
        "\n",
        "\n",
        "after_rounding_ret$rating_involves_others = ifelse(copy_of_ret_df_before_rounding$rating_involves_others_pred < actual_value_lower_cutoff_involves_others, 2, ifelse(copy_of_ret_df_before_rounding$rating_involves_others_pred > actual_value_upper_cutoff_involves_others, 4, 3))\n",
        "\n",
        "hist(train_pub_df$rating_involves_others)\n",
        "hist(after_rounding_ret$rating_involves_others)\n",
        "\n",
        "# FINAL DECISION QUANTILE \n",
        "\n",
        "table(train_pub_df$rating_decision_making_final_score)\n",
        "# 1   2   3   4   5   6   7 \n",
        "# 24 522 402 283 111 107  17 \n",
        "\n",
        "24 + 522 + 402 + 283 + 111 + 107 + 17 # = 1466\n",
        "\n",
        "final_decision_1_cutoff = 24 / 1466\n",
        "final_decision_2_cutoff = (24 + 522) / 1466\n",
        "final_decision_3_cutoff = (24 + 522 + 402) / 1466\n",
        "final_decision_4_cutoff = (24 + 522 + 402 + 283) / 1466\n",
        "final_decision_5_cutoff = (24 + 522 + 402 + 283 + 111) / 1466\n",
        "final_decision_6_cutoff = (24 + 522 + 402 + 283 + 111 + 107) / 1466\n",
        "\n",
        "actual_value_final_decision_1_cutoff = quantile(copy_of_ret_df_before_rounding$rating_decision_making_final_score_pred, probs = final_decision_1_cutoff, names = FALSE)\n",
        "actual_value_final_decision_2_cutoff = quantile(copy_of_ret_df_before_rounding$rating_decision_making_final_score_pred, probs = final_decision_2_cutoff, names = FALSE)\n",
        "actual_value_final_decision_3_cutoff = quantile(copy_of_ret_df_before_rounding$rating_decision_making_final_score_pred, probs = final_decision_3_cutoff, names = FALSE)\n",
        "actual_value_final_decision_4_cutoff = quantile(copy_of_ret_df_before_rounding$rating_decision_making_final_score_pred, probs = final_decision_4_cutoff, names = FALSE)\n",
        "actual_value_final_decision_5_cutoff = quantile(copy_of_ret_df_before_rounding$rating_decision_making_final_score_pred, probs = final_decision_5_cutoff, names = FALSE)\n",
        "actual_value_final_decision_6_cutoff = quantile(copy_of_ret_df_before_rounding$rating_decision_making_final_score_pred, probs = final_decision_6_cutoff, names = FALSE)\n",
        "\n",
        "\n",
        "after_rounding_ret$rating_decision_making_final_score = ifelse(copy_of_ret_df_before_rounding$rating_decision_making_final_score_pred < actual_value_final_decision_1_cutoff, 1, ifelse(copy_of_ret_df_before_rounding$rating_decision_making_final_score_pred <= actual_value_final_decision_2_cutoff, 2, ifelse(copy_of_ret_df_before_rounding$rating_decision_making_final_score_pred < actual_value_final_decision_3_cutoff, 3, ifelse(copy_of_ret_df_before_rounding$rating_decision_making_final_score_pred < actual_value_final_decision_4_cutoff, 4, ifelse(copy_of_ret_df_before_rounding$rating_decision_making_final_score_pred < actual_value_final_decision_5_cutoff, 5, ifelse(copy_of_ret_df_before_rounding$rating_decision_making_final_score_pred <= actual_value_final_decision_6_cutoff, 6, 7))))))\n",
        "\n",
        "hist(train_pub_df$rating_decision_making_final_score)\n",
        "hist(after_rounding_ret$rating_decision_making_final_score)\n",
        "\n",
        "write.csv(after_rounding_ret, 'model_2_predictions.csv')"
      ],
      "metadata": {
        "id": "MhUTz6wdlw8V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Starting Model 3 here:**"
      ],
      "metadata": {
        "id": "OkHeofHkk841"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.model_selection import train_test_split\n",
        "import sys\n",
        "from sklearn.linear_model import Ridge\n",
        "import time\n",
        "\n",
        "# Set pandas options to allow more printing rows/columns\n",
        "pd.set_option(\"display.max_rows\", 4000)\n",
        "pd.set_option(\"display.max_columns\", 4000)\n",
        "\n",
        "super_pub_df = pd.read_csv('/content/truly_corrected_super_df_correct_spelling_splits_cleaned_text_FINAL_TEST_SET.csv')\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "unwanted_pipes = [\"ner\", \"parser\"]\n",
        "\n",
        "def spacy_tokenizer(doc):\n",
        "  with nlp.disable_pipes(*unwanted_pipes):\n",
        "    return [t.lemma_ for t in nlp(doc) if \\\n",
        "            not t.is_punct and \\\n",
        "            not t.is_space and \\\n",
        "            t.is_alpha]\n",
        "  \n",
        "\n",
        "vectorizer = TfidfVectorizer(tokenizer=spacy_tokenizer)\n",
        "super_df_features = vectorizer.fit_transform(super_pub_df['super'])\n",
        "\n",
        "super_df_features_df = pd.DataFrame(super_df_features.todense(), columns=vectorizer.get_feature_names_out(super_pub_df['super']))\n",
        "\n",
        "super_df_features_df = pd.concat([super_df_features_df, super_pub_df['response_id']], axis = 1)\n",
        "\n",
        "super_df_features_df.to_csv('just_all_cols_tfidf_cleaned_text_w_splits_FINAL_TEST_SET.csv',index=False)\n"
      ],
      "metadata": {
        "id": "HhHF6nzjpMbf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "\n",
        "just_all_cols_tfidf_cleaned_text_w_splits = read.csv(\"/content/just_all_cols_tfidf_cleaned_text_w_splits_FINAL_TEST_SET.csv\")\n",
        "\n",
        "# fixing colnames for merge\n",
        "colnames(just_all_cols_tfidf_cleaned_text_w_splits)[colnames(just_all_cols_tfidf_cleaned_text_w_splits) == \"label\"] = \"label_feature\"\n",
        "colnames(just_all_cols_tfidf_cleaned_text_w_splits)[colnames(just_all_cols_tfidf_cleaned_text_w_splits) == \"super\"] = \"super_feature\"\n",
        "\n",
        "colnames(just_all_cols_tfidf_cleaned_text_w_splits)[10061:10082]\n",
        "# so this needs to connect with cc_super_df, on response_id\n",
        "\n",
        "print(colnames(just_all_cols_tfidf_cleaned_text_w_splits)[1:40])\n",
        "\n",
        "print(ncol(just_all_cols_tfidf_cleaned_text_w_splits))\n",
        "\n",
        "print(colnames(just_all_cols_tfidf_cleaned_text_w_splits)[10104:10114])\n"
      ],
      "metadata": {
        "id": "vEaKX68FsLYK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "\n",
        "# Start at the file we made in model 1, after using pyenchant + wordninja, but before seperating into groups:\n",
        "cc_super_df = read.csv(\"/content/truly_corrected_super_df_correct_spelling_splits_cleaned_text_FINAL_TEST_SET.csv\")\n",
        "\n",
        "# Removing the index column that Python added: \n",
        "colnames(cc_super_df)[1] = 'unnamed'\n",
        "\n",
        "cc_super_df = subset(cc_super_df, select = -c(unnamed))\n"
      ],
      "metadata": {
        "id": "l4Dk9qzgk78s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "\n",
        "just_all_cols_tfidf_cleaned_text_w_splits_merged_w_super = merge(cc_super_df, just_all_cols_tfidf_cleaned_text_w_splits, on = 'response_id')\n",
        "colnames(just_all_cols_tfidf_cleaned_text_w_splits_merged_w_super)[1:40]"
      ],
      "metadata": {
        "id": "NI_j60z1wE8j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import transformers as ppb # pytorch transformers"
      ],
      "metadata": {
        "id": "Ja4Scv6gyPTT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_class, tokenizer_class, pretrained_weights = (ppb.DistilBertModel, ppb.DistilBertTokenizer, 'distilbert-base-uncased')\n",
        "\n",
        "# Load pretrained model/tokenizer\n",
        "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
        "model = model_class.from_pretrained(pretrained_weights)"
      ],
      "metadata": {
        "id": "0X71wNLM0KcR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "super_pub_df = pd.read_csv(\"/content/truly_corrected_super_df_correct_spelling_splits_cleaned_text_FINAL_TEST_SET.csv\")\n"
      ],
      "metadata": {
        "id": "DJZ_vlVH0Pkv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized1 = super_pub_df['super'].apply((lambda x: tokenizer.encode(x, padding=True, truncation=True, add_special_tokens=True)))"
      ],
      "metadata": {
        "id": "AHCvRDQZ0Z7h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = 0\n",
        "for i in tokenized1.values:\n",
        "    if len(i) > max_len:\n",
        "        max_len = len(i)\n",
        "\n",
        "padded1 = np.array([i + [0]*(max_len-len(i)) for i in tokenized1.values])\n",
        "\n",
        "np.array(padded1).shape"
      ],
      "metadata": {
        "id": "uje8LA3I0cOg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attention_mask1 = np.where(padded1 != 0, 1, 0)\n",
        "attention_mask1.shape"
      ],
      "metadata": {
        "id": "7JKKXLPP0cmf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids1 = torch.tensor(np.array(padded1[0:115]))\n",
        "\n",
        "with torch.no_grad():\n",
        "    last_hidden_states = model(input_ids1)"
      ],
      "metadata": {
        "id": "awcv4NXw0j51"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features1 = last_hidden_states[0][:,0,:].numpy()"
      ],
      "metadata": {
        "id": "8y1X26In0kcv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids2 = torch.tensor(np.array(padded1[115:230]))\n",
        "\n",
        "with torch.no_grad():\n",
        "    last_hidden_states2 = model(input_ids2)"
      ],
      "metadata": {
        "id": "npp8RZp40mOw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features2 = last_hidden_states2[0][:,0,:].numpy()"
      ],
      "metadata": {
        "id": "bhUKoUTv0qmh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids3 = torch.tensor(np.array(padded1[230:345]))\n",
        "\n",
        "with torch.no_grad():\n",
        "    last_hidden_states3 = model(input_ids3)"
      ],
      "metadata": {
        "id": "lh45r3o00sqJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features3 = last_hidden_states3[0][:,0,:].numpy()"
      ],
      "metadata": {
        "id": "cgO5xqK50wPL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids4 = torch.tensor(np.array(padded1[345:460]))\n",
        "\n",
        "with torch.no_grad():\n",
        "    last_hidden_states4 = model(input_ids4)"
      ],
      "metadata": {
        "id": "WEZ0O36n0ytZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features4 = last_hidden_states4[0][:,0,:].numpy()"
      ],
      "metadata": {
        "id": "_cqui6l400fY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids5 = torch.tensor(np.array(padded1[460:575]))\n",
        "\n",
        "with torch.no_grad():\n",
        "    last_hidden_states5 = model(input_ids5)"
      ],
      "metadata": {
        "id": "yHTB9bbg02Ft"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features5 = last_hidden_states5[0][:,0,:].numpy()"
      ],
      "metadata": {
        "id": "OOdhIh5R04A9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids6 = torch.tensor(np.array(padded1[575:690]))\n",
        "\n",
        "with torch.no_grad():\n",
        "    last_hidden_states6 = model(input_ids6)"
      ],
      "metadata": {
        "id": "VGaDXUj005mQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features6 = last_hidden_states6[0][:,0,:].numpy()"
      ],
      "metadata": {
        "id": "4RagUMFq07YT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids7 = torch.tensor(np.array(padded1[690:805]))\n",
        "\n",
        "with torch.no_grad():\n",
        "    last_hidden_states7 = model(input_ids7)"
      ],
      "metadata": {
        "id": "FdmHOYJU080b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features7 = last_hidden_states7[0][:,0,:].numpy()"
      ],
      "metadata": {
        "id": "68pAbuub0-l4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids8 = torch.tensor(np.array(padded1[805:920]))\n",
        "\n",
        "with torch.no_grad():\n",
        "    last_hidden_states8 = model(input_ids8)"
      ],
      "metadata": {
        "id": "zrmUlLKY1APQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features8 = last_hidden_states8[0][:,0,:].numpy()"
      ],
      "metadata": {
        "id": "B3IGvEEa1CCl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids9 = torch.tensor(np.array(padded1[920:1035]))\n",
        "\n",
        "with torch.no_grad():\n",
        "    last_hidden_states9 = model(input_ids9)"
      ],
      "metadata": {
        "id": "NR_Q8XTD1DTt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features9 = last_hidden_states9[0][:,0,:].numpy()"
      ],
      "metadata": {
        "id": "q0EusqAS1FEa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids10 = torch.tensor(np.array(padded1[1035:1150]))\n",
        "\n",
        "with torch.no_grad():\n",
        "    last_hidden_states10 = model(input_ids10)\n",
        "\n",
        "features10 = last_hidden_states10[0][:,0,:].numpy()"
      ],
      "metadata": {
        "id": "pxxav1TW1GbG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids11 = torch.tensor(np.array(padded1[1150:1265]))\n",
        "\n",
        "with torch.no_grad():\n",
        "    last_hidden_states11 = model(input_ids11)\n",
        "\n",
        "features11 = last_hidden_states11[0][:,0,:].numpy()"
      ],
      "metadata": {
        "id": "cTPXn-gw1IZ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids12 = torch.tensor(np.array(padded1[1265:1380]))\n",
        "\n",
        "with torch.no_grad():\n",
        "    last_hidden_states12 = model(input_ids12)\n",
        "\n",
        "features12 = last_hidden_states12[0][:,0,:].numpy()"
      ],
      "metadata": {
        "id": "QcFHGS6N1McN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids13 = torch.tensor(np.array(padded1[1380:1495]))\n",
        "\n",
        "with torch.no_grad():\n",
        "    last_hidden_states13 = model(input_ids13)\n",
        "\n",
        "features13 = last_hidden_states13[0][:,0,:].numpy()"
      ],
      "metadata": {
        "id": "3zUO3rd51OW3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids14 = torch.tensor(np.array(padded1[1495:1610]))\n",
        "\n",
        "with torch.no_grad():\n",
        "    last_hidden_states14 = model(input_ids14)\n",
        "\n",
        "features14 = last_hidden_states14[0][:,0,:].numpy()"
      ],
      "metadata": {
        "id": "PHe9k2YA1QOC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids15 = torch.tensor(np.array(padded1[1610:1725]))\n",
        "\n",
        "with torch.no_grad():\n",
        "    last_hidden_states15 = model(input_ids15)\n",
        "\n",
        "features15 = last_hidden_states15[0][:,0,:].numpy()"
      ],
      "metadata": {
        "id": "56uvBbWT1SLL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids16 = torch.tensor(np.array(padded1[1725:1840]))\n",
        "\n",
        "with torch.no_grad():\n",
        "    last_hidden_states16 = model(input_ids16)\n",
        "\n",
        "features16 = last_hidden_states16[0][:,0,:].numpy()"
      ],
      "metadata": {
        "id": "1rqb8qFR1T4C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids17 = torch.tensor(np.array(padded1[1840:1955]))\n",
        "\n",
        "with torch.no_grad():\n",
        "    last_hidden_states17 = model(input_ids17)\n",
        "\n",
        "features17 = last_hidden_states17[0][:,0,:].numpy()"
      ],
      "metadata": {
        "id": "63T5rejz1V-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features_full = np.concatenate((features1, features2, features3, features4, features5, features6, features7, features8, features9, features10, features11, features12, features13, features14, features15, features16, features17),axis = 0)"
      ],
      "metadata": {
        "id": "7Lay57Kg1Xqj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas import DataFrame\n",
        "feat_full = pd.DataFrame(data=features_full)"
      ],
      "metadata": {
        "id": "kFtqNCLc1cMJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "super_pub_df = DataFrame (super_pub_df,columns=['Unnamed: 0', 'response_id','rating_chooses_appropriate_action',\n",
        "       'rating_commits_to_action', 'rating_gathers_information',\n",
        "       'rating_identifies_issues_opportunities',\n",
        "       'rating_interprets_information', 'rating_involves_others',\n",
        "       'rating_decision_making_final_score', 'text_exercise_4',\n",
        "       'text_exercise_5', 'text_exercise_6', 'text_exercise_7',\n",
        "       'text_exercise_8', 'text_exercise_9', 'text_exercise_10',\n",
        "       'text_exercise_11', 'text_exercise_12', 'text_exercise_13',\n",
        "       'text_exercise_14', 'text_exercise_15', 'text_exercise_16',\n",
        "       'text_exercise_17', 'text_exercise_18', 'text_exercise_19',\n",
        "       'text_exercise_final', 'super', \"label\"])\n",
        "frames1 = [super_pub_df, feat_full]\n",
        "out1 = pd.concat(frames1, axis=1, ignore_index=True)\n",
        "print(out1.head())"
      ],
      "metadata": {
        "id": "7QzankeF1cnd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out1.rename(columns={0 : 'Unnamed: 0', 1 : 'response_id', 2 : 'rating_chooses_appropriate_action',\n",
        "       3 : 'rating_commits_to_action', 4 : 'rating_gathers_information',\n",
        "       5 : 'rating_identifies_issues_opportunities',\n",
        "       6 : 'rating_interprets_information', 7 : 'rating_involves_others',\n",
        "       8 : 'rating_decision_making_final_score', 9 : 'text_exercise_4',\n",
        "       10 : 'text_exercise_5', 11 : 'text_exercise_6', 12 : 'text_exercise_7',\n",
        "       13 : 'text_exercise_8', 14 : 'text_exercise_9', 15 : 'text_exercise_10',\n",
        "       16 : 'text_exercise_11', 17 : 'text_exercise_12', 18 : 'text_exercise_13',\n",
        "       19 : 'text_exercise_14', 20 : 'text_exercise_15', 21 : 'text_exercise_16',\n",
        "       22 : 'text_exercise_17', 23 : 'text_exercise_18', 24 : 'text_exercise_19',\n",
        "       25 : 'text_exercise_final', 26 : 'super', 27 : 'label'}, inplace=True)\n",
        "\n",
        "#out.columns =['participant', 'transcript', 'r1_hd9']\n",
        "out1.to_csv('super_pub_df_w_distiblert_full_text_encoding_from_scratch_FINAL_TEST_SET.csv')\n",
        "out1.head()"
      ],
      "metadata": {
        "id": "5J6YwRBC1h3w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "\n",
        "library(stringr)\n",
        "\n",
        "# bringing it back in here to change x columns to have names: \n",
        "\n",
        "super_pub_df_w_distiblert_full_text_encoding_from_scratch = read.csv(\"/content/super_pub_df_w_distiblert_full_text_encoding_from_scratch_FINAL_TEST_SET.csv\")\n",
        "\n",
        "colnames(super_pub_df_w_distiblert_full_text_encoding_from_scratch)[2] = \"unnamed\"\n",
        "\n",
        "super_pub_df_w_distiblert_full_text_encoding_from_scratch = subset(super_pub_df_w_distiblert_full_text_encoding_from_scratch, select = -c(X, unnamed))\n",
        "\n",
        "# renaming all the columns \n",
        "\n",
        "i = 28\n",
        "while(i <= ncol(super_pub_df_w_distiblert_full_text_encoding_from_scratch))\n",
        "{\n",
        "  prev = colnames(super_pub_df_w_distiblert_full_text_encoding_from_scratch)[i]\n",
        "  curr = str_c(\"distilbert_embedding\", prev, sep = \"_\")\n",
        "  colnames(super_pub_df_w_distiblert_full_text_encoding_from_scratch)[i] = curr\n",
        "  i = i + 1\n",
        "}\n",
        "\n",
        "colnames(super_pub_df_w_distiblert_full_text_encoding_from_scratch)[28]\n",
        "\n",
        "# Ok, now sending it to real cos_sim Python script to get cos similarities \n",
        "\n",
        "write.csv(super_pub_df_w_distiblert_full_text_encoding_from_scratch, file = \"super_pub_df_w_distiblert_full_text_encoding_from_scratch_corrected_x_cols_FINAL_TEST_SET.csv\")\n"
      ],
      "metadata": {
        "id": "CZdmY2kB2l6u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.model_selection import train_test_split\n",
        "import sys\n",
        "from sklearn.linear_model import Ridge\n",
        "import time\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "# import torch\n",
        "\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.preprocessing import scale, StandardScaler\n",
        "from sklearn.linear_model import Ridge, RidgeCV, Lasso, LassoCV\n",
        "\n",
        "\n",
        "# Set pandas options to allow more printing rows/columns\n",
        "pd.set_option(\"display.max_rows\", 4000)\n",
        "pd.set_option(\"display.max_columns\", 4000)\n",
        "\n",
        "\n",
        "super_cos_sim_df = pd.read_csv(\"/content/super_pub_df_w_distiblert_full_text_encoding_from_scratch_corrected_x_cols_FINAL_TEST_SET.csv\")\n",
        "\n",
        "super_cos_sim_df = pd.concat([super_cos_sim_df, pd.DataFrame(cosine_similarity(super_cos_sim_df.iloc[:,28:]))], axis=1)\n",
        "\n",
        "super_cos_sim_df.columns = super_cos_sim_df.columns.astype(str)\n",
        "\n",
        "super_cos_sim_df.to_csv('super_cos_sim_df_from_scratch_FINAL_TEST_SET.csv',index=False)\n"
      ],
      "metadata": {
        "id": "3euE50re2wkD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "\n",
        "# Reading in back in from the real cos sim python script: \n",
        "super_cos_sim_df_from_scratch = read.csv(\"/content/super_cos_sim_df_from_scratch_FINAL_TEST_SET.csv\")\n",
        "\n",
        "# renaming the columns here again \n",
        "colnames(super_cos_sim_df_from_scratch)[1:40]\n",
        "\n",
        "i = 797\n",
        "while(i <= ncol(super_cos_sim_df_from_scratch))\n",
        "{\n",
        "  prev = colnames(super_cos_sim_df_from_scratch)[i]\n",
        "  curr = str_c(\"distilbert_cos_sim\", prev, sep = \"_\")\n",
        "  colnames(super_cos_sim_df_from_scratch)[i] = curr\n",
        "  i = i + 1\n",
        "}\n",
        "\n",
        "colnames(super_cos_sim_df_from_scratch)[1] = 'unnamed'\n",
        "super_cos_sim_df_from_scratch = subset(super_cos_sim_df_from_scratch, select = -c(unnamed))\n",
        "\n",
        "# Ok, so now this has all the og columns, the distilbert text embeddings, and distilbert cos sim\n",
        "\n",
        "# SO all I really need now is bigrams. Then I can combine this with pty length, bigrams, and tfidf cc - should be good then! \n"
      ],
      "metadata": {
        "id": "WA8KPBwu3SvF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# bigrams below here \n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "super_df = pd.read_csv(\"/content/truly_corrected_super_df_correct_spelling_splits_cleaned_text_FINAL_TEST_SET.csv\")\n",
        "\n",
        "cols = super_df.axes[1]\n",
        "\n",
        "print(cols)\n",
        "\n",
        "print(len(cols))\n",
        "\n",
        "print()\n",
        "\n",
        "print(super_df.iloc[:,26][1])\n",
        "\n",
        "print(len(super_df))"
      ],
      "metadata": {
        "id": "oTwd-K5k3qMJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd \n",
        "import spacy\n",
        "from scipy import spatial\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "\n",
        "pd.set_option(\"display.max_rows\", 4000)\n",
        "pd.set_option(\"display.max_columns\", 4000)\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "def spacy_tokenizer(doc):\n",
        "  return [t.text for t in nlp(doc) if not t.is_punct]\n",
        "\n",
        "super_df = pd.read_csv(\"/content/truly_corrected_super_df_correct_spelling_splits_cleaned_text_FINAL_TEST_SET.csv\")\n",
        "\n",
        "cols = super_df.axes[1]\n",
        "\n",
        "corpus = super_df.iloc[:,26].tolist()\n",
        "\n",
        "vectorizer = CountVectorizer(tokenizer=spacy_tokenizer, lowercase=False, binary=True, ngram_range=(1,2))\n",
        "\n",
        "bigrams = vectorizer.fit_transform(corpus)\n"
      ],
      "metadata": {
        "id": "EbMr19iO4DF3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "super_df_w_bigrams_cos_sim = pd.concat([super_df, pd.DataFrame(cosine_similarity(vectorizer.fit_transform(super_df.iloc[:,26].tolist())))], axis=1)\n"
      ],
      "metadata": {
        "id": "oT1vOIm24JiD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(super_df_w_bigrams_cos_sim.iloc[2,31])"
      ],
      "metadata": {
        "id": "jWJd1Gif4MES"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "super_df_w_bigrams_cos_sim.to_csv('/content/bigrams_cs_truly_correct_cc_super_df_correct_spelling_splits_cleaned_text_FINAL_TEST_SET.csv',index=False)"
      ],
      "metadata": {
        "id": "saqdUpxc4M6J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "\n",
        "bigrams_cs_truly_correct_cc_super_df_correct_spelling_splits_cleaned_text = read.csv(\"/content/bigrams_cs_truly_correct_cc_super_df_correct_spelling_splits_cleaned_text_FINAL_TEST_SET.csv\")\n",
        "\n",
        "colnames(bigrams_cs_truly_correct_cc_super_df_correct_spelling_splits_cleaned_text)[1] = 'unnamed'\n",
        "\n",
        "bigrams_cs_truly_correct_cc_super_df_correct_spelling_splits_cleaned_text = subset(bigrams_cs_truly_correct_cc_super_df_correct_spelling_splits_cleaned_text, select = -c(unnamed))\n",
        "\n",
        "# Fix column names: \n",
        "colnames(bigrams_cs_truly_correct_cc_super_df_correct_spelling_splits_cleaned_text)[28]\n",
        "\n",
        "i = 28\n",
        "while(i <= ncol(bigrams_cs_truly_correct_cc_super_df_correct_spelling_splits_cleaned_text))\n",
        "{\n",
        "  prev = colnames(bigrams_cs_truly_correct_cc_super_df_correct_spelling_splits_cleaned_text)[i]\n",
        "  curr = str_c(\"bigrams_cos_sim\", prev, sep = \"_\")\n",
        "  colnames(bigrams_cs_truly_correct_cc_super_df_correct_spelling_splits_cleaned_text)[i] = curr\n",
        "  i = i + 1\n",
        "}\n"
      ],
      "metadata": {
        "id": "ZQQ8indo4XIm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%R \n",
        "\n",
        "# Ok, last thing I need is please / thank you and length / length mean \n",
        "\n",
        "# adding please and thanks \n",
        "please_thanks_length_super = cc_super_df\n",
        "\n",
        "please_thanks_length_super$num_thanks = str_locate_all(please_thanks_length_super$super,'thank')\n",
        "\n",
        "ncol(please_thanks_length_super)\n",
        "\n",
        "i = 1\n",
        "while(i <= nrow(please_thanks_length_super))\n",
        "{\n",
        "  # please_thanks_length_super[i,29] = length(please_thanks_length_super[i,29])\n",
        "  vector_ = please_thanks_length_super[i,28]\n",
        "  j = nrow(as.data.frame(vector_))\n",
        "  please_thanks_length_super[i,28] = j\n",
        "  i = i + 1\n",
        "}\n",
        "\n",
        "please_thanks_length_super$num_please = str_locate_all(please_thanks_length_super$super,'please')\n",
        "\n",
        "ncol(please_thanks_length_super)\n",
        "\n",
        "i = 1\n",
        "while(i <= nrow(please_thanks_length_super))\n",
        "{\n",
        "  # please_thanks_length_super[i,29] = length(please_thanks_length_super[i,29])\n",
        "  vector_ = please_thanks_length_super[i,29]\n",
        "  j = nrow(as.data.frame(vector_))\n",
        "  please_thanks_length_super[i,29] = j\n",
        "  i = i + 1\n",
        "}\n",
        "\n",
        "\n",
        "please_thanks_length_super$num_please = as.numeric(please_thanks_length_super$num_please)\n",
        "please_thanks_length_super$num_thanks = as.numeric(please_thanks_length_super$num_thanks)\n",
        "\n",
        "please_thanks_length_super$num_please_and_thanks = please_thanks_length_super$num_please + please_thanks_length_super$num_thanks\n",
        "\n",
        "nrow(please_thanks_length_super)\n",
        "\n",
        "\n",
        "# adding length and mean length \n",
        "nrow(please_thanks_length_super)\n",
        "ncol(please_thanks_length_super)\n",
        "\n",
        "please_thanks_length_super$length_overall = ifelse(length(please_thanks_length_super$super)!= 0, 0, 0)\n",
        "please_thanks_length_super$length_mean = ifelse(length(please_thanks_length_super$super)!= 0, 0, 0)\n",
        "ncol(please_thanks_length_super)\n",
        "\n",
        "i = 1\n",
        "while (i <= nrow(please_thanks_length_super))\n",
        "{\n",
        "  j = 9\n",
        "  counter = 0\n",
        "  while (j <= 25)\n",
        "  {\n",
        "    if (is.na(please_thanks_length_super[i,j]))\n",
        "    {\n",
        "      j = j +1\n",
        "    }\n",
        "    else\n",
        "    {\n",
        "      counter = counter + 1\n",
        "      please_thanks_length_super[i,31] = please_thanks_length_super[i,31] + str_length(please_thanks_length_super[i,j])\n",
        "      j = j + 1\n",
        "    }\n",
        "    if (j == 25)\n",
        "    {\n",
        "      if (counter != 0)\n",
        "      {\n",
        "        please_thanks_length_super[i,32] = please_thanks_length_super[i,31] / counter\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "  i = i + 1\n",
        "}\n",
        "\n",
        "# view(please_thanks_length_super)\n"
      ],
      "metadata": {
        "id": "4lim6Wso4ju3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "\n",
        "\n",
        "# Ok, so now I have please_thanks_length, bigrams, distilbert_e + cs, and cctfidf all separate.\n",
        "# Time to merge them. \n",
        "\n",
        "# Then I need to get rid of duplicated columns, and figure out which one will keep - prob distilbert e + cs \n",
        "\n",
        "bigrams_cs_truly_correct_cc_super_df_correct_spelling_splits_cleaned_text = subset(bigrams_cs_truly_correct_cc_super_df_correct_spelling_splits_cleaned_text, select = -c(\n",
        "  rating_chooses_appropriate_action,\n",
        "  rating_commits_to_action,\n",
        "  rating_gathers_information,\n",
        "  rating_identifies_issues_opportunities,\n",
        "  rating_interprets_information,\n",
        "  rating_involves_others,\n",
        "  rating_decision_making_final_score,\n",
        "  text_exercise_4,\n",
        "  text_exercise_5,\n",
        "  text_exercise_6,\n",
        "  text_exercise_7,\n",
        "  text_exercise_8,\n",
        "  text_exercise_9,\n",
        "  text_exercise_10,\n",
        "  text_exercise_11,\n",
        "  text_exercise_12,\n",
        "  text_exercise_13,\n",
        "  text_exercise_14,\n",
        "  text_exercise_15,\n",
        "  text_exercise_16,\n",
        "  text_exercise_17,\n",
        "  text_exercise_18,\n",
        "  text_exercise_19,\n",
        "  text_exercise_final,\n",
        "  super,\n",
        "  label\n",
        "))\n",
        "\n",
        "just_all_cols_tfidf_cleaned_text_w_splits_merged_w_super = subset(just_all_cols_tfidf_cleaned_text_w_splits_merged_w_super, select = -c(\n",
        "  rating_chooses_appropriate_action,\n",
        "  rating_commits_to_action,\n",
        "  rating_gathers_information,\n",
        "  rating_identifies_issues_opportunities,\n",
        "  rating_interprets_information,\n",
        "  rating_involves_others,\n",
        "  rating_decision_making_final_score,\n",
        "  text_exercise_4,\n",
        "  text_exercise_5,\n",
        "  text_exercise_6,\n",
        "  text_exercise_7,\n",
        "  text_exercise_8,\n",
        "  text_exercise_9,\n",
        "  text_exercise_10,\n",
        "  text_exercise_11,\n",
        "  text_exercise_12,\n",
        "  text_exercise_13,\n",
        "  text_exercise_14,\n",
        "  text_exercise_15,\n",
        "  text_exercise_16,\n",
        "  text_exercise_17,\n",
        "  text_exercise_18,\n",
        "  text_exercise_19,\n",
        "  text_exercise_final,\n",
        "  super,\n",
        "  label\n",
        "))\n",
        "\n",
        "please_thanks_length_super = subset(please_thanks_length_super, select = -c(\n",
        "  rating_chooses_appropriate_action,\n",
        "  rating_commits_to_action,\n",
        "  rating_gathers_information,\n",
        "  rating_identifies_issues_opportunities,\n",
        "  rating_interprets_information,\n",
        "  rating_involves_others,\n",
        "  rating_decision_making_final_score,\n",
        "  text_exercise_4,\n",
        "  text_exercise_5,\n",
        "  text_exercise_6,\n",
        "  text_exercise_7,\n",
        "  text_exercise_8,\n",
        "  text_exercise_9,\n",
        "  text_exercise_10,\n",
        "  text_exercise_11,\n",
        "  text_exercise_12,\n",
        "  text_exercise_13,\n",
        "  text_exercise_14,\n",
        "  text_exercise_15,\n",
        "  text_exercise_16,\n",
        "  text_exercise_17,\n",
        "  text_exercise_18,\n",
        "  text_exercise_19,\n",
        "  text_exercise_final,\n",
        "  super,\n",
        "  label\n",
        "))\n",
        "\n",
        "print(ncol(super_cos_sim_df_from_scratch) + ncol(just_all_cols_tfidf_cleaned_text_w_splits_merged_w_super) + ncol(please_thanks_length_super) + ncol(bigrams_cs_truly_correct_cc_super_df_correct_spelling_splits_cleaned_text)) # 14790 - 3 reponse_ids = 14787 # 14826 - 3 = 14823\n",
        "\n",
        "super_cos_sim_df_from_scratch_huge = merge(super_cos_sim_df_from_scratch, bigrams_cs_truly_correct_cc_super_df_correct_spelling_splits_cleaned_text, on = 'response_id')\n",
        "\n",
        "super_cos_sim_df_from_scratch_huge = merge(super_cos_sim_df_from_scratch_huge, just_all_cols_tfidf_cleaned_text_w_splits_merged_w_super, on = 'response_id')\n",
        "\n",
        "super_cos_sim_df_from_scratch_huge = merge(super_cos_sim_df_from_scratch_huge,please_thanks_length_super, on = 'response_id')\n",
        "\n",
        "ncol(super_cos_sim_df_from_scratch_huge)\n",
        "\n",
        "nrow(super_cos_sim_df_from_scratch_huge)\n",
        "\n",
        "\n",
        "# Ok, now I just need to split into L and S clusters, and then into train and dev sets and run tests and submit !\n",
        "\n",
        "colSums(is.na(super_cos_sim_df_from_scratch_huge))[1:30]\n",
        "\n",
        "super_cos_sim_df_from_scratch_huge[super_cos_sim_df_from_scratch_huge==\"\"]<-NA\n",
        "\n",
        "colSums(is.na(super_cos_sim_df_from_scratch_huge))[1:40]\n",
        "\n",
        "L_cluster_super_cos_sim_df_from_scratch_huge = subset(super_cos_sim_df_from_scratch_huge, subset = is.na(super_cos_sim_df_from_scratch_huge$text_exercise_18))\n",
        "S_cluster_super_cos_sim_df_from_scratch_huge = subset(super_cos_sim_df_from_scratch_huge, subset = !is.na(super_cos_sim_df_from_scratch_huge$text_exercise_18))\n",
        "\n",
        "nrow(L_cluster_super_cos_sim_df_from_scratch_huge)\n",
        "nrow(S_cluster_super_cos_sim_df_from_scratch_huge)\n",
        "\n",
        "\n",
        "\n",
        "train_L_cluster_super_cos_sim_df_from_scratch_huge = subset(L_cluster_super_cos_sim_df_from_scratch_huge, subset = L_cluster_super_cos_sim_df_from_scratch_huge$label == 'train')\n",
        "dev_L_cluster_super_cos_sim_df_from_scratch_huge = subset(L_cluster_super_cos_sim_df_from_scratch_huge, subset = L_cluster_super_cos_sim_df_from_scratch_huge$label == 'dev')\n",
        "\n",
        "train_S_cluster_super_cos_sim_df_from_scratch_huge = subset(S_cluster_super_cos_sim_df_from_scratch_huge, subset = S_cluster_super_cos_sim_df_from_scratch_huge$label == 'train')\n",
        "dev_S_cluster_super_cos_sim_df_from_scratch_huge = subset(S_cluster_super_cos_sim_df_from_scratch_huge, subset = S_cluster_super_cos_sim_df_from_scratch_huge$label == 'dev')\n",
        "\n",
        "\n",
        "# using just instead of common cols FINAL TEST SET  \n",
        "write.csv(train_L_cluster_super_cos_sim_df_from_scratch_huge, file = \"train_L_cluster_super_cos_sim_df_from_scratch_huge_just_FINAL_TEST_SET.csv\")\n",
        "write.csv(dev_L_cluster_super_cos_sim_df_from_scratch_huge, file = \"dev_L_cluster_super_cos_sim_df_from_scratch_huge_just_FINAL_TEST_SET.csv\")\n",
        "\n",
        "write.csv(train_S_cluster_super_cos_sim_df_from_scratch_huge, file = \"train_S_cluster_super_cos_sim_df_from_scratch_huge_just_FINAL_TEST_SET.csv\")\n",
        "write.csv(dev_S_cluster_super_cos_sim_df_from_scratch_huge, file = \"dev_S_cluster_super_cos_sim_df_from_scratch_huge_just_FINAL_TEST_SET.csv\")\n",
        "\n",
        "(ncol(train_L_cluster_super_cos_sim_df_from_scratch_huge) - 27) / 3 # 4932\n"
      ],
      "metadata": {
        "id": "VVu0ZVhk5Vzw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.model_selection import train_test_split\n",
        "import sys\n",
        "from sklearn.linear_model import Ridge\n",
        "import time\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "# import torch\n",
        "from sklearn.linear_model import Ridge, RidgeCV, Lasso, LassoCV\n",
        "from sklearn.preprocessing import scale\n",
        "from sklearn.preprocessing import scale, StandardScaler\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "\n",
        "# Set pandas options to allow more printing rows/columns\n",
        "pd.set_option(\"display.max_rows\", 4000)\n",
        "pd.set_option(\"display.max_columns\", 4000)\n",
        "\n",
        "train_pub_df = pd.read_csv(\"/content/train_L_cluster_super_cos_sim_df_from_scratch_huge_just_FINAL_TEST_SET.csv\")\n",
        "dev_pub_df = pd.read_csv(\"/content/dev_L_cluster_super_cos_sim_df_from_scratch_huge_just_FINAL_TEST_SET.csv\")\n",
        "\n",
        "\n",
        "# computing number of columns\n",
        "cols = len(train_pub_df.axes[1])\n",
        "print(cols)\n",
        "\n",
        "cols_div_3 = cols // 3\n",
        "\n",
        "cols = train_pub_df.axes[1]\n",
        "print(cols)\n",
        "\n",
        "\n",
        "print('got that ')\n",
        "X = train_pub_df.drop(['Unnamed: 0', 'response_id', 'super', 'rating_chooses_appropriate_action','rating_commits_to_action','rating_gathers_information','rating_identifies_issues_opportunities','rating_interprets_information', 'rating_involves_others', \"rating_decision_making_final_score\", 'text_exercise_4',\n",
        "    'text_exercise_5',\n",
        "    'text_exercise_6',\n",
        "    'text_exercise_7',\n",
        "    \"text_exercise_8\",\n",
        "    \"text_exercise_9\",\n",
        "    \"text_exercise_10\",\n",
        "    \"text_exercise_11\",\n",
        "    \"text_exercise_12\",\n",
        "    \"text_exercise_13\",\n",
        "    \"text_exercise_14\",\n",
        "    \"text_exercise_15\",\n",
        "    \"text_exercise_16\",\n",
        "    \"text_exercise_17\",\n",
        "    \"text_exercise_18\",\n",
        "    \"text_exercise_19\",\n",
        "    \"text_exercise_final\", \n",
        "    'label'], axis=1)\n",
        "\n",
        "ys = train_pub_df[['rating_chooses_appropriate_action','rating_commits_to_action','rating_gathers_information','rating_identifies_issues_opportunities','rating_interprets_information', 'rating_involves_others', \"rating_decision_making_final_score\"]]\n",
        "\n",
        "X_dev = dev_pub_df.drop(['Unnamed: 0', 'response_id', 'super', 'rating_chooses_appropriate_action','rating_commits_to_action','rating_gathers_information','rating_identifies_issues_opportunities','rating_interprets_information', 'rating_involves_others', \"rating_decision_making_final_score\", 'text_exercise_4',\n",
        "    'text_exercise_5',\n",
        "    'text_exercise_6',\n",
        "    'text_exercise_7',\n",
        "    \"text_exercise_8\",\n",
        "    \"text_exercise_9\",\n",
        "    \"text_exercise_10\",\n",
        "    \"text_exercise_11\",\n",
        "    \"text_exercise_12\",\n",
        "    \"text_exercise_13\",\n",
        "    \"text_exercise_14\",\n",
        "    \"text_exercise_15\",\n",
        "    \"text_exercise_16\",\n",
        "    \"text_exercise_17\",\n",
        "    \"text_exercise_18\",\n",
        "    \"text_exercise_19\",\n",
        "    \"text_exercise_final\", \n",
        "    \"label\"], axis=1)\n",
        "\n",
        "\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,ys, test_size = 0.2 ,random_state= 42)\n",
        "\n",
        "def run_ridge(X_train, X_test, y_train, y_test, y_label, prediction_vector):\n",
        "    ridge = Ridge()\n",
        "    ridge.fit(X_train,y_train[y_label])\n",
        "    # test_preds = ridge.predict(X_test)\n",
        "    # test = pd.DataFrame(y_test[y_label])\n",
        "    # test['Pred_score'] = test_preds\n",
        "    # return test.corr().values[0][1]\n",
        "    dev_pred = ridge.predict(prediction_vector)\n",
        "    return dev_pred\n",
        "\n",
        "\n",
        "def run_rf(X_train, X_test, y_train, y_test, y_label, prediction_vector):\n",
        "    rf = RandomForestRegressor(max_depth=5, random_state=42, max_features= 4932) #, max_features=9962 # or .333\n",
        "    rf.fit(X_train,np.ravel(y_train[y_label],order='C'))\n",
        "    # test_preds = rf.predict(X_test)\n",
        "    # test = pd.DataFrame(y_test[y_label])\n",
        "    # test['Pred_score'] = test_preds\n",
        "    # return test.corr().values[0][1]\n",
        "    dev_pred = rf.predict(prediction_vector)\n",
        "    return dev_pred\n",
        "\n",
        "def run_bag(X_train, X_test, y_train, y_test, y_label, prediction_vector):\n",
        "    rf = RandomForestRegressor(max_depth=5, random_state=42) #, max_features=9962 # or .333\n",
        "    rf.fit(X_train,np.ravel(y_train[y_label],order='C'))\n",
        "    # test_preds = rf.predict(X_test)\n",
        "    # test = pd.DataFrame(y_test[y_label])\n",
        "    # test['Pred_score'] = test_preds\n",
        "    # return test.corr().values[0][1]\n",
        "    dev_pred = rf.predict(prediction_vector)\n",
        "    return dev_pred\n",
        "\n",
        "def run_knn(X_train, X_test, y_train, y_test, y_label, prediction_vector):\n",
        "    knn = KNeighborsRegressor(n_neighbors=93, p=2, weights=\"distance\")\n",
        "    knn.fit(X_train,y_train[y_label])\n",
        "    # test_preds = knn.predict(X_test)\n",
        "    # test = pd.DataFrame(y_test[y_label])\n",
        "    # test['Pred_score'] = test_preds\n",
        "    # return test.corr().values[0][1]\n",
        "    dev_pred = knn.predict(prediction_vector)\n",
        "    return dev_pred\n",
        "\n",
        "\n",
        "def new_run_ridge(X_train, X_test, y_train, y_test, y_label, prediction_vector):\n",
        "    scaler = StandardScaler().set_output(transform=\"pandas\")\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "    X_test = scaler.fit_transform(X_test)\n",
        "    grid = 10 ** np.linspace(3,-2,100)\n",
        "    ridge_cv = RidgeCV(alphas=grid, scoring='neg_mean_squared_error')\n",
        "    ridge_cv.fit(X_train,y_train[y_label])\n",
        "    ridge_cv.alpha_\n",
        "    ridge5 = Ridge(alpha=ridge_cv.alpha_)\n",
        "    ridge5_fit = ridge5.fit(X_train,y_train[y_label])\n",
        "    # test_preds = ridge5_fit.predict(X_test)\n",
        "    # test = pd.DataFrame(y_test[y_label])\n",
        "    # test['Pred_score'] = test_preds\n",
        "    # return test.corr().values[0][1]\n",
        "    dev_pred = ridge5_fit.predict(prediction_vector)\n",
        "    return dev_pred\n",
        "\n",
        "\n",
        "def run_lasso(X_train, X_test, y_train, y_test, y_label, prediction_vector):\n",
        "    scaler = StandardScaler().set_output(transform=\"pandas\")\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "    X_test = scaler.fit_transform(X_test)\n",
        "    grid = 10 ** np.linspace(3,-2,100)\n",
        "    lasso_cv = LassoCV(alphas=grid, cv=10)#,max_iter=100000,)\n",
        "    lasso_cv.fit(X_train,np.ravel(y_train[y_label],order='C'))\n",
        "    lasso_cv.alpha_\n",
        "    lasso2 = Lasso(alpha=lasso_cv.alpha_)#, max_iter=10000)\n",
        "    lasso2_fit = lasso2.fit(X_train,np.ravel(y_train[y_label],order='C'))\n",
        "    # test_preds = lasso2_fit.predict(X_test)\n",
        "    # test = pd.DataFrame(y_test[y_label])\n",
        "    # test['Pred_score'] = test_preds\n",
        "    # return test.corr().values[0][1]\n",
        "    dev_pred = lasso2_fit.predict(prediction_vector)\n",
        "    return dev_pred\n",
        "\n",
        "# [ bag, bag, rf, rf, bag, bag, bag ]\n",
        "\n",
        "\n",
        "# rating_chooses_appropriate_action\n",
        "rating_chooses_appropriate_action_pred = run_bag(X, X, ys, ys, ['rating_chooses_appropriate_action'], X_dev)\n",
        "print('finished one of those')\n",
        "dev_pub_df['rating_chooses_appropriate_action_pred'] = rating_chooses_appropriate_action_pred\n",
        "# rating_commits_to_action\n",
        "rating_commits_to_action_pred = run_bag(X, X, ys, ys, ['rating_commits_to_action'], X_dev)\n",
        "dev_pub_df['rating_commits_to_action_pred'] = rating_commits_to_action_pred\n",
        "\n",
        "# rating_gathers_information\n",
        "rating_gathers_information_pred = run_rf(X, X, ys, ys, ['rating_gathers_information'], X_dev)\n",
        "dev_pub_df['rating_gathers_information_pred'] = rating_gathers_information_pred\n",
        "\n",
        "# rating_identifies_issues_opportunities\n",
        "rating_identifies_issues_opportunities_pred = run_rf(X, X, ys, ys, ['rating_identifies_issues_opportunities'], X_dev)\n",
        "dev_pub_df['rating_identifies_issues_opportunities_pred'] = rating_identifies_issues_opportunities_pred\n",
        "\n",
        "# rating_interprets_information\n",
        "rating_interprets_information_pred = run_bag(X, X, ys, ys, ['rating_interprets_information'], X_dev)\n",
        "dev_pub_df['rating_interprets_information_pred'] = rating_interprets_information_pred\n",
        "\n",
        "# rating_involves_others\n",
        "rating_involves_others_pred = run_bag(X, X, ys, ys, ['rating_involves_others'], X_dev)\n",
        "dev_pub_df['rating_involves_others_pred'] = rating_involves_others_pred\n",
        "\n",
        "# rating_decision_making_final_score\n",
        "rating_decision_making_final_score_pred = run_bag(X, X, ys, ys, ['rating_decision_making_final_score'], X_dev)\n",
        "dev_pub_df['rating_decision_making_final_score_pred'] = rating_decision_making_final_score_pred\n",
        "\n",
        "# dev_pub_df.to_csv('old_ridge_S_cluster_cleaned_text_truly_clean_w_splits_w_bigrams_cos_sim.csv',index=False)\n",
        "dev_pub_df.to_csv('ctws_huge_L_optimal_just_FINAL_TEST_SET.csv',index=False)\n",
        "print('done')\n",
        "# so going with optimals is genearlly best, except don't use ridge on this except for on final decision (on huge I mean. It seems ok for LST clustered version Ls, but def not on Huge, nonlinear there.)\n"
      ],
      "metadata": {
        "id": "hV_II_tW54AY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.model_selection import train_test_split\n",
        "import sys\n",
        "from sklearn.linear_model import Ridge\n",
        "import time\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "# import torch\n",
        "from sklearn.linear_model import Ridge, RidgeCV, Lasso, LassoCV\n",
        "from sklearn.preprocessing import scale\n",
        "from sklearn.preprocessing import scale, StandardScaler\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "\n",
        "# Set pandas options to allow more printing rows/columns\n",
        "pd.set_option(\"display.max_rows\", 4000)\n",
        "pd.set_option(\"display.max_columns\", 4000)\n",
        "\n",
        "train_pub_df = pd.read_csv(\"/content/train_S_cluster_super_cos_sim_df_from_scratch_huge_just_FINAL_TEST_SET.csv\")\n",
        "dev_pub_df = pd.read_csv(\"/content/dev_S_cluster_super_cos_sim_df_from_scratch_huge_just_FINAL_TEST_SET.csv\")\n",
        "\n",
        "\n",
        "# computing number of columns\n",
        "cols = len(train_pub_df.axes[1])\n",
        "print(cols)\n",
        "\n",
        "cols_div_3 = cols // 3\n",
        "\n",
        "cols = train_pub_df.axes[1]\n",
        "print(cols)\n",
        "\n",
        "\n",
        "print('got that ')\n",
        "X = train_pub_df.drop(['Unnamed: 0', 'response_id', 'super', 'rating_chooses_appropriate_action','rating_commits_to_action','rating_gathers_information','rating_identifies_issues_opportunities','rating_interprets_information', 'rating_involves_others', \"rating_decision_making_final_score\", 'text_exercise_4',\n",
        "    'text_exercise_5',\n",
        "    'text_exercise_6',\n",
        "    'text_exercise_7',\n",
        "    \"text_exercise_8\",\n",
        "    \"text_exercise_9\",\n",
        "    \"text_exercise_10\",\n",
        "    \"text_exercise_11\",\n",
        "    \"text_exercise_12\",\n",
        "    \"text_exercise_13\",\n",
        "    \"text_exercise_14\",\n",
        "    \"text_exercise_15\",\n",
        "    \"text_exercise_16\",\n",
        "    \"text_exercise_17\",\n",
        "    \"text_exercise_18\",\n",
        "    \"text_exercise_19\",\n",
        "    \"text_exercise_final\", \n",
        "    'label'], axis=1)\n",
        "\n",
        "ys = train_pub_df[['rating_chooses_appropriate_action','rating_commits_to_action','rating_gathers_information','rating_identifies_issues_opportunities','rating_interprets_information', 'rating_involves_others', \"rating_decision_making_final_score\"]]\n",
        "\n",
        "X_dev = dev_pub_df.drop(['Unnamed: 0', 'response_id', 'super', 'rating_chooses_appropriate_action','rating_commits_to_action','rating_gathers_information','rating_identifies_issues_opportunities','rating_interprets_information', 'rating_involves_others', \"rating_decision_making_final_score\", 'text_exercise_4',\n",
        "    'text_exercise_5',\n",
        "    'text_exercise_6',\n",
        "    'text_exercise_7',\n",
        "    \"text_exercise_8\",\n",
        "    \"text_exercise_9\",\n",
        "    \"text_exercise_10\",\n",
        "    \"text_exercise_11\",\n",
        "    \"text_exercise_12\",\n",
        "    \"text_exercise_13\",\n",
        "    \"text_exercise_14\",\n",
        "    \"text_exercise_15\",\n",
        "    \"text_exercise_16\",\n",
        "    \"text_exercise_17\",\n",
        "    \"text_exercise_18\",\n",
        "    \"text_exercise_19\",\n",
        "    \"text_exercise_final\", \n",
        "    \"label\"], axis=1)\n",
        "\n",
        "\n",
        "# [ rf, bag, rf, bag, bag, rf, bag ]\n",
        "\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,ys, test_size = 0.2 ,random_state= 42)\n",
        "\n",
        "def run_ridge(X_train, X_test, y_train, y_test, y_label, prediction_vector):\n",
        "    ridge = Ridge()\n",
        "    ridge.fit(X_train,y_train[y_label])\n",
        "    # test_preds = ridge.predict(X_test)\n",
        "    # test = pd.DataFrame(y_test[y_label])\n",
        "    # test['Pred_score'] = test_preds\n",
        "    # return test.corr().values[0][1]\n",
        "    dev_pred = ridge.predict(prediction_vector)\n",
        "    return dev_pred\n",
        "\n",
        "\n",
        "def rf_5_wd3(X_train, X_test, y_train, y_test, y_label, prediction_vector):\n",
        "    rf = RandomForestRegressor(max_depth=5, random_state=42, max_features= 3176) #, max_features=9962 # or .333\n",
        "    rf.fit(X_train,np.ravel(y_train[y_label],order='C'))\n",
        "    # test_preds = rf.predict(X_test)\n",
        "    # test = pd.DataFrame(y_test[y_label])\n",
        "    # test['Pred_score'] = test_preds\n",
        "    # return test.corr().values[0][1]\n",
        "    dev_pred = rf.predict(prediction_vector)\n",
        "    return dev_pred\n",
        "\n",
        "def rf_3_wd3(X_train, X_test, y_train, y_test, y_label, prediction_vector):\n",
        "    rf = RandomForestRegressor(max_depth=3, random_state=42, max_features= 3176) #, max_features=9962 # or .333\n",
        "    rf.fit(X_train,np.ravel(y_train[y_label],order='C'))\n",
        "    # test_preds = rf.predict(X_test)\n",
        "    # test = pd.DataFrame(y_test[y_label])\n",
        "    # test['Pred_score'] = test_preds\n",
        "    # return test.corr().values[0][1]\n",
        "    dev_pred = rf.predict(prediction_vector)\n",
        "    return dev_pred\n",
        "\n",
        "def rf_7(X_train, X_test, y_train, y_test, y_label, prediction_vector):\n",
        "    rf = RandomForestRegressor(max_depth=7, random_state=42, max_features= 4932) #, max_features=9962 # or .333\n",
        "    rf.fit(X_train,np.ravel(y_train[y_label],order='C'))\n",
        "    # test_preds = rf.predict(X_test)\n",
        "    # test = pd.DataFrame(y_test[y_label])\n",
        "    # test['Pred_score'] = test_preds\n",
        "    # return test.corr().values[0][1]\n",
        "    dev_pred = rf.predict(prediction_vector)\n",
        "    return dev_pred\n",
        "\n",
        "def run_rf(X_train, X_test, y_train, y_test, y_label, prediction_vector):\n",
        "    rf = RandomForestRegressor(max_depth=5, random_state=42, max_features= 4932) #, max_features=9962 # or .333\n",
        "    rf.fit(X_train,np.ravel(y_train[y_label],order='C'))\n",
        "    # test_preds = rf.predict(X_test)\n",
        "    # test = pd.DataFrame(y_test[y_label])\n",
        "    # test['Pred_score'] = test_preds\n",
        "    # return test.corr().values[0][1]\n",
        "    dev_pred = rf.predict(prediction_vector)\n",
        "    return dev_pred\n",
        "\n",
        "def run_bag(X_train, X_test, y_train, y_test, y_label, prediction_vector):\n",
        "    rf = RandomForestRegressor(max_depth=5, random_state=42) #, max_features=9962 # or .333\n",
        "    rf.fit(X_train,np.ravel(y_train[y_label],order='C'))\n",
        "    # test_preds = rf.predict(X_test)\n",
        "    # test = pd.DataFrame(y_test[y_label])\n",
        "    # test['Pred_score'] = test_preds\n",
        "    # return test.corr().values[0][1]\n",
        "    dev_pred = rf.predict(prediction_vector)\n",
        "    return dev_pred\n",
        "\n",
        "def bag_3(X_train, X_test, y_train, y_test, y_label, prediction_vector):\n",
        "    rf = RandomForestRegressor(max_depth=3, random_state=42) #, max_features=9962 # or .333\n",
        "    rf.fit(X_train,np.ravel(y_train[y_label],order='C'))\n",
        "    # test_preds = rf.predict(X_test)\n",
        "    # test = pd.DataFrame(y_test[y_label])\n",
        "    # test['Pred_score'] = test_preds\n",
        "    # return test.corr().values[0][1]\n",
        "    dev_pred = rf.predict(prediction_vector)\n",
        "    return dev_pred\n",
        "\n",
        "def run_knn(X_train, X_test, y_train, y_test, y_label, prediction_vector):\n",
        "    knn = KNeighborsRegressor(n_neighbors=93, p=2, weights=\"distance\")\n",
        "    knn.fit(X_train,y_train[y_label])\n",
        "    # test_preds = knn.predict(X_test)\n",
        "    # test = pd.DataFrame(y_test[y_label])\n",
        "    # test['Pred_score'] = test_preds\n",
        "    # return test.corr().values[0][1]\n",
        "    dev_pred = knn.predict(prediction_vector)\n",
        "    return dev_pred\n",
        "\n",
        "\n",
        "def new_run_ridge(X_train, X_test, y_train, y_test, y_label, prediction_vector):\n",
        "    scaler = StandardScaler().set_output(transform=\"pandas\")\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "    X_test = scaler.fit_transform(X_test)\n",
        "    grid = 10 ** np.linspace(3,-2,100)\n",
        "    ridge_cv = RidgeCV(alphas=grid, scoring='neg_mean_squared_error')\n",
        "    ridge_cv.fit(X_train,y_train[y_label])\n",
        "    ridge_cv.alpha_\n",
        "    ridge5 = Ridge(alpha=ridge_cv.alpha_)\n",
        "    ridge5_fit = ridge5.fit(X_train,y_train[y_label])\n",
        "    # test_preds = ridge5_fit.predict(X_test)\n",
        "    # test = pd.DataFrame(y_test[y_label])\n",
        "    # test['Pred_score'] = test_preds\n",
        "    # return test.corr().values[0][1]\n",
        "    dev_pred = ridge5_fit.predict(prediction_vector)\n",
        "    return dev_pred\n",
        "\n",
        "\n",
        "def run_lasso(X_train, X_test, y_train, y_test, y_label, prediction_vector):\n",
        "    scaler = StandardScaler().set_output(transform=\"pandas\")\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "    X_test = scaler.fit_transform(X_test)\n",
        "    grid = 10 ** np.linspace(3,-2,100)\n",
        "    lasso_cv = LassoCV(alphas=grid, cv=10)#,max_iter=100000,)\n",
        "    lasso_cv.fit(X_train,np.ravel(y_train[y_label],order='C'))\n",
        "    lasso_cv.alpha_\n",
        "    lasso2 = Lasso(alpha=lasso_cv.alpha_)#, max_iter=10000)\n",
        "    lasso2_fit = lasso2.fit(X_train,np.ravel(y_train[y_label],order='C'))\n",
        "    # test_preds = lasso2_fit.predict(X_test)\n",
        "    # test = pd.DataFrame(y_test[y_label])\n",
        "    # test['Pred_score'] = test_preds\n",
        "    # return test.corr().values[0][1]\n",
        "    dev_pred = lasso2_fit.predict(prediction_vector)\n",
        "    return dev_pred\n",
        "\n",
        "\n",
        "# [ rf, bag, rf, bag, bag, rf, bag ]\n",
        "\n",
        "# rating_chooses_appropriate_action\n",
        "rating_chooses_appropriate_action_pred = run_rf(X, X, ys, ys, ['rating_chooses_appropriate_action'], X_dev)\n",
        "print('finished one of those')\n",
        "dev_pub_df['rating_chooses_appropriate_action_pred'] = rating_chooses_appropriate_action_pred\n",
        "# rating_commits_to_action\n",
        "rating_commits_to_action_pred = run_bag(X, X, ys, ys, ['rating_commits_to_action'], X_dev)\n",
        "dev_pub_df['rating_commits_to_action_pred'] = rating_commits_to_action_pred\n",
        "\n",
        "# rating_gathers_information\n",
        "rating_gathers_information_pred = run_rf(X, X, ys, ys, ['rating_gathers_information'], X_dev)\n",
        "dev_pub_df['rating_gathers_information_pred'] = rating_gathers_information_pred\n",
        "\n",
        "# rating_identifies_issues_opportunities\n",
        "rating_identifies_issues_opportunities_pred = run_bag(X, X, ys, ys, ['rating_identifies_issues_opportunities'], X_dev)\n",
        "dev_pub_df['rating_identifies_issues_opportunities_pred'] = rating_identifies_issues_opportunities_pred\n",
        "\n",
        "# rating_interprets_information\n",
        "rating_interprets_information_pred = run_bag(X, X, ys, ys, ['rating_interprets_information'], X_dev)\n",
        "dev_pub_df['rating_interprets_information_pred'] = rating_interprets_information_pred\n",
        "\n",
        "# rating_involves_others\n",
        "rating_involves_others_pred = run_rf(X, X, ys, ys, ['rating_involves_others'], X_dev)\n",
        "dev_pub_df['rating_involves_others_pred'] = rating_involves_others_pred\n",
        "\n",
        "# rating_decision_making_final_score\n",
        "rating_decision_making_final_score_pred = run_bag(X, X, ys, ys, ['rating_decision_making_final_score'], X_dev)\n",
        "dev_pub_df['rating_decision_making_final_score_pred'] = rating_decision_making_final_score_pred\n",
        "\n",
        "# dev_pub_df.to_csv('old_ridge_S_cluster_cleaned_text_truly_clean_w_splits_w_bigrams_cos_sim.csv',index=False)\n",
        "dev_pub_df.to_csv('ctws_huge_S_optimal_just_FINAL_TEST_SET.csv',index=False)\n",
        "print('done')"
      ],
      "metadata": {
        "id": "Ffiz2rBd55eV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "\n",
        "ctws_huge_L_optimal = read.csv(\"/content/ctws_huge_L_optimal_just_FINAL_TEST_SET.csv\")\n",
        "ctws_huge_S_optimal = read.csv(\"/content/ctws_huge_S_optimal_just_FINAL_TEST_SET.csv\")\n",
        "\n",
        "dev_pub_w_preds = rbind(ctws_huge_L_optimal, ctws_huge_S_optimal)\n"
      ],
      "metadata": {
        "id": "hjCXTvcg54Jc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "\n",
        "train_pub_df <- read.csv(\"/content/train_pub.csv\")"
      ],
      "metadata": {
        "id": "FPBPH3jArs-4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "\n",
        "ret_df_before_rounding = subset(dev_pub_w_preds, select = c(response_id, rating_chooses_appropriate_action_pred, rating_commits_to_action_pred, rating_gathers_information_pred, rating_identifies_issues_opportunities_pred, rating_interprets_information_pred, rating_involves_others_pred, rating_decision_making_final_score_pred))\n",
        "\n",
        "copy_of_ret_df_before_rounding = ret_df_before_rounding\n",
        "\n",
        "round_df <- function(x, digits) {\n",
        "  # round all numeric variables\n",
        "  # x: data frame \n",
        "  # digits: number of digits to round\n",
        "  numeric_columns <- sapply(x, mode) == 'numeric'\n",
        "  x[numeric_columns] <-  round(x[numeric_columns], digits)\n",
        "  x\n",
        "}\n",
        "\n",
        "after_rounding_ret = round_df(copy_of_ret_df_before_rounding, 0)\n",
        "\n",
        "colnames(after_rounding_ret)[2] = \"rating_chooses_appropriate_action\"\n",
        "colnames(after_rounding_ret)[3] = \"rating_commits_to_action\"\n",
        "colnames(after_rounding_ret)[4] = \"rating_gathers_information\"\n",
        "colnames(after_rounding_ret)[5] = \"rating_identifies_issues_opportunities\"\n",
        "colnames(after_rounding_ret)[6] = \"rating_interprets_information\"\n",
        "colnames(after_rounding_ret)[7] = \"rating_involves_others\"\n",
        "colnames(after_rounding_ret)[8] = \"rating_decision_making_final_score\"\n",
        "\n",
        "\n",
        "########## QUANTILES ##########\n",
        "\n",
        "## CHOOSES APPROPRIATE ACTION QUANTILE\n",
        "\n",
        "table(train_pub_df$rating_chooses_appropriate_action)\n",
        "8 + 436 + 819 +  123 # = 1386\n",
        "436 + 8\n",
        "444 / 1386 # = 0.3203463 = lower_cutoff_chooses_appropriate_action\n",
        "(444 + 819) / 1386 # = 0.9112554 = upper_cutoff_chooses_appropriate_action\n",
        "lower_cutoff_chooses_appropriate_action = 0.3203463\n",
        "upper_cutoff_chooses_appropriate_action = 0.9112554\n",
        "\n",
        "actual_value_lower_cutoff_chooses_appropriate_action = quantile(copy_of_ret_df_before_rounding$rating_chooses_appropriate_action_pred, probs = lower_cutoff_chooses_appropriate_action, names = FALSE)\n",
        "\n",
        "actual_value_upper_cutoff_chooses_appropriate_action = quantile(copy_of_ret_df_before_rounding$rating_chooses_appropriate_action_pred, probs = upper_cutoff_chooses_appropriate_action, names = FALSE)\n",
        "\n",
        "\n",
        "after_rounding_ret$rating_chooses_appropriate_action = ifelse(copy_of_ret_df_before_rounding$rating_chooses_appropriate_action_pred < actual_value_lower_cutoff_chooses_appropriate_action, 2, ifelse(copy_of_ret_df_before_rounding$rating_chooses_appropriate_action_pred > actual_value_upper_cutoff_chooses_appropriate_action, 4, 3))\n",
        "\n",
        "hist(train_pub_df$rating_chooses_appropriate_action)\n",
        "hist(after_rounding_ret$rating_chooses_appropriate_action)\n",
        "\n",
        "\n",
        "\n",
        "### COMMITS TO ACTION QUANTILE\n",
        "\n",
        "table(train_pub_df$rating_commits_to_action)\n",
        "\n",
        "# 1   2   3   4 \n",
        "# 3 203 915 345 \n",
        "# 3 + 203 + 915 + 345 # = 1466\n",
        "# 206/1466 # = 0.1405184\n",
        "\n",
        "lower_cutoff_commits_to_action = 0.1405184\n",
        "\n",
        "\n",
        "# (206 + 915) / 1466 # = 0.7646658\n",
        "\n",
        "upper_cutoff_commits_to_action = 0.7646658\n",
        "\n",
        "actual_value_lower_cutoff_commits_to_action = quantile(copy_of_ret_df_before_rounding$rating_commits_to_action_pred, probs = lower_cutoff_commits_to_action, names = FALSE)\n",
        "\n",
        "actual_value_upper_cutoff_commits_to_action = quantile(copy_of_ret_df_before_rounding$rating_commits_to_action_pred, probs = upper_cutoff_commits_to_action, names = FALSE)\n",
        "\n",
        "quantile_test_commits_to_action = ifelse(copy_of_ret_df_before_rounding$rating_commits_to_action_pred < actual_value_lower_cutoff_commits_to_action, 2, ifelse(copy_of_ret_df_before_rounding$rating_commits_to_action_pred > actual_value_upper_cutoff_commits_to_action, 4, 3))\n",
        "\n",
        "after_rounding_ret$rating_commits_to_action = quantile_test_commits_to_action\n",
        "\n",
        "hist(after_rounding_ret$rating_commits_to_action)\n",
        "hist(train_pub_df$rating_commits_to_action)\n",
        "\n",
        "\n",
        "## GATHERS INFORMATION QUANTILE \n",
        "\n",
        "table(train_pub_df$rating_gathers_information)\n",
        "# 1   2   3   4 \n",
        "# 3 581 730 152 \n",
        "3 + 581 + 730 + 152 # = 1466\n",
        "\n",
        "lower_cutoff_gathers_information = 584 / 1466\n",
        "\n",
        "upper_cutoff_gathers_information = (584 + 730) / 1466\n",
        "\n",
        "actual_value_lower_cutoff_gathers_information = quantile(copy_of_ret_df_before_rounding$rating_gathers_information_pred, probs = lower_cutoff_gathers_information, names = FALSE)\n",
        "\n",
        "actual_value_upper_cutoff_gathers_information = quantile(copy_of_ret_df_before_rounding$rating_gathers_information_pred, probs = upper_cutoff_gathers_information, names = FALSE)\n",
        "\n",
        "\n",
        "after_rounding_ret$rating_gathers_information = ifelse(copy_of_ret_df_before_rounding$rating_gathers_information_pred < actual_value_lower_cutoff_gathers_information, 2, ifelse(copy_of_ret_df_before_rounding$rating_gathers_information_pred > actual_value_upper_cutoff_gathers_information, 4, 3))\n",
        "\n",
        "hist(after_rounding_ret$rating_gathers_information)\n",
        "hist(train_pub_df$rating_gathers_information)\n",
        "\n",
        "\n",
        "## IDENTIFIES ISSUES OPPS QUANTILE \n",
        "\n",
        "table(train_pub_df$rating_identifies_issues_opportunities)\n",
        "# 1   2   3   4 \n",
        "# 3 517 802  64 \n",
        "\n",
        "3 + 517 + 802 + 64 # = 1386\n",
        "\n",
        "lower_cutoff_identifies_issues_oppurtunities = 520 / 1386\n",
        "\n",
        "upper_cutoff_identifies_issues_oppurtunities = (520 + 802) / 1386\n",
        "\n",
        "actual_value_lower_cutoff_identifies_issues_oppurtunities = quantile(copy_of_ret_df_before_rounding$rating_identifies_issues_opportunities_pred, probs = lower_cutoff_identifies_issues_oppurtunities, names = FALSE)\n",
        "\n",
        "actual_value_upper_cutoff_identifies_issues_oppurtunities  = quantile(copy_of_ret_df_before_rounding$rating_identifies_issues_opportunities_pred, probs = upper_cutoff_identifies_issues_oppurtunities, names = FALSE)\n",
        "\n",
        "\n",
        "after_rounding_ret$rating_identifies_issues_opportunities = ifelse(copy_of_ret_df_before_rounding$rating_identifies_issues_opportunities_pred < actual_value_lower_cutoff_identifies_issues_oppurtunities, 2, ifelse(copy_of_ret_df_before_rounding$rating_identifies_issues_opportunities_pred > actual_value_upper_cutoff_identifies_issues_oppurtunities, 4, 3))\n",
        "\n",
        "\n",
        "hist(train_pub_df$rating_identifies_issues_opportunities)\n",
        "hist(after_rounding_ret$rating_identifies_issues_opportunities)\n",
        "\n",
        "table(after_rounding_ret$rating_identifies_issues_opportunities)\n",
        "\n",
        "# INTERPRETS INFORMATION QUANTILE \n",
        "\n",
        "table(train_pub_df$rating_interprets_information)\n",
        "\n",
        "# 2   3   4 \n",
        "# 883 484  99 \n",
        "\n",
        "883 + 484 + 99 # = 1466\n",
        "\n",
        "lower_cutoff_interprets_information = 883/1466\n",
        "\n",
        "upper_cutoff_interprets_information = (883 + 484) / 1466\n",
        "\n",
        "actual_value_lower_cutoff_interprets_information = quantile(copy_of_ret_df_before_rounding$rating_interprets_information_pred, probs = lower_cutoff_interprets_information, names = FALSE)\n",
        "\n",
        "actual_value_upper_cutoff_interprets_information  = quantile(copy_of_ret_df_before_rounding$rating_interprets_information_pred, probs = upper_cutoff_interprets_information, names = FALSE)\n",
        "\n",
        "\n",
        "after_rounding_ret$rating_interprets_information = ifelse(copy_of_ret_df_before_rounding$rating_interprets_information_pred < actual_value_lower_cutoff_interprets_information, 2, ifelse(copy_of_ret_df_before_rounding$rating_interprets_information_pred > actual_value_upper_cutoff_interprets_information, 4, 3))\n",
        "\n",
        "hist(train_pub_df$rating_interprets_information)\n",
        "hist(after_rounding_ret$rating_interprets_information)\n",
        "\n",
        "\n",
        "# INVOLVES OTHERS QUANTILE \n",
        "\n",
        "table(train_pub_df$rating_involves_others)\n",
        "# 2   3   4 \n",
        "# 474 703 204 \n",
        "\n",
        "\n",
        "474 + 703 + 204 # = 1381\n",
        "\n",
        "lower_cutoff_involves_others = 474 / 1381\n",
        "upper_cutoff_involves_others = (474 + 703) / 1381\n",
        "\n",
        "actual_value_lower_cutoff_involves_others = quantile(copy_of_ret_df_before_rounding$rating_involves_others_pred, probs = lower_cutoff_involves_others, names = FALSE)\n",
        "\n",
        "actual_value_upper_cutoff_involves_others  = quantile(copy_of_ret_df_before_rounding$rating_involves_others_pred, probs = upper_cutoff_involves_others, names = FALSE)\n",
        "\n",
        "\n",
        "after_rounding_ret$rating_involves_others = ifelse(copy_of_ret_df_before_rounding$rating_involves_others_pred < actual_value_lower_cutoff_involves_others, 2, ifelse(copy_of_ret_df_before_rounding$rating_involves_others_pred > actual_value_upper_cutoff_involves_others, 4, 3))\n",
        "\n",
        "hist(train_pub_df$rating_involves_others)\n",
        "hist(after_rounding_ret$rating_involves_others)\n",
        "\n",
        "# FINAL DECISION QUANTILE \n",
        "\n",
        "table(train_pub_df$rating_decision_making_final_score)\n",
        "# 1   2   3   4   5   6   7 \n",
        "# 24 522 402 283 111 107  17 \n",
        "\n",
        "24 + 522 + 402 + 283 + 111 + 107 + 17 # = 1466\n",
        "\n",
        "final_decision_1_cutoff = 24 / 1466\n",
        "final_decision_2_cutoff = (24 + 522) / 1466\n",
        "final_decision_3_cutoff = (24 + 522 + 402) / 1466\n",
        "final_decision_4_cutoff = (24 + 522 + 402 + 283) / 1466\n",
        "final_decision_5_cutoff = (24 + 522 + 402 + 283 + 111) / 1466\n",
        "final_decision_6_cutoff = (24 + 522 + 402 + 283 + 111 + 107) / 1466\n",
        "\n",
        "actual_value_final_decision_1_cutoff = quantile(copy_of_ret_df_before_rounding$rating_decision_making_final_score_pred, probs = final_decision_1_cutoff, names = FALSE)\n",
        "actual_value_final_decision_2_cutoff = quantile(copy_of_ret_df_before_rounding$rating_decision_making_final_score_pred, probs = final_decision_2_cutoff, names = FALSE)\n",
        "actual_value_final_decision_3_cutoff = quantile(copy_of_ret_df_before_rounding$rating_decision_making_final_score_pred, probs = final_decision_3_cutoff, names = FALSE)\n",
        "actual_value_final_decision_4_cutoff = quantile(copy_of_ret_df_before_rounding$rating_decision_making_final_score_pred, probs = final_decision_4_cutoff, names = FALSE)\n",
        "actual_value_final_decision_5_cutoff = quantile(copy_of_ret_df_before_rounding$rating_decision_making_final_score_pred, probs = final_decision_5_cutoff, names = FALSE)\n",
        "actual_value_final_decision_6_cutoff = quantile(copy_of_ret_df_before_rounding$rating_decision_making_final_score_pred, probs = final_decision_6_cutoff, names = FALSE)\n",
        "\n",
        "\n",
        "after_rounding_ret$rating_decision_making_final_score = ifelse(copy_of_ret_df_before_rounding$rating_decision_making_final_score_pred < actual_value_final_decision_1_cutoff, 1, ifelse(copy_of_ret_df_before_rounding$rating_decision_making_final_score_pred <= actual_value_final_decision_2_cutoff, 2, ifelse(copy_of_ret_df_before_rounding$rating_decision_making_final_score_pred < actual_value_final_decision_3_cutoff, 3, ifelse(copy_of_ret_df_before_rounding$rating_decision_making_final_score_pred < actual_value_final_decision_4_cutoff, 4, ifelse(copy_of_ret_df_before_rounding$rating_decision_making_final_score_pred < actual_value_final_decision_5_cutoff, 5, ifelse(copy_of_ret_df_before_rounding$rating_decision_making_final_score_pred <= actual_value_final_decision_6_cutoff, 6, 7))))))\n",
        "\n",
        "hist(train_pub_df$rating_decision_making_final_score)\n",
        "hist(after_rounding_ret$rating_decision_making_final_score)\n",
        "\n",
        "write.csv(after_rounding_ret, 'model_3_predictions.csv')"
      ],
      "metadata": {
        "id": "NxJSHJnz6Kkg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Finally, combine the predictions from Models 1, 2, and 3:**"
      ],
      "metadata": {
        "id": "3pfJH0FJ7Qvf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "\n",
        "model_1_preds <- read.csv(\"/content/model_1_predictions.csv\")\n",
        "model_2_preds <- read.csv(\"/content/model_2_predictions.csv\")\n",
        "model_3_preds <- read.csv(\"/content/model_3_predictions.csv\")\n",
        "\n",
        "model_1_preds <- subset(model_1_preds, select = -c(X))\n",
        "model_2_preds <- subset(model_2_preds, select = -c(X))\n",
        "model_3_preds <- subset(model_3_preds, select = -c(X))\n",
        "\n",
        "curr_best = model_1_preds\n",
        "\n",
        "after_rounding_ret = model_3_preds\n",
        "\n",
        "colnames(after_rounding_ret)[2] = \"no\"\n",
        "colnames(after_rounding_ret)[3] = \"noo\"\n",
        "colnames(after_rounding_ret)[4] = \"nooo\"\n",
        "colnames(after_rounding_ret)[5] = \"noooo\"\n",
        "colnames(after_rounding_ret)[6] = \"nooooo\"\n",
        "colnames(after_rounding_ret)[8] = \"noooooo\"\n",
        "\n",
        "colnames(curr_best)[7] = \"nope\"\n",
        "\n",
        "curr_best = merge(curr_best, after_rounding_ret, on = \"response_id\")\n",
        "\n",
        "curr_best$nope = curr_best$rating_involves_others\n",
        "\n",
        "colnames(curr_best)\n",
        "\n",
        "curr_best = subset(curr_best, select = -c(no, noo, nooo, noooo, nooooo, rating_involves_others,noooooo))\n",
        "\n",
        "colnames(curr_best)\n",
        "\n",
        "colnames(curr_best)[7] = \"rating_involves_others\"\n",
        "\n",
        "# Just interprets information\n",
        "\n",
        "after_rounding_ret = model_2_preds\n",
        "\n",
        "colnames(after_rounding_ret)\n",
        "colnames(curr_best)\n",
        "\n",
        "colnames(after_rounding_ret)[2] = \"no\"\n",
        "colnames(after_rounding_ret)[3] = \"noo\"\n",
        "colnames(after_rounding_ret)[4] = \"nooo\"\n",
        "colnames(after_rounding_ret)[5] = \"noooo\"\n",
        "colnames(after_rounding_ret)[7] = \"nooooo\"\n",
        "colnames(after_rounding_ret)[8] = \"noooooo\"\n",
        "\n",
        "colnames(curr_best)[6] = \"nope\"\n",
        "\n",
        "curr_best = merge(curr_best, after_rounding_ret, on = \"response_id\")\n",
        "\n",
        "curr_best$nope = curr_best$rating_interprets_information\n",
        "\n",
        "colnames(curr_best)\n",
        "\n",
        "curr_best = subset(curr_best, select = -c(no, noo, nooo, rating_interprets_information ,noooo, nooooo,noooooo))\n",
        "\n",
        "colnames(curr_best)[6] = \"rating_interprets_information\"\n",
        "\n",
        "write.csv(curr_best, file = \"FINAL_PREDICTIONS.csv\")\n"
      ],
      "metadata": {
        "id": "JB_PlrHI7OG1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
